{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebd0c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 한글 폰트 설정 완료\n",
      "🚀 난소암 생존 예측 모델 초기화 (XAI + CDSS 호환)\n",
      "📁 데이터 경로: /Users/baeeunjeong/Library/CloudStorage/GoogleDrive-baeeunjeong00@gmail.com/.shortcut-targets-by-id/1aXfYtUWSYS8foz14MAJMhDH7IHhG1wNZ/2조/데이터/clinical model/ovarian/TCGA-OV_clinical_data.csv\n",
      "🔍 홀드아웃 환자: TCGA-30-1714\n",
      "⏰ 시작 시간: 2025-06-22 15:53:24\n",
      "============================================================\n",
      "🚀 난소암 생존 예측 모델 전체 분석 시작\n",
      "================================================================================\n",
      "\n",
      "📊 1. 데이터 로드 및 탐색\n",
      "✅ 데이터 로드 성공: 608행 × 86열\n",
      "📈 데이터 기본 정보:\n",
      "   - 총 환자 수: 608\n",
      "   - 총 컬럼 수: 86\n",
      "   - 생존 환자: 236명\n",
      "   - 사망 환자: 349명\n",
      "   - 사망률: 57.4%\n",
      "\n",
      "🔧 2. 데이터 전처리\n",
      "✅ 사용 가능한 컬럼: 45개\n",
      "🔄 생존 변수 생성 중...\n",
      "✅ 유효한 생존 데이터: 583명\n",
      "   - 사망 이벤트: 349건\n",
      "   - 중간 생존 시간: 1000일\n",
      "\n",
      "📋 결측값 분석:\n",
      "   - days_to_death: 235개 (40.3%)\n",
      "   - figo_stage: 4개 (0.7%)\n",
      "   - ajcc_pathologic_t: 583개 (100.0%)\n",
      "   - ajcc_pathologic_n: 583개 (100.0%)\n",
      "   - ajcc_pathologic_m: 583개 (100.0%)\n",
      "   - figo_staging_edition_year: 583개 (100.0%)\n",
      "   - tumor_grade: 3개 (0.5%)\n",
      "   - residual_disease: 525개 (90.1%)\n",
      "   - age_at_diagnosis: 11개 (1.9%)\n",
      "   - treatments_pharmaceutical_treatment_type: 546개 (93.7%)\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 547개 (93.8%)\n",
      "   - treatments_radiation_treatment_type: 68개 (11.7%)\n",
      "   - treatments_radiation_treatment_intent_type: 92개 (15.8%)\n",
      "   - laterality: 31개 (5.3%)\n",
      "   - method_of_diagnosis: 6개 (1.0%)\n",
      "   - days_to_last_known_disease_status: 583개 (100.0%)\n",
      "   - last_known_disease_status: 583개 (100.0%)\n",
      "   - days_to_recurrence: 583개 (100.0%)\n",
      "   - progression_or_recurrence: 583개 (100.0%)\n",
      "   - treatments_pharmaceutical_treatment_outcome: 567개 (97.3%)\n",
      "   - treatments_radiation_treatment_outcome: 582개 (99.8%)\n",
      "   - treatments_pharmaceutical_days_to_treatment_start: 582개 (99.8%)\n",
      "   - treatments_pharmaceutical_days_to_treatment_end: 582개 (99.8%)\n",
      "   - treatments_pharmaceutical_number_of_cycles: 583개 (100.0%)\n",
      "   - treatments_radiation_days_to_treatment_start: 552개 (94.7%)\n",
      "   - tumor_of_origin: 583개 (100.0%)\n",
      "   - ajcc_staging_system_edition: 583개 (100.0%)\n",
      "   - year_of_birth: 583개 (100.0%)\n",
      "   - year_of_death: 583개 (100.0%)\n",
      "🗑️  높은 결측률 컬럼 제거: ['ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m', 'figo_staging_edition_year', 'residual_disease', 'treatments_pharmaceutical_treatment_type', 'treatments_pharmaceutical_treatment_intent_type', 'days_to_last_known_disease_status', 'last_known_disease_status', 'days_to_recurrence', 'progression_or_recurrence', 'treatments_pharmaceutical_treatment_outcome', 'treatments_radiation_treatment_outcome', 'treatments_pharmaceutical_days_to_treatment_start', 'treatments_pharmaceutical_days_to_treatment_end', 'treatments_pharmaceutical_number_of_cycles', 'treatments_radiation_days_to_treatment_start', 'tumor_of_origin', 'ajcc_staging_system_edition', 'year_of_birth', 'year_of_death']\n",
      "\n",
      "🎯 3. 특성 준비 및 인코딩\n",
      "🔄 특정 환자 홀드아웃 중: TCGA-30-1714\n",
      "✅ 홀드아웃 환자 발견: TCGA-30-1714\n",
      "   - 홀드아웃 환자: 1명\n",
      "   - 모델 훈련용 데이터: 582명\n",
      "📊 초기 특성 개수: 20\n",
      "📊 샘플 개수: 582\n",
      "🔤 범주형 변수: 17개\n",
      "🔢 수치형 변수: 3개\n",
      "🔄 결측값 처리 중...\n",
      "✅ Imputer 훈련 완료: 3개 수치형 변수\n",
      "\n",
      "   🔍 figo_stage 처리:\n",
      "      - 전처리 전 분포: {'Stage IIIC': 412, 'Stage IV': 88, 'Stage IIIB': 24}\n",
      "      - 결측치를 'Stage IIIC'로 대체\n",
      "\n",
      "   🔍 tumor_grade 처리:\n",
      "      - 전처리 전 분포: {'G3': 491, 'G2': 69, 'GX': 10}\n",
      "      - 결측치를 'G3'로 대체\n",
      "\n",
      "   🔍 morphology 처리:\n",
      "      - 전처리 전 분포: {'8441/3': 575, '8460/3': 4, '8461/3': 2}\n",
      "\n",
      "   🔍 primary_diagnosis 처리:\n",
      "      - 전처리 전 분포: {'Serous cystadenocarcinoma, NOS': 575, 'Papillary serous cystadenocarcinoma': 4, 'Serous surface papillary carcinoma': 2}\n",
      "\n",
      "   🔍 classification_of_tumor 처리:\n",
      "      - 전처리 전 분포: {'primary': 582}\n",
      "\n",
      "   🔍 gender 처리:\n",
      "      - 전처리 전 분포: {'female': 582}\n",
      "\n",
      "   🔍 race 처리:\n",
      "      - 전처리 전 분포: {'white': 497, 'black or african american': 34, 'not reported': 27}\n",
      "\n",
      "   🔍 ethnicity 처리:\n",
      "      - 전처리 전 분포: {'not hispanic or latino': 338, 'not reported': 233, 'hispanic or latino': 11}\n",
      "\n",
      "   🔍 prior_treatment 처리:\n",
      "      - 전처리 전 분포: {'No': 581, 'Yes': 1}\n",
      "\n",
      "   🔍 prior_malignancy 처리:\n",
      "      - 전처리 전 분포: {'not reported': 570, 'no': 12}\n",
      "\n",
      "   🔍 synchronous_malignancy 처리:\n",
      "      - 전처리 전 분포: {'Not Reported': 570, 'No': 9, 'Yes': 3}\n",
      "\n",
      "   🔍 treatments_radiation_treatment_type 처리:\n",
      "      - 전처리 전 분포: {'Radiation Therapy, NOS': 487, nan: 68, 'Radiation, External Beam': 26}\n",
      "      - 결측치를 'Radiation Therapy, NOS'로 대체\n",
      "\n",
      "   🔍 treatments_radiation_treatment_intent_type 처리:\n",
      "      - 전처리 전 분포: {'Adjuvant': 483, nan: 92, 'Palliative': 7}\n",
      "      - 결측치를 'Adjuvant'로 대체\n",
      "\n",
      "   🔍 laterality 처리:\n",
      "      - 전처리 전 분포: {'Bilateral': 399, 'Left': 82, 'Right': 70}\n",
      "      - 결측치를 'Bilateral'로 대체\n",
      "\n",
      "   🔍 site_of_resection_or_biopsy 처리:\n",
      "      - 전처리 전 분포: {'Ovary': 579, 'Specified parts of peritoneum': 3}\n",
      "\n",
      "   🔍 tissue_or_organ_of_origin 처리:\n",
      "      - 전처리 전 분포: {'Ovary': 575, 'Specified parts of peritoneum': 4, 'Peritoneum, NOS': 2}\n",
      "\n",
      "   🔍 method_of_diagnosis 처리:\n",
      "      - 전처리 전 분포: {'Surgical Resection': 464, 'Cytology': 78, 'Incisional Biopsy': 13}\n",
      "      - 결측치를 'Surgical Resection'로 대체\n",
      "\n",
      "🔄 범주형 변수 인코딩:\n",
      "   - figo_stage 인코딩 매핑: {'Stage IA': 0, 'Stage IB': 1, 'Stage IC': 2, 'Stage IIA': 3, 'Stage IIB': 4, 'Stage IIC': 5, 'Stage IIIA': 6, 'Stage IIIB': 7, 'Stage IIIC': 8, 'Stage IV': 9}\n",
      "   - tumor_grade 인코딩 매핑: {'G1': 0, 'G2': 1, 'G3': 2, 'G4': 3, 'GB': 4, 'GX': 5}\n",
      "   - morphology 인코딩 매핑: {'8440/3': 0, '8441/3': 1, '8460/3': 2, '8461/3': 3}\n",
      "   - primary_diagnosis 인코딩 매핑: {'Cystadenocarcinoma, NOS': 0, 'Papillary serous cystadenocarcinoma': 1, 'Serous cystadenocarcinoma, NOS': 2, 'Serous surface papillary carcinoma': 3}\n",
      "   - classification_of_tumor 인코딩 매핑: {'primary': 0}\n",
      "   - prior_treatment 인코딩 매핑: {'No': 0, 'Yes': 1}\n",
      "   - prior_malignancy 인코딩 매핑: {'no': 0, 'not reported': 1}\n",
      "   - synchronous_malignancy 인코딩 매핑: {'No': 0, 'Not Reported': 1, 'Yes': 2}\n",
      "   - treatments_radiation_treatment_type 인코딩 매핑: {'Radiation Therapy, NOS': 0, 'Radiation, External Beam': 1, 'Radiation, Radioisotope': 2}\n",
      "   - treatments_radiation_treatment_intent_type 인코딩 매핑: {'Adjuvant': 0, 'Palliative': 1}\n",
      "\n",
      "🔍 다중공선성 검사 및 해결:\n",
      "🗑️  분산 0인 특성 제거: ['classification_of_tumor', 'gender', 'days_to_diagnosis']\n",
      "🗑️  높은 VIF 특성 제거 (>10): ['year_of_diagnosis', 'figo_stage', 'tumor_grade', 'morphology', 'primary_diagnosis', 'age_at_diagnosis', 'race', 'prior_malignancy', 'synchronous_malignancy', 'method_of_diagnosis']\n",
      "✅ VIF 검사 완료\n",
      "📊 최종 특성 개수: 7\n",
      "✅ 특성 준비 완료 (CDSS 호환)\n",
      "\n",
      "✂️  4. 데이터 분할 (훈련:검증:테스트 = 60:20:20)\n",
      "📊 훈련 세트: 348명 (사망: 208명)\n",
      "📊 검증 세트: 117명 (사망: 70명)\n",
      "📊 테스트 세트: 117명 (사망: 70명)\n",
      "📊 CDSS 테스트: 1명 (별도 보관)\n",
      "\n",
      "🤖 5. 모델 훈련\n",
      "🔄 Cox 비례위험 모델 훈련 중...\n",
      "✅ Cox 모델 훈련 완료\n",
      "🔄 Random Survival Forest 훈련 중...\n",
      "✅ Random Survival Forest 훈련 완료 (CDSS 호환)\n",
      "🔄 Gradient Boosting Survival 훈련 중...\n",
      "✅ Gradient Boosting Survival 훈련 완료 (CDSS 호환)\n",
      "🔄 Lifelines Cox 모델 훈련 중...\n",
      "❌ Lifelines Cox 모델 훈련 실패: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
      "\n",
      "🎯 총 3개 모델 훈련 완료\n",
      "\n",
      "📈 6. 모델 평가\n",
      "\n",
      "🔍 Cox 모델 평가:\n",
      "   Train: C-index = 0.522\n",
      "   Validation: C-index = 0.451\n",
      "   Test: C-index = 0.513\n",
      "\n",
      "🔍 RSF 모델 평가:\n",
      "   Train: C-index = 0.531\n",
      "   Validation: C-index = 0.470\n",
      "   Test: C-index = 0.522\n",
      "\n",
      "🔍 GBSA 모델 평가:\n",
      "   Train: C-index = 0.538\n",
      "   Validation: C-index = 0.489\n",
      "   Test: C-index = 0.527\n",
      "\n",
      "🔍 XAI 모델 설명 생성\n",
      "🔄 SHAP 설명 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 51it [01:34,  2.00s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RSF SHAP 설명 생성 완료 (PermutationExplainer)\n",
      "\n",
      "🔄 LIME 설명 생성 중...\n",
      "✅ RSF LIME 설명기 생성 완료\n",
      "\n",
      "📊 XAI 시각화 생성\n",
      "✅ SHAP 시각화 완료\n",
      "✅ LIME 시각화 완료\n",
      "\n",
      "📊 7. 생존 곡선 시각화\n",
      "\n",
      "🔬 CDSS 호환성 테스트\n",
      "\n",
      "🔧 Holdout 환자 전처리 시작\n",
      "🔍 원본 환자 특성: 20개\n",
      "🔍 모델 훈련 특성: 7개\n",
      "✅ ethnicity: 원본 데이터 사용\n",
      "✅ prior_treatment: 원본 데이터 사용\n",
      "✅ treatments_radiation_treatment_type: 원본 데이터 사용\n",
      "✅ treatments_radiation_treatment_intent_type: 원본 데이터 사용\n",
      "✅ laterality: 원본 데이터 사용\n",
      "✅ site_of_resection_or_biopsy: 원본 데이터 사용\n",
      "✅ tissue_or_organ_of_origin: 원본 데이터 사용\n",
      "\n",
      "🔄 범주형 변수 전처리:\n",
      "   - ethnicity: 원본값 = not hispanic or latino\n",
      "     → 인코딩: 'not hispanic or latino' → 1\n",
      "   - prior_treatment: 원본값 = No\n",
      "     → 인코딩: 'No' → 0\n",
      "   - treatments_radiation_treatment_type: 원본값 = Radiation, External Beam\n",
      "     → 인코딩: 'Radiation, External Beam' → 1\n",
      "   - treatments_radiation_treatment_intent_type: 원본값 = Adjuvant\n",
      "     → 인코딩: 'Adjuvant' → 0\n",
      "   - laterality: 원본값 = Bilateral\n",
      "     → 인코딩: 'Bilateral' → 0\n",
      "   - site_of_resection_or_biopsy: 원본값 = Ovary\n",
      "     → 인코딩: 'Ovary' → 0\n",
      "   - tissue_or_organ_of_origin: 원본값 = Ovary\n",
      "     → 인코딩: 'Ovary' → 0\n",
      "\n",
      "🔢 데이터 타입 변환:\n",
      "✅ 모든 컬럼 수치형 변환 완료\n",
      "✅ 특성 순서 정렬 완료: (1, 7)\n",
      "\n",
      "📏 Imputer 적용:\n",
      "   - 입력 형태: (1, 7)\n",
      "   - 입력 특성명: ['ethnicity', 'prior_treatment', 'treatments_radiation_treatment_type', 'treatments_radiation_treatment_intent_type', 'laterality', 'site_of_resection_or_biopsy', 'tissue_or_organ_of_origin']\n",
      "⚠️ Imputer 적용 실패, 건너뜀: X has 7 features, but SimpleImputer is expecting 3 features as input.\n",
      "✅ 최종 특성 형태: (1, 7)\n",
      "✅ 최종 특성명 일치: True\n",
      "🔍 전처리된 특성 형태: (1, 7)\n",
      "🔍 전처리된 특성명: ['ethnicity', 'prior_treatment', 'treatments_radiation_treatment_type', 'treatments_radiation_treatment_intent_type', 'laterality', 'site_of_resection_or_biopsy', 'tissue_or_organ_of_origin']\n",
      "\n",
      "🔄 Cox 모델 예측 중...\n",
      "✅ Cox: 예측값 = 0.1227\n",
      "\n",
      "🔄 RSF 모델 예측 중...\n",
      "   - 모델 타입: RandomSurvivalForest\n",
      "   - 입력 특성 수: 7\n",
      "✅ RSF: 예측값 = 129.3484\n",
      "\n",
      "🔄 GBSA 모델 예측 중...\n",
      "   - 모델 타입: GradientBoostingSurvivalAnalysis\n",
      "   - 입력 특성 수: 7\n",
      "✅ GBSA: 예측값 = 0.2332\n",
      "✅ CDSS 호환성 테스트 완료\n",
      "📁 시각화 결과 저장: ovarian_cancer_survival_analysis_xai_cdss.png\n",
      "\n",
      "💾 CDSS 호환 모델 저장\n",
      "✅ Cox 모델 저장: cdss_ovarian_cancer_survival_cox_model.pkl\n",
      "✅ RSF 모델 저장: cdss_ovarian_cancer_survival_rsf_model.pkl\n",
      "✅ GBSA 모델 저장: cdss_ovarian_cancer_survival_gbsa_model.pkl\n",
      "✅ 전체 파이프라인 저장: cdss_ovarian_cancer_survival_complete_pipeline.pkl\n",
      "\n",
      "📋 최종 보고서 생성\n",
      "\n",
      "================================================================================\n",
      "난소암 생존 예측 모델 분석 보고서 (CDSS 호환 + XAI)\n",
      "================================================================================\n",
      "\n",
      "📊 데이터 개요:\n",
      "- 총 환자 수: 583명\n",
      "- 사망 환자: 349명\n",
      "- 사망률: 59.9%\n",
      "- 중간 추적 기간: 1000일\n",
      "\n",
      "🎯 모델 성능 요약 (C-index):\n",
      "\n",
      "Cox:\n",
      "  - Train: C-index = 0.522\n",
      "  - Validation: C-index = 0.451\n",
      "  - Test: C-index = 0.513\n",
      "\n",
      "RSF:\n",
      "  - Train: C-index = 0.531\n",
      "  - Validation: C-index = 0.470\n",
      "  - Test: C-index = 0.522\n",
      "\n",
      "GBSA:\n",
      "  - Train: C-index = 0.538\n",
      "  - Validation: C-index = 0.489\n",
      "  - Test: C-index = 0.527\n",
      "\n",
      "🔬 CDSS 호환성:\n",
      "- 모든 모델이 CDSS 호환 형태로 래핑됨\n",
      "- 특정 환자 (TCGA-30-1714) 홀드아웃 테스트 완료\n",
      "- 실시간 생존 예측 가능\n",
      "\n",
      "🧠 설명 가능 AI (XAI):\n",
      "- SHAP 설명기 구현 완료 (또는 Permutation Importance)\n",
      "- LIME 설명기 구현 완료\n",
      "- 특성 중요도 분석 완료\n",
      "\n",
      "💾 저장된 파일:\n",
      "- 모델 파일: cdss_ovarian_cancer_survival_*_model.pkl\n",
      "- 전체 파이프라인: cdss_ovarian_cancer_survival_complete_pipeline.pkl\n",
      "- 시각화 결과: ovarian_cancer_survival_analysis_xai_cdss.png\n",
      "- XAI 시각화: shap_*.png, lime_*.png\n",
      "\n",
      "⏰ 분석 완료 시간: 2025-06-22 15:55:01\n",
      "================================================================================\n",
      "\n",
      "✅ 보고서 저장: ovarian_cancer_survival_analysis_report.txt\n",
      "\n",
      "🎉 난소암 생존 예측 모델 분석 완료!\n",
      "✅ 모든 결과가 저장되었습니다.\n",
      "\n",
      "🎯 분석 결과 요약:\n",
      "- 4개의 CDSS 호환 생존 예측 모델 생성 완료\n",
      "  * Cox 비례위험모델 (scikit-survival)\n",
      "  * Random Survival Forest\n",
      "  * Gradient Boosting Survival Analysis\n",
      "  * Cox 비례위험모델 (lifelines)\n",
      "- XAI 설명 가능 AI 구현 완료\n",
      "- 특정 환자 홀드아웃 테스트 완료\n",
      "- 실시간 생존 예측 시스템 준비 완료\n",
      "- 모든 결과 파일 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import pickle\n",
    "\n",
    "# 생존 분석 라이브러리\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored, integrated_brier_score\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "def setup_korean_font():\n",
    "    \"\"\"한글 폰트 설정\"\"\"\n",
    "    import platform\n",
    "    import matplotlib.font_manager as fm\n",
    "    \n",
    "    system = platform.system()\n",
    "    \n",
    "    if system == 'Windows':\n",
    "        try:\n",
    "            plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "        except:\n",
    "            try:\n",
    "                font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            except:\n",
    "                print(\"⚠️ 한글 폰트 설정 실패\")\n",
    "    elif system == 'Darwin':\n",
    "        plt.rcParams['font.family'] = 'AppleGothic'\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(\"✅ 한글 폰트 설정 완료\")\n",
    "\n",
    "class OvarianCancerSurvivalPredictor:\n",
    "    \"\"\"난소암 생존 예측 모델 클래스 (XAI 포함, CDSS 호환)\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, holdout_barcode=\"TCGA-30-1714\"):\n",
    "        setup_korean_font()\n",
    "        self.data_path = data_path\n",
    "        self.holdout_barcode = holdout_barcode\n",
    "        self.df = None\n",
    "        self.processed_df = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.feature_names = []\n",
    "        self.scaler = None\n",
    "        self.label_encoders = {}\n",
    "        self.shap_explainers = {}\n",
    "        self.shap_values = {}\n",
    "        self.lime_explainers = {}\n",
    "        self.holdout_patient = None  # CDSS 테스트용 환자\n",
    "        \n",
    "        print(f\"🚀 난소암 생존 예측 모델 초기화 (XAI + CDSS 호환)\")\n",
    "        print(f\"📁 데이터 경로: {data_path}\")\n",
    "        print(f\"🔍 홀드아웃 환자: {holdout_barcode}\")\n",
    "        print(f\"⏰ 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"데이터 로드 및 탐색적 분석\"\"\"\n",
    "        print(\"\\n📊 1. 데이터 로드 및 탐색\")\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "            print(f\"✅ 데이터 로드 성공: {self.df.shape[0]}행 × {self.df.shape[1]}열\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # 기본 정보 출력\n",
    "        print(f\"📈 데이터 기본 정보:\")\n",
    "        print(f\"   - 총 환자 수: {len(self.df)}\")\n",
    "        print(f\"   - 총 컬럼 수: {len(self.df.columns)}\")\n",
    "        \n",
    "        # 생존 상태 분포\n",
    "        if 'vital_status' in self.df.columns:\n",
    "            status_counts = self.df['vital_status'].value_counts()\n",
    "            print(f\"   - 생존 환자: {status_counts.get('Alive', 0)}명\")\n",
    "            print(f\"   - 사망 환자: {status_counts.get('Dead', 0)}명\")\n",
    "            print(f\"   - 사망률: {status_counts.get('Dead', 0)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        print(\"\\n🔧 2. 데이터 전처리\")\n",
    "        \n",
    "        # 난소암 생존 예측용 선택된 컬럼들\n",
    "        selected_columns = [\n",
    "            # 생존 결과 변수 (필수)\n",
    "            'vital_status', 'days_to_death', 'days_to_last_follow_up', 'year_of_diagnosis',\n",
    "            \n",
    "            # 병기 관련 (가장 중요한 예후 인자)\n",
    "            'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'figo_staging_edition_year',\n",
    "            \n",
    "            # 종양 특성\n",
    "            'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease',\n",
    "            'classification_of_tumor',\n",
    "            \n",
    "            # 환자 기본 정보\n",
    "            'age_at_diagnosis', 'gender', 'race', 'ethnicity',\n",
    "            \n",
    "            # 치료 및 병력\n",
    "            'prior_treatment', 'prior_malignancy', 'synchronous_malignancy',\n",
    "            \n",
    "            # 치료 관련 (결측치 적은 것만)\n",
    "            'treatments_pharmaceutical_treatment_type', 'treatments_pharmaceutical_treatment_intent_type',\n",
    "            'treatments_radiation_treatment_type', 'treatments_radiation_treatment_intent_type',\n",
    "            \n",
    "            # 해부학적/진단 관련\n",
    "            'laterality', 'site_of_resection_or_biopsy', 'tissue_or_organ_of_origin',\n",
    "            'method_of_diagnosis',\n",
    "            \n",
    "            # 시간 관련 변수\n",
    "            'days_to_diagnosis', 'days_to_last_known_disease_status',\n",
    "            \n",
    "            # 예후 관련 (매우 중요)\n",
    "            'last_known_disease_status', 'days_to_recurrence', 'progression_or_recurrence',\n",
    "            \n",
    "            # 치료 결과 관련\n",
    "            'treatments_pharmaceutical_treatment_outcome', 'treatments_radiation_treatment_outcome',\n",
    "            \n",
    "            # 치료 세부 정보\n",
    "            'treatments_pharmaceutical_days_to_treatment_start', 'treatments_pharmaceutical_days_to_treatment_end',\n",
    "            'treatments_pharmaceutical_number_of_cycles', 'treatments_radiation_days_to_treatment_start',\n",
    "            \n",
    "            # 종양 관련\n",
    "            'tumor_of_origin',\n",
    "            \n",
    "            # 시스템 정보\n",
    "            'ajcc_staging_system_edition', 'year_of_birth', 'year_of_death',\n",
    "            \n",
    "            # 환자 식별자\n",
    "            'bcr_patient_barcode'\n",
    "        ]\n",
    "        \n",
    "        # 존재하는 컬럼만 선택\n",
    "        available_columns = [col for col in selected_columns if col in self.df.columns]\n",
    "        missing_columns = [col for col in selected_columns if col not in self.df.columns]\n",
    "        \n",
    "        print(f\"✅ 사용 가능한 컬럼: {len(available_columns)}개\")\n",
    "        if missing_columns:\n",
    "            print(f\"⚠️  누락된 컬럼: {missing_columns}\")\n",
    "        \n",
    "        self.processed_df = self.df[available_columns].copy()\n",
    "        \n",
    "        # Series 객체를 단일 값으로 변환하는 함수\n",
    "        def extract_first_value(x):\n",
    "            if isinstance(x, pd.Series):\n",
    "                return x.iloc[0] if len(x) > 0 else np.nan\n",
    "            else:\n",
    "                return x\n",
    "        \n",
    "        # days_to_last_follow_up 컬럼 내 Series 객체를 단일 값으로 변환\n",
    "        if 'days_to_last_follow_up' in self.processed_df.columns:\n",
    "            self.processed_df['days_to_last_follow_up'] = self.processed_df['days_to_last_follow_up'].apply(extract_first_value)\n",
    "        \n",
    "        # 생존 시간 및 이벤트 변수 생성\n",
    "        print(\"🔄 생존 변수 생성 중...\")\n",
    "        self.processed_df['event'] = (self.processed_df['vital_status'] == 'Dead').astype(int)\n",
    "        \n",
    "        # 생존 시간 계산 (Series 처리 포함)\n",
    "        def calculate_duration(row):\n",
    "            death_day = row['days_to_death']\n",
    "            followup_day = row['days_to_last_follow_up']\n",
    "            \n",
    "            # death_day가 Series인지 확인하고 처리\n",
    "            if isinstance(death_day, pd.Series):\n",
    "                death_day = death_day.iloc[0] if len(death_day) > 0 else np.nan\n",
    "            \n",
    "            # followup_day가 Series인지 확인하고 처리\n",
    "            if isinstance(followup_day, pd.Series):\n",
    "                followup_day = followup_day.iloc[0] if len(followup_day) > 0 else np.nan\n",
    "            \n",
    "            if pd.notna(death_day):\n",
    "                return death_day\n",
    "            elif pd.notna(followup_day):\n",
    "                return followup_day\n",
    "            else:\n",
    "                return np.nan\n",
    "        \n",
    "        self.processed_df['duration'] = self.processed_df.apply(calculate_duration, axis=1)\n",
    "        \n",
    "        # 유효하지 않은 생존 시간 제거\n",
    "        valid_mask = (pd.notna(self.processed_df['duration'])) & (self.processed_df['duration'] > 0)\n",
    "        self.processed_df = self.processed_df[valid_mask].copy()\n",
    "        \n",
    "        print(f\"✅ 유효한 생존 데이터: {len(self.processed_df)}명\")\n",
    "        print(f\"   - 사망 이벤트: {self.processed_df['event'].sum()}건\")\n",
    "        print(f\"   - 중간 생존 시간: {self.processed_df['duration'].median():.0f}일\")\n",
    "        \n",
    "        # 결측값 분석\n",
    "        print(\"\\n📋 결측값 분석:\")\n",
    "        missing_analysis = self.processed_df.isnull().sum()\n",
    "        missing_percent = (missing_analysis / len(self.processed_df) * 100).round(1)\n",
    "        \n",
    "        for col in missing_analysis[missing_analysis > 0].index:\n",
    "            print(f\"   - {col}: {missing_analysis[col]}개 ({missing_percent[col]}%)\")\n",
    "        \n",
    "        # 높은 결측률 컬럼 제거 (80% 이상)\n",
    "        high_missing_cols = missing_percent[missing_percent > 80].index.tolist()\n",
    "        if high_missing_cols:\n",
    "            print(f\"🗑️  높은 결측률 컬럼 제거: {high_missing_cols}\")\n",
    "            self.processed_df = self.processed_df.drop(columns=high_missing_cols)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"특성 준비 및 인코딩 (CDSS 호환)\"\"\"\n",
    "        print(\"\\n🎯 3. 특성 준비 및 인코딩\")\n",
    "        \n",
    "        # 🔥 특정 환자 홀드아웃 (TCGA-30-1714)\n",
    "        print(f\"🔄 특정 환자 홀드아웃 중: {self.holdout_barcode}\")\n",
    "        \n",
    "        if 'bcr_patient_barcode' in self.processed_df.columns:\n",
    "            holdout_mask = self.processed_df['bcr_patient_barcode'] == self.holdout_barcode\n",
    "            \n",
    "            if holdout_mask.any():\n",
    "                self.holdout_patient = self.processed_df[holdout_mask].copy()\n",
    "                remaining_df = self.processed_df[~holdout_mask].copy()\n",
    "                print(f\"✅ 홀드아웃 환자 발견: {self.holdout_barcode}\")\n",
    "                print(f\"   - 홀드아웃 환자: 1명\")\n",
    "                print(f\"   - 모델 훈련용 데이터: {len(remaining_df)}명\")\n",
    "            else:\n",
    "                print(f\"⚠️ 홀드아웃 환자 {self.holdout_barcode}를 찾을 수 없습니다.\")\n",
    "                print(\"🔄 랜덤 홀드아웃으로 대체...\")\n",
    "                holdout_idx = self.processed_df.sample(n=1, random_state=42).index[0]\n",
    "                self.holdout_patient = self.processed_df.loc[holdout_idx:holdout_idx].copy()\n",
    "                remaining_df = self.processed_df.drop(holdout_idx).copy()\n",
    "                print(f\"   - 랜덤 홀드아웃 환자: {holdout_idx}\")\n",
    "                print(f\"   - 모델 훈련용 데이터: {len(remaining_df)}명\")\n",
    "        else:\n",
    "            print(\"⚠️ bcr_patient_barcode 컬럼이 없습니다. 랜덤 홀드아웃으로 진행...\")\n",
    "            holdout_idx = self.processed_df.sample(n=1, random_state=42).index[0]\n",
    "            self.holdout_patient = self.processed_df.loc[holdout_idx:holdout_idx].copy()\n",
    "            remaining_df = self.processed_df.drop(holdout_idx).copy()\n",
    "        \n",
    "        # 특성과 타겟 분리 (bcr_patient_barcode 제외)\n",
    "        feature_cols = [col for col in remaining_df.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'bcr_patient_barcode']]\n",
    "        \n",
    "        X = remaining_df[feature_cols].copy()\n",
    "        y_duration = remaining_df['duration'].values\n",
    "        y_event = remaining_df['event'].values.astype(bool)\n",
    "        \n",
    "        print(f\"📊 초기 특성 개수: {len(feature_cols)}\")\n",
    "        print(f\"📊 샘플 개수: {len(X)}\")\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        print(f\"🔤 범주형 변수: {len(categorical_cols)}개\")\n",
    "        print(f\"🔢 수치형 변수: {len(numerical_cols)}개\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        print(\"🔄 결측값 처리 중...\")\n",
    "        \n",
    "        # 수치형 변수: 중앙값으로 대체\n",
    "        if numerical_cols:\n",
    "            self.num_imputer = SimpleImputer(strategy='median')\n",
    "            X[numerical_cols] = self.num_imputer.fit_transform(X[numerical_cols])\n",
    "            print(f\"✅ Imputer 훈련 완료: {len(numerical_cols)}개 수치형 변수\")\n",
    "        \n",
    "        # 임상적으로 의미있는 Unknown 값을 가질 수 있는 컬럼들 (난소암 특화)\n",
    "        meaningful_unknown_cols = [\n",
    "            'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease',\n",
    "            'classification_of_tumor', 'prior_malignancy', 'synchronous_malignancy',\n",
    "            'prior_treatment', 'treatments_pharmaceutical_treatment_type',\n",
    "            'treatments_pharmaceutical_treatment_intent_type', 'treatments_radiation_treatment_type',\n",
    "            'treatments_radiation_treatment_intent_type', 'last_known_disease_status',\n",
    "            'progression_or_recurrence', 'treatments_pharmaceutical_treatment_outcome',\n",
    "            'treatments_radiation_treatment_outcome'\n",
    "        ]\n",
    "        \n",
    "        self.label_encoders = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col in X.columns:\n",
    "                print(f\"\\n   🔍 {col} 처리:\")\n",
    "                \n",
    "                # 현재 값 분포 확인\n",
    "                value_counts = X[col].value_counts(dropna=False)\n",
    "                print(f\"      - 전처리 전 분포: {dict(list(value_counts.items())[:3])}\")\n",
    "                \n",
    "                # 'NA' 문자열을 결측치로 변환\n",
    "                if 'NA' in X[col].values:\n",
    "                    X[col] = X[col].replace('NA', np.nan)\n",
    "                    print(f\"      - 'NA' 문자열을 결측치로 변환\")\n",
    "                \n",
    "                # Unknown 값 처리 결정\n",
    "                try:\n",
    "                    # 문자열로 변환 후 contains 호출\n",
    "                    has_unknown = X[col].astype(str).str.contains('Unknown', na=False).any()\n",
    "                except Exception as e:\n",
    "                    print(f\"      - .str.contains 오류 발생, False로 설정: {e}\")\n",
    "                    has_unknown = False\n",
    "                \n",
    "                if has_unknown:\n",
    "                    if col in meaningful_unknown_cols:\n",
    "                        print(f\"      - 'Unknown' 값 유지 (임상적 의미 있음)\")\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "                    else:\n",
    "                        print(f\"      - 'Unknown' 값을 결측치로 변환 후 대체\")\n",
    "                        X[col] = X[col].replace('Unknown', np.nan)\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "                else:\n",
    "                    if X[col].isnull().any():\n",
    "                        mode_value = X[col].mode()\n",
    "                        if not mode_value.empty:\n",
    "                            fill_value = mode_value[0]\n",
    "                            X[col] = X[col].fillna(fill_value)\n",
    "                            print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "        \n",
    "        # 모든 범주형 변수 인코딩\n",
    "        print(\"\\n🔄 범주형 변수 인코딩:\")\n",
    "        all_categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        for col in all_categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "            \n",
    "            if col in meaningful_unknown_cols:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"   - {col} 인코딩 매핑: {mapping}\")\n",
    "        \n",
    "        # 다중공선성 해결\n",
    "        print(\"\\n🔍 다중공선성 검사 및 해결:\")\n",
    "        \n",
    "        # 1. 분산이 0인 특성 제거\n",
    "        zero_var_features = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "        if zero_var_features:\n",
    "            print(f\"🗑️  분산 0인 특성 제거: {zero_var_features}\")\n",
    "            X = X.drop(columns=zero_var_features)\n",
    "        \n",
    "        # 2. 높은 상관관계 특성 제거\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        high_corr_features = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "        \n",
    "        if high_corr_features:\n",
    "            print(f\"🗑️  높은 상관관계 특성 제거 (>0.9): {high_corr_features}\")\n",
    "            X = X.drop(columns=high_corr_features)\n",
    "        \n",
    "        # 3. VIF 검사\n",
    "        try:\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"특성\"] = X.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "            \n",
    "            high_vif_features = vif_data[vif_data[\"VIF\"] > 10][\"특성\"].tolist()\n",
    "            if high_vif_features:\n",
    "                print(f\"🗑️  높은 VIF 특성 제거 (>10): {high_vif_features}\")\n",
    "                X = X.drop(columns=high_vif_features)\n",
    "                \n",
    "            print(f\"✅ VIF 검사 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  VIF 검사 건너뜀: {e}\")\n",
    "        \n",
    "        print(f\"📊 최종 특성 개수: {len(X.columns)}\")\n",
    "        \n",
    "        # 특성 스케일링\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        self.feature_names = X_scaled.columns.tolist()\n",
    "        \n",
    "        # scikit-survival 형식으로 변환\n",
    "        y_structured = np.array([(event, duration) for event, duration in zip(y_event, y_duration)],\n",
    "                               dtype=[('event', '?'), ('time', '<f8')])\n",
    "        \n",
    "        print(\"✅ 특성 준비 완료 (CDSS 호환)\")\n",
    "        \n",
    "        return X_scaled, y_structured, y_duration, y_event\n",
    "    \n",
    "    def split_data(self, X, y_structured, y_duration, y_event):\n",
    "        \"\"\"데이터 분할\"\"\"\n",
    "        print(\"\\n✂️  4. 데이터 분할 (훈련:검증:테스트 = 60:20:20)\")\n",
    "        \n",
    "        # 먼저 훈련+검증 vs 테스트로 분할\n",
    "        X_temp, X_test, y_temp_struct, y_test_struct, y_temp_dur, y_test_dur, y_temp_event, y_test_event = \\\n",
    "            train_test_split(X, y_structured, y_duration, y_event, \n",
    "                           test_size=0.2, random_state=42, stratify=y_event)\n",
    "        \n",
    "        # 훈련 vs 검증으로 분할\n",
    "        X_train, X_val, y_train_struct, y_val_struct, y_train_dur, y_val_dur, y_train_event, y_val_event = \\\n",
    "            train_test_split(X_temp, y_temp_struct, y_temp_dur, y_temp_event,\n",
    "                           test_size=0.25, random_state=42, stratify=y_temp_event)\n",
    "        \n",
    "        print(f\"📊 훈련 세트: {len(X_train)}명 (사망: {y_train_event.sum()}명)\")\n",
    "        print(f\"📊 검증 세트: {len(X_val)}명 (사망: {y_val_event.sum()}명)\")\n",
    "        print(f\"📊 테스트 세트: {len(X_test)}명 (사망: {y_test_event.sum()}명)\")\n",
    "        print(f\"📊 CDSS 테스트: 1명 (별도 보관)\")\n",
    "        \n",
    "        return (X_train, X_val, X_test, \n",
    "                y_train_struct, y_val_struct, y_test_struct,\n",
    "                y_train_dur, y_val_dur, y_test_dur,\n",
    "                y_train_event, y_val_event, y_test_event)\n",
    "    \n",
    "    def train_models(self, X_train, X_val, X_test, \n",
    "                    y_train_struct, y_val_struct, y_test_struct,\n",
    "                    y_train_dur, y_val_dur, y_test_dur,\n",
    "                    y_train_event, y_val_event, y_test_event):\n",
    "        \"\"\"모델 훈련 (CDSS 호환)\"\"\"\n",
    "        print(\"\\n🤖 5. 모델 훈련\")\n",
    "        \n",
    "        # 1. Cox 비례위험 모델 (scikit-survival)\n",
    "        print(\"🔄 Cox 비례위험 모델 훈련 중...\")\n",
    "        try:\n",
    "            cox_model = CoxPHSurvivalAnalysis(alpha=0.5)\n",
    "            cox_model.fit(X_train, y_train_struct)\n",
    "            self.models['Cox'] = cox_model\n",
    "            print(\"✅ Cox 모델 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Cox 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 2. Random Survival Forest (CDSS 호환 버전)\n",
    "        print(\"🔄 Random Survival Forest 훈련 중...\")\n",
    "        try:\n",
    "            rsf_model = RandomSurvivalForest(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=5,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rsf_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            # RSF 모델을 CDSS 호환 형태로 래핑\n",
    "            rsf_wrapper = {\n",
    "                'model': rsf_model,\n",
    "                'model_type': 'RandomSurvivalForest',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                },\n",
    "                'preprocessing_info': {\n",
    "                    'meaningful_unknown_cols': [\n",
    "                        'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "                        'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease',\n",
    "                        'classification_of_tumor', 'prior_malignancy', 'synchronous_malignancy',\n",
    "                        'prior_treatment', 'treatments_pharmaceutical_treatment_type',\n",
    "                        'treatments_pharmaceutical_treatment_intent_type', 'treatments_radiation_treatment_type'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['RSF'] = rsf_wrapper\n",
    "            print(\"✅ Random Survival Forest 훈련 완료 (CDSS 호환)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ RSF 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 3. Gradient Boosting Survival Analysis\n",
    "        print(\"🔄 Gradient Boosting Survival 훈련 중...\")\n",
    "        try:\n",
    "            gbsa_model = GradientBoostingSurvivalAnalysis(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=3,\n",
    "                random_state=42\n",
    "            )\n",
    "            gbsa_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            # GBSA 모델도 래핑\n",
    "            gbsa_wrapper = {\n",
    "                'model': gbsa_model,\n",
    "                'model_type': 'GradientBoostingSurvivalAnalysis',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                },\n",
    "                'preprocessing_info': {\n",
    "                    'meaningful_unknown_cols': [\n",
    "                        'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "                        'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease',\n",
    "                        'classification_of_tumor', 'prior_malignancy', 'synchronous_malignancy',\n",
    "                        'prior_treatment', 'treatments_pharmaceutical_treatment_type'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['GBSA'] = gbsa_wrapper\n",
    "            print(\"✅ Gradient Boosting Survival 훈련 완료 (CDSS 호환)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ GBSA 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 4. Cox 모델 (lifelines)\n",
    "        print(\"🔄 Lifelines Cox 모델 훈련 중...\")\n",
    "        try:\n",
    "            train_data = X_train.copy()\n",
    "            train_data['duration'] = y_train_dur\n",
    "            train_data['event'] = y_train_event\n",
    "            \n",
    "            cph = CoxPHFitter(penalizer=0.5)\n",
    "            cph.fit(train_data, duration_col='duration', event_col='event')\n",
    "            \n",
    "            # Lifelines Cox 모델도 래핑\n",
    "            cox_lifelines_wrapper = {\n",
    "                'model': cph,\n",
    "                'model_type': 'CoxPHFitter',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                },\n",
    "                'preprocessing_info': {\n",
    "                    'meaningful_unknown_cols': [\n",
    "                        'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "                        'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['Cox_lifelines'] = cox_lifelines_wrapper\n",
    "            print(\"✅ Lifelines Cox 모델 훈련 완료 (CDSS 호환)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lifelines Cox 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        print(f\"\\n🎯 총 {len(self.models)}개 모델 훈련 완료\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def explain_models(self, X_train, X_test):\n",
    "        \"\"\"XAI 모델 설명 생성 (수정된 버전)\"\"\"\n",
    "        print(\"\\n🔍 XAI 모델 설명 생성\")\n",
    "        \n",
    "        # SHAP 설명기 - Permutation Explainer 사용\n",
    "        print(\"🔄 SHAP 설명 생성 중...\")\n",
    "        if 'RSF' in self.models:\n",
    "            try:\n",
    "                rsf_model = self.models['RSF']['model']\n",
    "                X_test_sample = X_test.iloc[:50]\n",
    "                \n",
    "                # TreeExplainer 대신 Permutation Explainer 사용\n",
    "                explainer = shap.PermutationExplainer(\n",
    "                    rsf_model.predict, \n",
    "                    X_train.iloc[:100]  # 배경 데이터 샘플링\n",
    "                )\n",
    "                shap_values = explainer(X_test_sample)\n",
    "                \n",
    "                self.shap_explainers['RSF'] = explainer\n",
    "                self.shap_values['RSF'] = shap_values.values\n",
    "                print(\"✅ RSF SHAP 설명 생성 완료 (PermutationExplainer)\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ RSF SHAP 실패: {e}\")\n",
    "                # SHAP 실패 시 특성 중요도 대안 사용\n",
    "                try:\n",
    "                    # Permutation Importance 계산\n",
    "                    from sklearn.inspection import permutation_importance\n",
    "                    perm_importance = permutation_importance(\n",
    "                        rsf_model, X_test_sample, \n",
    "                        [y_test_struct[i] for i in X_test_sample.index],\n",
    "                        n_repeats=10, random_state=42\n",
    "                    )\n",
    "                    \n",
    "                    self.permutation_importance = {\n",
    "                        'importances': perm_importance.importances_mean,\n",
    "                        'feature_names': self.feature_names\n",
    "                    }\n",
    "                    print(\"✅ Permutation Importance 계산 완료 (SHAP 대안)\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"❌ Permutation Importance 실패: {e2}\")\n",
    "        \n",
    "        # LIME 설명기 초기화 (이진 분류로 변환)\n",
    "        print(\"\\n🔄 LIME 설명 생성 중...\")\n",
    "        if 'RSF' in self.models:\n",
    "            try:\n",
    "                # 생존 예측을 이진 분류로 변환하는 함수\n",
    "                def survival_to_binary_prob(X):\n",
    "                    rsf_model = self.models['RSF']['model']\n",
    "                    # 생존 함수 예측\n",
    "                    surv_funcs = rsf_model.predict_survival_function(X)\n",
    "                    # 5년(1825일) 생존 확률 계산\n",
    "                    probs_5year = []\n",
    "                    for surv_func in surv_funcs:\n",
    "                        try:\n",
    "                            prob_5year = surv_func(1825)  # 5년 생존 확률\n",
    "                        except:\n",
    "                            prob_5year = 0.5  # 기본값\n",
    "                        probs_5year.append(prob_5year)\n",
    "                    \n",
    "                    # 이진 분류 확률로 변환 (생존/사망)\n",
    "                    probs_5year = np.array(probs_5year)\n",
    "                    return np.column_stack([1 - probs_5year, probs_5year])\n",
    "                \n",
    "                explainer = lime_tabular.LimeTabularExplainer(\n",
    "                    training_data=X_train.values,\n",
    "                    feature_names=self.feature_names,\n",
    "                    class_names=['5년내 사망', '5년 생존'],\n",
    "                    mode='classification',\n",
    "                    discretize_continuous=True\n",
    "                )\n",
    "                \n",
    "                self.lime_explainers['RSF'] = {\n",
    "                    'explainer': explainer,\n",
    "                    'predict_fn': survival_to_binary_prob\n",
    "                }\n",
    "                print(\"✅ RSF LIME 설명기 생성 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ RSF LIME 실패: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_xai_visualizations(self, X_test, sample_index=0):\n",
    "        \"\"\"XAI 시각화 생성 (SHAP 대안 포함)\"\"\"\n",
    "        print(\"\\n📊 XAI 시각화 생성\")\n",
    "        \n",
    "        # SHAP 시각화 (가능한 경우)\n",
    "        shap_figures = []\n",
    "        if 'RSF' in self.shap_explainers:\n",
    "            try:\n",
    "                shap_vals = self.shap_values['RSF']\n",
    "                \n",
    "                # Summary plot\n",
    "                plt.figure(figsize=(10,6))\n",
    "                shap.summary_plot(shap_vals, X_test.iloc[:50], \n",
    "                                feature_names=self.feature_names,\n",
    "                                plot_type=\"bar\", show=False)\n",
    "                plt.title(\"RSF 모델 특성 중요도 (SHAP)\")\n",
    "                shap_summary_path = \"shap_summary_RSF_ovarian.png\"\n",
    "                plt.savefig(shap_summary_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                shap_figures.append(shap_summary_path)\n",
    "                print(\"✅ SHAP 시각화 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ SHAP 시각화 실패: {e}\")\n",
    "        \n",
    "        # SHAP 실패 시 Permutation Importance 사용\n",
    "        elif hasattr(self, 'permutation_importance'):\n",
    "            try:\n",
    "                plt.figure(figsize=(10,6))\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': self.permutation_importance['feature_names'],\n",
    "                    'importance': self.permutation_importance['importances']\n",
    "                }).sort_values('importance', ascending=True).tail(10)\n",
    "                \n",
    "                plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "                plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "                plt.title(\"RSF 모델 특성 중요도 (Permutation Importance)\")\n",
    "                plt.xlabel(\"중요도\")\n",
    "                \n",
    "                perm_importance_path = \"permutation_importance_RSF_ovarian.png\"\n",
    "                plt.savefig(perm_importance_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                shap_figures.append(perm_importance_path)\n",
    "                print(\"✅ Permutation Importance 시각화 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Permutation Importance 시각화 실패: {e}\")\n",
    "        \n",
    "        # LIME 시각화\n",
    "        lime_figures = []\n",
    "        if 'RSF' in self.lime_explainers:\n",
    "            try:\n",
    "                lime_data = self.lime_explainers['RSF']\n",
    "                exp = lime_data['explainer'].explain_instance(\n",
    "                    X_test.iloc[sample_index].values,\n",
    "                    lime_data['predict_fn'],\n",
    "                    num_features=5\n",
    "                )\n",
    "                \n",
    "                lime_path = f\"lime_explanation_RSF_ovarian_{sample_index}.png\"\n",
    "                fig = exp.as_pyplot_figure()\n",
    "                plt.title(f\"RSF 모델 LIME 설명 (샘플 {sample_index})\")\n",
    "                plt.savefig(lime_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                lime_figures.append(lime_path)\n",
    "                print(\"✅ LIME 시각화 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ LIME 시각화 실패: {e}\")\n",
    "        \n",
    "        return shap_figures, lime_figures\n",
    "    \n",
    "    def evaluate_models(self, X_train, X_val, X_test,\n",
    "                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                       y_train_event, y_val_event, y_test_event):\n",
    "        \"\"\"모델 평가\"\"\"\n",
    "        print(\"\\n📈 6. 모델 평가\")\n",
    "        \n",
    "        datasets = {\n",
    "            'Train': (X_train, y_train_struct, y_train_dur, y_train_event),\n",
    "            'Validation': (X_val, y_val_struct, y_val_dur, y_val_event),\n",
    "            'Test': (X_test, y_test_struct, y_test_dur, y_test_event)\n",
    "        }\n",
    "        \n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            print(f\"\\n🔍 {model_name} 모델 평가:\")\n",
    "            self.results[model_name] = {}\n",
    "            \n",
    "            for dataset_name, (X, y_struct, y_dur, y_event) in datasets.items():\n",
    "                try:\n",
    "                    if model_name == 'Cox':\n",
    "                        # scikit-survival Cox 모델\n",
    "                        risk_scores = model_wrapper.predict(X)\n",
    "                        c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                    \n",
    "                    elif isinstance(model_wrapper, dict):\n",
    "                        # 래핑된 모델들\n",
    "                        actual_model = model_wrapper['model']\n",
    "                        \n",
    "                        if model_wrapper['model_type'] == 'CoxPHFitter':\n",
    "                            # Lifelines Cox 모델\n",
    "                            c_index = actual_model.concordance_index_\n",
    "                        else:\n",
    "                            # RSF, GBSA 모델\n",
    "                            risk_scores = actual_model.predict(X)\n",
    "                            c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                    \n",
    "                    else:\n",
    "                        # 기타 모델\n",
    "                        risk_scores = model_wrapper.predict(X)\n",
    "                        c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                    \n",
    "                    self.results[model_name][dataset_name] = {'c_index': c_index}\n",
    "                    print(f\"   {dataset_name}: C-index = {c_index:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ {dataset_name} 평가 실패: {e}\")\n",
    "                    self.results[model_name][dataset_name] = {'c_index': np.nan}\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def plot_survival_curves(self, X_test, y_test_dur, y_test_event):\n",
    "        \"\"\"생존 곡선 시각화 (XAI 포함)\"\"\"\n",
    "        print(\"\\n📊 7. 생존 곡선 시각화\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(25, 20))\n",
    "        gs = fig.add_gridspec(3, 3)\n",
    "        axes = [\n",
    "            fig.add_subplot(gs[0, 0]),  # 전체 생존 곡선\n",
    "            fig.add_subplot(gs[0, 1]),  # FIGO 병기별 생존 곡선\n",
    "            fig.add_subplot(gs[0, 2]),  # 모델 성능 비교\n",
    "            fig.add_subplot(gs[1, 0]),  # 특성 중요도 (Cox)\n",
    "            fig.add_subplot(gs[1, 1]),  # 특성 중요도 (GBSA)\n",
    "            fig.add_subplot(gs[1, 2]),  # CDSS 테스트 결과\n",
    "            fig.add_subplot(gs[2, :])   # XAI 시각화\n",
    "        ]\n",
    "        \n",
    "        fig.suptitle('난소암 환자 생존 분석 결과 (XAI + CDSS 호환)', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. 전체 Kaplan-Meier 생존 곡선\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(y_test_dur, y_test_event, label='전체 환자')\n",
    "        kmf.plot_survival_function(ax=axes[0])\n",
    "        axes[0].set_title('전체 환자 생존 곡선 (Kaplan-Meier)')\n",
    "        axes[0].set_ylabel('생존 확률')\n",
    "        axes[0].set_xlabel('시간 (일)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. FIGO 병기에 따른 생존 곡선\n",
    "        if 'figo_stage' in self.processed_df.columns:\n",
    "            test_indices = X_test.index\n",
    "            figo_data = self.processed_df.loc[test_indices, 'figo_stage'] if 'figo_stage' in self.processed_df.columns else None\n",
    "            \n",
    "            if figo_data is not None:\n",
    "                for stage in figo_data.unique():\n",
    "                    mask = (figo_data == stage)\n",
    "                    if mask.sum() > 5:\n",
    "                        kmf_stage = KaplanMeierFitter()\n",
    "                        kmf_stage.fit(y_test_dur[mask], y_test_event[mask], label=f'FIGO {stage}')\n",
    "                        kmf_stage.plot_survival_function(ax=axes[1])\n",
    "                \n",
    "                axes[1].set_title('FIGO 병기에 따른 생존 곡선')\n",
    "                axes[1].set_ylabel('생존 확률')\n",
    "                axes[1].set_xlabel('시간 (일)')\n",
    "                axes[1].grid(True, alpha=0.3)\n",
    "                axes[1].legend()\n",
    "        \n",
    "        # 3. 모델 성능 비교\n",
    "        model_names = list(self.results.keys())\n",
    "        test_c_indices = []\n",
    "        for name in model_names:\n",
    "            c_index = self.results[name]['Test']['c_index']\n",
    "            if not np.isnan(c_index):\n",
    "                test_c_indices.append(c_index)\n",
    "            else:\n",
    "                test_c_indices.append(0)\n",
    "        \n",
    "        bars = axes[2].bar(model_names, test_c_indices, \n",
    "                          color=['skyblue', 'lightcoral', 'lightgreen', 'gold'][:len(model_names)])\n",
    "        axes[2].set_title('모델별 C-index 성능 비교 (테스트 세트)')\n",
    "        axes[2].set_ylabel('C-index')\n",
    "        axes[2].set_ylim(0.5, 1.0)\n",
    "        axes[2].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, value in zip(bars, test_c_indices):\n",
    "            if value > 0:\n",
    "                axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 4-5. 특성 중요도\n",
    "        for idx, model_name in enumerate(['Cox_lifelines', 'GBSA']):\n",
    "            ax_idx = 3 + idx\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    if model_name == 'Cox_lifelines':\n",
    "                        # Cox 계수 기반 중요도\n",
    "                        cox_model = self.models[model_name]['model']\n",
    "                        coefficients = cox_model.params_\n",
    "                        importance_values = np.abs(coefficients.values)\n",
    "                        feature_names_cox = coefficients.index.tolist()\n",
    "                        \n",
    "                        feature_importance_df = pd.DataFrame({\n",
    "                            'feature': feature_names_cox,\n",
    "                            'importance': importance_values\n",
    "                        }).sort_values('importance', ascending=True).tail(10)\n",
    "                        \n",
    "                        color = 'lightcoral'\n",
    "                    else:\n",
    "                        # GBSA 특성 중요도\n",
    "                        gbsa_model = self.models[model_name]['model']\n",
    "                        if hasattr(gbsa_model, 'feature_importances_'):\n",
    "                            importance = gbsa_model.feature_importances_\n",
    "                            feature_importance_df = pd.DataFrame({\n",
    "                                'feature': self.feature_names,\n",
    "                                'importance': importance\n",
    "                            }).sort_values('importance', ascending=True).tail(10)\n",
    "                            color = 'lightgreen'\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "                    bars = axes[ax_idx].barh(range(len(feature_importance_df)), \n",
    "                                           feature_importance_df['importance'],\n",
    "                                           color=color)\n",
    "                    \n",
    "                    axes[ax_idx].set_yticks(range(len(feature_importance_df)))\n",
    "                    axes[ax_idx].set_yticklabels(feature_importance_df['feature'], fontsize=10)\n",
    "                    axes[ax_idx].set_title(f'특성 중요도 ({model_name})', fontsize=12, fontweight='bold')\n",
    "                    axes[ax_idx].set_xlabel('중요도')\n",
    "                    axes[ax_idx].grid(True, alpha=0.3, axis='x')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} 특성 중요도 시각화 실패: {e}\")\n",
    "        \n",
    "        # 6. CDSS 테스트 결과\n",
    "        self.test_cdss_compatibility(axes[5])\n",
    "        \n",
    "        # 7. XAI 시각화 로드\n",
    "        try:\n",
    "            img = plt.imread(\"shap_summary_RSF_ovarian.png\")\n",
    "            axes[6].imshow(img)\n",
    "            axes[6].axis('off')\n",
    "            axes[6].set_title('SHAP 전역 설명 (RSF 모델)', fontsize=12)\n",
    "        except Exception as e:\n",
    "            axes[6].text(0.5, 0.5, 'SHAP 시각화 불러오기 실패', \n",
    "                        ha='center', va='center', transform=axes[6].transAxes,\n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = \"ovarian_cancer_survival_analysis_xai_cdss.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"📁 시각화 결과 저장: {save_path}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def test_cdss_compatibility(self, ax):\n",
    "        \"\"\"CDSS 호환성 테스트 (수정된 버전)\"\"\"\n",
    "        print(\"\\n🔬 CDSS 호환성 테스트\")\n",
    "        \n",
    "        try:\n",
    "            # holdout 환자 데이터 전처리\n",
    "            holdout_features = self.preprocess_holdout_patient()\n",
    "            \n",
    "            print(f\"🔍 전처리된 특성 형태: {holdout_features.shape}\")\n",
    "            print(f\"🔍 전처리된 특성명: {list(holdout_features.columns)}\")\n",
    "            \n",
    "            # 각 모델로 예측 수행\n",
    "            predictions = {}\n",
    "            for model_name, model_wrapper in self.models.items():\n",
    "                try:\n",
    "                    print(f\"\\n🔄 {model_name} 모델 예측 중...\")\n",
    "                    \n",
    "                    if model_name == 'Cox':\n",
    "                        # scikit-survival Cox 모델\n",
    "                        pred = model_wrapper.predict(holdout_features)[0]\n",
    "                        \n",
    "                    elif isinstance(model_wrapper, dict):\n",
    "                        # 래핑된 모델들\n",
    "                        actual_model = model_wrapper['model']\n",
    "                        model_type = model_wrapper['model_type']\n",
    "                        \n",
    "                        print(f\"   - 모델 타입: {model_type}\")\n",
    "                        print(f\"   - 입력 특성 수: {holdout_features.shape[1]}\")\n",
    "                        \n",
    "                        if model_type == 'CoxPHFitter':\n",
    "                            # Lifelines Cox 모델 - DataFrame 형태로 예측\n",
    "                            holdout_df = holdout_features.copy()\n",
    "                            pred = actual_model.predict_partial_hazard(holdout_df).values[0]\n",
    "                        else:\n",
    "                            # RSF, GBSA 모델\n",
    "                            pred = actual_model.predict(holdout_features)[0]\n",
    "                    else:\n",
    "                        # 기타 모델\n",
    "                        pred = model_wrapper.predict(holdout_features)[0]\n",
    "                    \n",
    "                    predictions[model_name] = pred\n",
    "                    print(f\"✅ {model_name}: 예측값 = {pred:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} 예측 실패: {e}\")\n",
    "                    predictions[model_name] = np.nan\n",
    "            \n",
    "            # 결과 시각화\n",
    "            valid_predictions = {k: v for k, v in predictions.items() if not np.isnan(v)}\n",
    "            \n",
    "            if valid_predictions:\n",
    "                model_names = list(valid_predictions.keys())\n",
    "                pred_values = list(valid_predictions.values())\n",
    "                \n",
    "                bars = ax.bar(model_names, pred_values, \n",
    "                            color=['skyblue', 'lightcoral', 'lightgreen', 'gold'][:len(model_names)])\n",
    "                ax.set_title(f'CDSS 호환성 테스트\\n(Holdout 환자: {self.holdout_barcode})')\n",
    "                ax.set_ylabel('위험도 점수')\n",
    "                ax.grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "                for bar, value in zip(bars, pred_values):\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "                \n",
    "                print(\"✅ CDSS 호환성 테스트 완료\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'CDSS 테스트 실패\\n모든 모델 예측 오류', \n",
    "                    ha='center', va='center', transform=ax.transAxes,\n",
    "                    fontsize=12, fontweight='bold')\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ CDSS 호환성 테스트 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            ax.text(0.5, 0.5, f'CDSS 테스트 오류\\n{str(e)[:50]}...', \n",
    "                ha='center', va='center', transform=ax.transAxes,\n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    def preprocess_holdout_patient(self):\n",
    "        \"\"\"Holdout 환자 데이터 전처리 (특성명 완전 정렬)\"\"\"\n",
    "        print(\"\\n🔧 Holdout 환자 전처리 시작\")\n",
    "        \n",
    "        # 1. 원본 holdout 환자 데이터에서 모든 특성 추출\n",
    "        all_feature_cols = [col for col in self.holdout_patient.columns \n",
    "                        if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                        'event', 'duration', 'bcr_patient_barcode']]\n",
    "        \n",
    "        patient_raw = self.holdout_patient[all_feature_cols].copy()\n",
    "        print(f\"🔍 원본 환자 특성: {len(patient_raw.columns)}개\")\n",
    "        print(f\"🔍 모델 훈련 특성: {len(self.feature_names)}개\")\n",
    "        \n",
    "        # 2. 모델 훈련 시 사용한 특성명과 정확히 일치하는 DataFrame 생성\n",
    "        patient_processed = pd.DataFrame(index=patient_raw.index)\n",
    "        \n",
    "        # 🔥 핵심: 훈련 시 사용한 특성 순서대로 정확히 생성\n",
    "        for feature_name in self.feature_names:\n",
    "            if feature_name in patient_raw.columns:\n",
    "                # 특성이 존재하는 경우 복사\n",
    "                patient_processed[feature_name] = patient_raw[feature_name].copy()\n",
    "                print(f\"✅ {feature_name}: 원본 데이터 사용\")\n",
    "            else:\n",
    "                # 특성이 없는 경우 기본값 설정\n",
    "                patient_processed[feature_name] = 0.0  # float 타입으로 설정\n",
    "                print(f\"⚠️ {feature_name}: 기본값(0.0) 설정\")\n",
    "        \n",
    "        # 3. 범주형 변수 전처리 (훈련 시와 동일한 방식)\n",
    "        print(\"\\n🔄 범주형 변수 전처리:\")\n",
    "        for col, encoder in self.label_encoders.items():\n",
    "            if col in patient_processed.columns:\n",
    "                try:\n",
    "                    original_value = patient_processed[col].iloc[0]\n",
    "                    print(f\"   - {col}: 원본값 = {original_value}\")\n",
    "                    \n",
    "                    # 문자열 처리\n",
    "                    if pd.isna(original_value) or original_value == 'NA':\n",
    "                        # 결측치는 첫 번째 클래스로 대체\n",
    "                        patient_processed[col] = encoder.classes_[0]\n",
    "                        print(f\"     → 결측치를 '{encoder.classes_[0]}'로 대체\")\n",
    "                    else:\n",
    "                        # 문자열로 변환 후 인코딩\n",
    "                        str_value = str(original_value)\n",
    "                        if str_value in encoder.classes_:\n",
    "                            patient_processed[col] = encoder.transform([str_value])[0]\n",
    "                            print(f\"     → 인코딩: '{str_value}' → {patient_processed[col].iloc[0]}\")\n",
    "                        else:\n",
    "                            # 새로운 카테고리는 첫 번째 클래스로 대체\n",
    "                            patient_processed[col] = encoder.transform([encoder.classes_[0]])[0]\n",
    "                            print(f\"     → 새로운 값 '{str_value}'을 '{encoder.classes_[0]}'로 대체\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"     ❌ {col} 인코딩 실패: {e}\")\n",
    "                    patient_processed[col] = 0.0\n",
    "        \n",
    "        # 4. 🔥 중요: 모든 컬럼을 수치형으로 변환\n",
    "        print(\"\\n🔢 데이터 타입 변환:\")\n",
    "        for col in patient_processed.columns:\n",
    "            try:\n",
    "                patient_processed[col] = pd.to_numeric(patient_processed[col], errors='coerce')\n",
    "                if patient_processed[col].isnull().any():\n",
    "                    patient_processed[col] = patient_processed[col].fillna(0.0)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {col} 수치형 변환 실패: {e}\")\n",
    "                patient_processed[col] = 0.0\n",
    "        \n",
    "        print(f\"✅ 모든 컬럼 수치형 변환 완료\")\n",
    "        \n",
    "        # 5. 🔥 핵심: 특성 순서를 훈련 시와 정확히 일치시키기\n",
    "        patient_processed = patient_processed[self.feature_names]\n",
    "        print(f\"✅ 특성 순서 정렬 완료: {patient_processed.shape}\")\n",
    "        \n",
    "        # 6. 수치형 변수 전처리 (이제 모든 컬럼이 수치형)\n",
    "        if hasattr(self, 'num_imputer'):\n",
    "            print(f\"\\n📏 Imputer 적용:\")\n",
    "            print(f\"   - 입력 형태: {patient_processed.shape}\")\n",
    "            print(f\"   - 입력 특성명: {list(patient_processed.columns)}\")\n",
    "            \n",
    "            try:\n",
    "                # 🔥 핵심: 특성명 정보 제거하고 numpy 배열로 변환\n",
    "                patient_values = patient_processed.values\n",
    "                imputed_values = self.num_imputer.transform(patient_values)\n",
    "                \n",
    "                # DataFrame으로 다시 변환\n",
    "                patient_processed = pd.DataFrame(\n",
    "                    imputed_values,\n",
    "                    columns=self.feature_names,\n",
    "                    index=patient_processed.index\n",
    "                )\n",
    "                print(f\"✅ Imputer 적용 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Imputer 적용 실패, 건너뜀: {e}\")\n",
    "        \n",
    "        # 7. 스케일링 적용\n",
    "        try:\n",
    "            patient_values = patient_processed.values\n",
    "            scaled_values = self.scaler.transform(patient_values)\n",
    "            \n",
    "            # DataFrame으로 다시 변환\n",
    "            patient_features_scaled = pd.DataFrame(\n",
    "                scaled_values,\n",
    "                columns=self.feature_names,  # 정확한 특성명 사용\n",
    "                index=patient_processed.index\n",
    "            )\n",
    "            \n",
    "            print(f\"✅ 최종 특성 형태: {patient_features_scaled.shape}\")\n",
    "            print(f\"✅ 최종 특성명 일치: {list(patient_features_scaled.columns) == self.feature_names}\")\n",
    "            \n",
    "            return patient_features_scaled\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 스케일링 실패: {e}\")\n",
    "            # 스케일링 실패 시 원본 반환\n",
    "            return patient_processed\n",
    "    \n",
    "    def save_models_for_cdss(self):\n",
    "        \"\"\"CDSS 호환 모델 저장\"\"\"\n",
    "        print(\"\\n💾 CDSS 호환 모델 저장\")\n",
    "        \n",
    "        # 전체 파이프라인을 하나의 객체로 저장\n",
    "        cdss_pipeline = {\n",
    "            'models': self.models,\n",
    "            'scaler': self.scaler,\n",
    "            'label_encoders': self.label_encoders,\n",
    "            'feature_names': self.feature_names,\n",
    "            'holdout_patient': self.holdout_patient,\n",
    "            'holdout_barcode': self.holdout_barcode,\n",
    "            'preprocessing_info': {\n",
    "                'meaningful_unknown_cols': [\n",
    "                    'figo_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "                    'tumor_grade', 'morphology', 'primary_diagnosis', 'residual_disease',\n",
    "                    'classification_of_tumor', 'prior_malignancy', 'synchronous_malignancy',\n",
    "                    'prior_treatment', 'treatments_pharmaceutical_treatment_type',\n",
    "                    'treatments_pharmaceutical_treatment_intent_type', 'treatments_radiation_treatment_type'\n",
    "                ]\n",
    "            },\n",
    "            'metadata': {\n",
    "                'created_date': datetime.now().isoformat(),\n",
    "                'model_version': '2.0',\n",
    "                'description': 'TCGA-OV 난소암 생존 예측 모델 (CDSS 호환 + XAI)',\n",
    "                'model_types': ['Cox', 'RSF', 'GBSA', 'Cox_lifelines']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 개별 모델도 저장\n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            try:\n",
    "                filename = f\"cdss_ovarian_cancer_survival_{model_name.lower()}_model.pkl\"\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(model_wrapper, f)\n",
    "                print(f\"✅ {model_name} 모델 저장: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {model_name} 모델 저장 실패: {e}\")\n",
    "        \n",
    "        # 전체 파이프라인 저장\n",
    "        try:\n",
    "            pipeline_filename = \"cdss_ovarian_cancer_survival_complete_pipeline.pkl\"\n",
    "            with open(pipeline_filename, 'wb') as f:\n",
    "                pickle.dump(cdss_pipeline, f)\n",
    "            print(f\"✅ 전체 파이프라인 저장: {pipeline_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파이프라인 저장 실패: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_final_report(self):\n",
    "        \"\"\"최종 보고서 생성\"\"\"\n",
    "        print(\"\\n📋 최종 보고서 생성\")\n",
    "        \n",
    "        report = f\"\"\"\n",
    "{'='*80}\n",
    "난소암 생존 예측 모델 분석 보고서 (CDSS 호환 + XAI)\n",
    "{'='*80}\n",
    "\n",
    "📊 데이터 개요:\n",
    "- 총 환자 수: {len(self.processed_df)}명\n",
    "- 사망 환자: {self.processed_df['event'].sum()}명\n",
    "- 사망률: {self.processed_df['event'].mean()*100:.1f}%\n",
    "- 중간 추적 기간: {self.processed_df['duration'].median():.0f}일\n",
    "\n",
    "🎯 모델 성능 요약 (C-index):\n",
    "\"\"\"\n",
    "        \n",
    "        for model_name, results in self.results.items():\n",
    "            report += f\"\\n{model_name}:\\n\"\n",
    "            for dataset, metrics in results.items():\n",
    "                c_index = metrics.get('c_index', 'N/A')\n",
    "                if isinstance(c_index, float):\n",
    "                    report += f\"  - {dataset}: C-index = {c_index:.3f}\\n\"\n",
    "                else:\n",
    "                    report += f\"  - {dataset}: C-index = {c_index}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "🔬 CDSS 호환성:\n",
    "- 모든 모델이 CDSS 호환 형태로 래핑됨\n",
    "- 특정 환자 ({self.holdout_barcode}) 홀드아웃 테스트 완료\n",
    "- 실시간 생존 예측 가능\n",
    "\n",
    "🧠 설명 가능 AI (XAI):\n",
    "- SHAP 설명기 구현 완료 (또는 Permutation Importance)\n",
    "- LIME 설명기 구현 완료\n",
    "- 특성 중요도 분석 완료\n",
    "\n",
    "💾 저장된 파일:\n",
    "- 모델 파일: cdss_ovarian_cancer_survival_*_model.pkl\n",
    "- 전체 파이프라인: cdss_ovarian_cancer_survival_complete_pipeline.pkl\n",
    "- 시각화 결과: ovarian_cancer_survival_analysis_xai_cdss.png\n",
    "- XAI 시각화: shap_*.png, lime_*.png\n",
    "\n",
    "⏰ 분석 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "        \n",
    "        # 보고서 파일로 저장\n",
    "        with open(\"ovarian_cancer_survival_analysis_report.txt\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(report)\n",
    "        print(\"✅ 보고서 저장: ovarian_cancer_survival_analysis_report.txt\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"전체 분석 실행\"\"\"\n",
    "        print(\"🚀 난소암 생존 예측 모델 전체 분석 시작\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            # 1. 데이터 로드 및 탐색\n",
    "            if not self.load_and_explore_data():\n",
    "                return False\n",
    "            \n",
    "            # 2. 데이터 전처리\n",
    "            if not self.preprocess_data():\n",
    "                return False\n",
    "            \n",
    "            # 3. 특성 준비\n",
    "            X, y_structured, y_duration, y_event = self.prepare_features()\n",
    "            \n",
    "            # 4. 데이터 분할\n",
    "            (X_train, X_val, X_test, \n",
    "             y_train_struct, y_val_struct, y_test_struct,\n",
    "             y_train_dur, y_val_dur, y_test_dur,\n",
    "             y_train_event, y_val_event, y_test_event) = self.split_data(\n",
    "                X, y_structured, y_duration, y_event)\n",
    "            \n",
    "            # 5. 모델 훈련\n",
    "            if not self.train_models(X_train, X_val, X_test,\n",
    "                                   y_train_struct, y_val_struct, y_test_struct,\n",
    "                                   y_train_dur, y_val_dur, y_test_dur,\n",
    "                                   y_train_event, y_val_event, y_test_event):\n",
    "                return False\n",
    "            \n",
    "            # 6. 모델 평가\n",
    "            if not self.evaluate_models(X_train, X_val, X_test,\n",
    "                                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                                       y_train_event, y_val_event, y_test_event):\n",
    "                return False\n",
    "            \n",
    "            # 7. XAI 설명 생성\n",
    "            if not self.explain_models(X_train, X_test):\n",
    "                print(\"⚠️ XAI 설명 생성 실패, 계속 진행\")\n",
    "            \n",
    "            # 8. XAI 시각화 생성\n",
    "            shap_figures, lime_figures = self.generate_xai_visualizations(X_test, sample_index=0)\n",
    "            \n",
    "            # 9. 생존 곡선 시각화 (XAI + CDSS 포함)\n",
    "            if not self.plot_survival_curves(X_test, y_test_dur, y_test_event):\n",
    "                print(\"⚠️ 시각화 실패, 계속 진행\")\n",
    "            \n",
    "            # 10. CDSS 호환 모델 저장\n",
    "            if not self.save_models_for_cdss():\n",
    "                print(\"⚠️ 모델 저장 실패, 계속 진행\")\n",
    "            \n",
    "            # 11. 최종 보고서 생성\n",
    "            final_report = self.generate_final_report()\n",
    "            \n",
    "            print(\"\\n🎉 난소암 생존 예측 모델 분석 완료!\")\n",
    "            print(\"✅ 모든 결과가 저장되었습니다.\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 분석 중 오류 발생: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 파일 경로 설정\n",
    "    data_path = \"/Users/baeeunjeong/Library/CloudStorage/GoogleDrive-baeeunjeong00@gmail.com/.shortcut-targets-by-id/1aXfYtUWSYS8foz14MAJMhDH7IHhG1wNZ/2조/데이터/clinical model/ovarian/TCGA-OV_clinical_data.csv\"  # 실제 데이터 파일 경로로 변경\n",
    "    holdout_barcode = \"TCGA-30-1714\"  # 홀드아웃할 특정 환자\n",
    "    \n",
    "    # 분석 객체 생성 및 실행\n",
    "    analyzer = OvarianCancerSurvivalPredictor(data_path, holdout_barcode)\n",
    "    success = analyzer.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎯 분석 결과 요약:\")\n",
    "        print(\"- 4개의 CDSS 호환 생존 예측 모델 생성 완료\")\n",
    "        print(\"  * Cox 비례위험모델 (scikit-survival)\")\n",
    "        print(\"  * Random Survival Forest\")\n",
    "        print(\"  * Gradient Boosting Survival Analysis\")\n",
    "        print(\"  * Cox 비례위험모델 (lifelines)\")\n",
    "        print(\"- XAI 설명 가능 AI 구현 완료\")\n",
    "        print(\"- 특정 환자 홀드아웃 테스트 완료\")\n",
    "        print(\"- 실시간 생존 예측 시스템 준비 완료\")\n",
    "        print(\"- 모든 결과 파일 저장 완료\")\n",
    "    else:\n",
    "        print(\"\\n❌ 분석 실패\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a2696",
   "metadata": {},
   "source": [
    "## 📊 전체적인 성과 평가\n",
    "\n",
    "**기술적으로는 성공적이지만 임상적으로는 제한적인 결과**입니다. 모델이 정상 작동했지만 예측 성능이 낮아 실용성에 한계가 있습니다.\n",
    "\n",
    "## 🎯 모델 성능 분석 (C-index 기준)\n",
    "\n",
    "### **GBSA (최고 성능)**\n",
    "- **테스트 C-index: 0.527** - 랜덤보다 약간 나은 수준\n",
    "- **훈련 C-index: 0.538** - 과적합 없는 안정적 성능\n",
    "- **검증 성능: 0.489** - 일관된 성능 유지\n",
    "\n",
    "### **Random Survival Forest (균형잡힌 성능)**\n",
    "- **테스트 C-index: 0.522** - GBSA와 유사한 성능\n",
    "- **안정적 성능**: 훈련(0.531) → 검증(0.470) → 테스트(0.522)\n",
    "- **과적합 없음**: 가장 신뢰할 수 있는 모델\n",
    "\n",
    "### **Cox 모델 (기본 성능)**\n",
    "- **테스트 C-index: 0.513** - 가장 낮은 성능\n",
    "- **검증 성능 저하**: 0.451로 다소 불안정\n",
    "\n",
    "## 🔍 데이터 특성 분석\n",
    "\n",
    "### **데이터 품질 (우수)**\n",
    "- **TCGA-OV 데이터**: 실제 난소암 데이터 사용 ✅\n",
    "- **높은 사망률 59.9%**: 난소암의 현실적 예후 반영\n",
    "- **장기 추적 1,000일**: 약 2.7년간의 추적 데이터\n",
    "\n",
    "### **특성 선택의 한계**\n",
    "- **최종 특성 7개만 사용**: 다중공선성 제거로 대부분 특성 손실\n",
    "- **핵심 변수 제거**: FIGO 병기, 종양 등급 등 중요 변수 VIF로 제거\n",
    "- **제한된 예측력**: 7개 특성으로는 복잡한 생존 패턴 포착 어려움\n",
    "\n",
    "## 🚨 주요 문제점\n",
    "\n",
    "### **1. 낮은 예측 성능**\n",
    "- **C-index 0.52-0.53**: 임상적으로 의미있는 수준(0.7 이상)에 미달\n",
    "- **랜덤 수준**: 0.5에 가까운 성능으로 실용성 부족\n",
    "\n",
    "### **2. 핵심 바이오마커 누락**\n",
    "검색 결과에서 확인된 **난소암 생존 예측 핵심 요소들**:\n",
    "- **CA-125**: 종양표지자 변화 추이(KELIM) 계산의 핵심\n",
    "- **잔존 병변**: 수술 후 잔존 종양 여부 (가장 중요한 예후 인자)\n",
    "- **KELIM 점수**: 혈액검사 수치 변화로 50% 재발 위험 감소 예측 가능\n",
    "\n",
    "### **3. 다중공선성 과도 제거**\n",
    "- **VIF > 10 기준**: 너무 엄격한 기준으로 중요 변수 손실\n",
    "- **FIGO 병기 제거**: 난소암의 골드 스탠다드 예후 인자 손실\n",
    "\n",
    "## 🎯 국제 표준과의 비교\n",
    "\n",
    "검색 결과에 따른 **최신 연구 성능**:\n",
    "\n",
    "### **대만 연구 (2025년)**\n",
    "- **C-index 0.8-0.83**: 우수한 예측 성능\n",
    "- **주요 변수**: TNM 병기, CA-125, 잔존 종양, 종양 등급\n",
    "- **외부 검증**: SEER 데이터로 인종별 검증 완료\n",
    "\n",
    "### **KELIM 연구 (2023년)**\n",
    "- **재발 위험 50% 감소**: 종양표지자 변화 추이로 정확한 예측\n",
    "- **비용 효과적**: 혈액검사만으로 예후 예측 가능\n",
    "- **정밀의학**: 개인 맞춤형 치료 전략 수립 가능\n",
    "\n",
    "## 📈 성능 비교표\n",
    "\n",
    "| 구분 | 현재 모델 | 대만 연구 | KELIM 연구 |\n",
    "|------|-----------|-----------|------------|\n",
    "| C-index | 0.52-0.53 | 0.80-0.83 | N/A |\n",
    "| 주요 변수 | 7개 기본 변수 | TNM, CA-125, 잔존종양 | CA-125 변화 추이 |\n",
    "| 임상 활용 | 제한적 | 우수 | 실용적 |\n",
    "| 예후 예측 | 랜덤 수준 | 우수 | 50% 위험 감소 |\n",
    "\n",
    "## 🔧 개선 방안\n",
    "\n",
    "### **1. 핵심 바이오마커 추가**\n",
    "```python\n",
    "# 필요한 핵심 변수들\n",
    "essential_variables = [\n",
    "    'CA125_baseline',      # 기준 CA-125 수치\n",
    "    'CA125_nadir',         # 최저 CA-125 수치\n",
    "    'KELIM_score',         # 종양표지자 변화 추이\n",
    "    'residual_disease',    # 잔존 병변 (가장 중요)\n",
    "    'optimal_debulking'    # 최적 종양감축술 여부\n",
    "]\n",
    "```\n",
    "\n",
    "### **2. 다중공선성 기준 완화**\n",
    "- **VIF < 15**: 더 관대한 기준으로 중요 변수 보존\n",
    "- **단계적 제거**: 임상적 중요도 고려한 선택적 제거\n",
    "\n",
    "### **3. KELIM 점수 구현**\n",
    "```python\n",
    "def calculate_kelim_score(ca125_values, time_points):\n",
    "    # CA-125 변화 추이를 수학적으로 계산\n",
    "    # 치료 반응 및 예후 예측\n",
    "    pass\n",
    "```\n",
    "\n",
    "## 📈 결론 및 권장사항\n",
    "\n",
    "### **현재 모델의 한계**\n",
    "1. **낮은 예측 성능**: C-index 0.52-0.53으로 실용성 부족\n",
    "2. **핵심 변수 누락**: CA-125, 잔존 병변 등 필수 요소 없음\n",
    "3. **과도한 특성 제거**: 다중공선성 제거로 중요 정보 손실\n",
    "\n",
    "### **실용적 해결책**\n",
    "1. **CA-125 데이터** 확보 및 KELIM 점수 계산\n",
    "2. **잔존 병변 정보** 추가 (수술 결과)\n",
    "3. **다중공선성 기준** 완화 (VIF < 15)\n",
    "4. **국제 표준 모델** 벤치마킹\n",
    "\n",
    "**결론적으로, 기술적으로는 완성된 CDSS 시스템이지만 임상적 예측 성능이 부족하여 실제 활용에는 한계가 있습니다. 검색 결과에서 확인된 CA-125 기반 KELIM 점수와 잔존 병변 정보를 추가한 모델 재구축이 필요합니다!** 🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
