{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cf1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 한글 폰트 설정 완료\n",
      "🚀 간암 치료 효과 예측 모델 초기화 (CDSS 호환 + XAI + 과적합 방지)\n",
      "📁 데이터 경로: C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\n",
      "⏰ 시작 시간: 2025-06-16 12:42:43\n",
      "============================================================\n",
      "🎯 간암 치료 효과 예측 모델 전체 분석 시작 (XAI + CDSS 호환 + 과적합 방지)\n",
      "\n",
      "📊 1. 데이터 로드 및 탐색\n",
      "✅ 데이터 로드 성공: 377행 × 87열\n",
      "📈 데이터 기본 정보:\n",
      "   - 총 환자 수: 377\n",
      "   - 총 컬럼 수: 87\n",
      "   - 생존 환자: 245명\n",
      "   - 사망 환자: 132명\n",
      "   - 사망률: 35.0%\n",
      "\n",
      "🔧 2. 데이터 전처리\n",
      "✅ 사용 가능한 컬럼: 20개\n",
      "🔄 생존 변수 생성 중...\n",
      "✅ 유효한 생존 데이터: 372명\n",
      "   - 사망 이벤트: 132건\n",
      "   - 중간 생존 시간: 602일\n",
      "   - 치료 효과 양호: 188명\n",
      "\n",
      "📋 결측값 분석:\n",
      "   - days_to_death: 240개 (64.5%)\n",
      "   - child_pugh_classification: 47개 (12.6%)\n",
      "   - ishak_fibrosis_score: 96개 (25.8%)\n",
      "   - ajcc_pathologic_stage: 24개 (6.5%)\n",
      "   - ajcc_pathologic_t: 2개 (0.5%)\n",
      "   - ajcc_pathologic_n: 1개 (0.3%)\n",
      "   - tumor_grade: 5개 (1.3%)\n",
      "   - age_at_diagnosis: 3개 (0.8%)\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 44개 (11.8%)\n",
      "   - treatments_pharmaceutical_treatment_type: 42개 (11.3%)\n",
      "   - year_of_diagnosis: 2개 (0.5%)\n",
      "\n",
      "🎯 3. 특성 준비 및 인코딩\n",
      "🔄 CDSS 테스트용 환자 분리 중...\n",
      "   - CDSS 테스트 환자: 332\n",
      "   - 모델 훈련용 데이터: 371명\n",
      "📊 초기 특성 개수: 17\n",
      "📊 샘플 개수: 371\n",
      "🔤 범주형 변수: 15개\n",
      "🔢 수치형 변수: 2개\n",
      "🔄 결측값 처리 중...\n",
      "\n",
      "   🔍 child_pugh_classification 처리:\n",
      "      - 전처리 전 분포: {'A': 222, 'Unknown': 80, nan: 47}\n",
      "      - 'Unknown' 값 유지 (임상적 의미 있음)\n",
      "      - 결측치를 'A'로 대체\n",
      "\n",
      "   🔍 ishak_fibrosis_score 처리:\n",
      "      - 전처리 전 분포: {nan: 95, '0 - No Fibrosis': 76, '6 - Established Cirrhosis': 70}\n",
      "      - 'Unknown' 값을 결측치로 변환 후 대체\n",
      "      - 결측치를 '0 - No Fibrosis'로 대체\n",
      "\n",
      "   🔍 ajcc_pathologic_stage 처리:\n",
      "      - 전처리 전 분포: {'Stage I': 174, 'Stage II': 84, 'Stage IIIA': 63}\n",
      "      - 결측치를 'Stage I'로 대체\n",
      "\n",
      "   🔍 ajcc_pathologic_t 처리:\n",
      "      - 전처리 전 분포: {'T1': 184, 'T2': 90, 'T3': 44}\n",
      "      - 결측치를 'T1'로 대체\n",
      "\n",
      "   🔍 ajcc_pathologic_n 처리:\n",
      "      - 전처리 전 분포: {'N0': 253, 'NX': 113, 'N1': 4}\n",
      "      - 결측치를 'N0'로 대체\n",
      "\n",
      "   🔍 ajcc_pathologic_m 처리:\n",
      "      - 전처리 전 분포: {'M0': 268, 'MX': 99, 'M1': 4}\n",
      "\n",
      "   🔍 tumor_grade 처리:\n",
      "      - 전처리 전 분포: {'G2': 177, 'G3': 121, 'G1': 55}\n",
      "      - 결측치를 'G2'로 대체\n",
      "\n",
      "   🔍 morphology 처리:\n",
      "      - 전처리 전 분포: {'8170/3': 354, '8180/3': 7, '8171/3': 4}\n",
      "\n",
      "   🔍 gender 처리:\n",
      "      - 전처리 전 분포: {'male': 250, 'female': 121}\n",
      "\n",
      "   🔍 race 처리:\n",
      "      - 전처리 전 분포: {'white': 186, 'asian': 157, 'black or african american': 17}\n",
      "      - 'Unknown' 값을 결측치로 변환 후 대체\n",
      "      - 결측치를 'white'로 대체\n",
      "\n",
      "   🔍 ethnicity 처리:\n",
      "      - 전처리 전 분포: {'not hispanic or latino': 335, 'hispanic or latino': 18, 'not reported': 15}\n",
      "      - 'Unknown' 값을 결측치로 변환 후 대체\n",
      "      - 결측치를 'not hispanic or latino'로 대체\n",
      "\n",
      "   🔍 treatments_pharmaceutical_treatment_intent_type 처리:\n",
      "      - 전처리 전 분포: {'Adjuvant': 327, nan: 44}\n",
      "      - 결측치를 'Adjuvant'로 대체\n",
      "\n",
      "   🔍 treatments_pharmaceutical_treatment_type 처리:\n",
      "      - 전처리 전 분포: {'Pharmaceutical Therapy, NOS': 329, nan: 42}\n",
      "      - 결측치를 'Pharmaceutical Therapy, NOS'로 대체\n",
      "\n",
      "   🔍 prior_treatment 처리:\n",
      "      - 전처리 전 분포: {'No': 369, 'Yes': 2}\n",
      "\n",
      "   🔍 primary_diagnosis 처리:\n",
      "      - 전처리 전 분포: {'Hepatocellular carcinoma, NOS': 354, 'Combined hepatocellular carcinoma and cholangiocarcinoma': 7, 'Hepatocellular carcinoma, fibrolamellar': 4}\n",
      "\n",
      "🔄 범주형 변수 인코딩:\n",
      "   - child_pugh_classification 인코딩 매핑: {'A': 0, 'B': 1, 'C': 2, 'Unknown': 3}\n",
      "   - ajcc_pathologic_stage 인코딩 매핑: {'Stage I': 0, 'Stage II': 1, 'Stage III': 2, 'Stage IIIA': 3, 'Stage IIIB': 4, 'Stage IIIC': 5, 'Stage IV': 6, 'Stage IVA': 7, 'Stage IVB': 8}\n",
      "   - ajcc_pathologic_t 인코딩 매핑: {'T1': 0, 'T2': 1, 'T2a': 2, 'T2b': 3, 'T3': 4, 'T3a': 5, 'T3b': 6, 'T4': 7, 'TX': 8}\n",
      "   - ajcc_pathologic_n 인코딩 매핑: {'N0': 0, 'N1': 1, 'NX': 2}\n",
      "   - ajcc_pathologic_m 인코딩 매핑: {'M0': 0, 'M1': 1, 'MX': 2}\n",
      "   - tumor_grade 인코딩 매핑: {'G1': 0, 'G2': 1, 'G3': 2, 'G4': 3}\n",
      "   - treatments_pharmaceutical_treatment_intent_type 인코딩 매핑: {'Adjuvant': 0}\n",
      "   - treatments_pharmaceutical_treatment_type 인코딩 매핑: {'Pharmaceutical Therapy, NOS': 0}\n",
      "   - prior_treatment 인코딩 매핑: {'No': 0, 'Yes': 1}\n",
      "\n",
      "📏 전체 특성 Imputer 훈련:\n",
      "   - 전체 특성 수: 17\n",
      "✅ 전체 특성 Imputer 훈련 완료: 17개 특성\n",
      "✅ 특성 준비 완료 (CDSS 호환)\n",
      "\n",
      "✂️  4. 데이터 분할 (훈련:검증:테스트 = 60:20:20)\n",
      "📊 훈련 세트: 222명 (사망: 80명, 치료효과양호: 113명)\n",
      "📊 검증 세트: 74명 (사망: 23명, 치료효과양호: 37명)\n",
      "📊 테스트 세트: 75명 (사망: 29명, 치료효과양호: 38명)\n",
      "📊 CDSS 테스트: 1명 (별도 보관)\n",
      "\n",
      "🤖 5. 모델 훈련 (균형잡힌 과적합 방지)\n",
      "🔄 Random Survival Forest 훈련 중...\n",
      "✅ Random Survival Forest 훈련 완료\n",
      "🔄 Cox 비례위험 모델 훈련 중...\n",
      "✅ Cox 생존 모델 훈련 완료\n",
      "🔄 Random Forest 균형잡힌 설정으로 훈련 중...\n",
      "✅ Random Forest 균형잡힌 훈련 완료\n",
      "🔄 XGBoost 적절한 정규화로 훈련 중...\n",
      "✅ XGBoost 적절한 정규화 훈련 완료\n",
      "🔄 LightGBM 과적합 방지 최적화로 훈련 중...\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's binary_logloss: 0.571581\n",
      "✅ LightGBM 과적합 방지 훈련 완료\n",
      "\n",
      "🎯 균형잡힌 5개 모델 훈련 완료\n",
      "\n",
      "📈 6. 모델 평가\n",
      "\n",
      "🔍 RSF 모델 평가:\n",
      "   Train: C-index = 0.764\n",
      "   Validation: C-index = 0.692\n",
      "   Test: C-index = 0.570\n",
      "\n",
      "🔍 Cox_Survival 모델 평가:\n",
      "   Train: C-index = 0.642\n",
      "   Validation: C-index = 0.699\n",
      "   Test: C-index = 0.567\n",
      "\n",
      "🔍 RF_Treatment 모델 평가:\n",
      "   Train: Accuracy = 0.824, AUC = 0.910\n",
      "   Validation: Accuracy = 0.716, AUC = 0.743\n",
      "   Test: Accuracy = 0.667, AUC = 0.703\n",
      "\n",
      "🔍 XGB_Treatment 모델 평가:\n",
      "   Train: Accuracy = 0.986, AUC = 0.997\n",
      "   Validation: Accuracy = 0.689, AUC = 0.740\n",
      "   Test: Accuracy = 0.693, AUC = 0.718\n",
      "\n",
      "🔍 LGB_Treatment 모델 평가:\n",
      "   Train: Accuracy = 0.815, AUC = 0.895\n",
      "   Validation: Accuracy = 0.730, AUC = 0.755\n",
      "   Test: Accuracy = 0.693, AUC = 0.757\n",
      "\n",
      "🔍 XAI 모델 설명 생성\n",
      "🔄 SHAP 설명 생성 중...\n",
      "✅ RF_Treatment SHAP 설명 생성 완료\n",
      "✅ XGB_Treatment SHAP 설명 생성 완료\n",
      "✅ LGB_Treatment SHAP 설명 생성 완료\n",
      "\n",
      "🔄 LIME 설명 생성 중...\n",
      "✅ RF_Treatment LIME 설명기 생성 완료\n",
      "✅ XGB_Treatment LIME 설명기 생성 완료\n",
      "✅ LGB_Treatment LIME 설명기 생성 완료\n",
      "\n",
      "📊 XAI 시각화 생성\n",
      "🔄 RF_Treatment SHAP 시각화 생성 중...\n",
      "✅ RF_Treatment SHAP 시각화 완료\n",
      "🔄 XGB_Treatment SHAP 시각화 생성 중...\n",
      "✅ XGB_Treatment SHAP 시각화 완료\n",
      "🔄 LGB_Treatment SHAP 시각화 생성 중...\n",
      "✅ LGB_Treatment SHAP 시각화 완료\n",
      "✅ RF_Treatment LIME 시각화 완료\n",
      "✅ XGB_Treatment LIME 시각화 완료\n",
      "✅ LGB_Treatment LIME 시각화 완료\n",
      "\n",
      "📊 7. 결과 시각화\n",
      "🔍 치료효과별 생존 곡선 생성 중...\n",
      "\n",
      "🔬 CDSS 호환성 테스트\n",
      "\n",
      "🔧 Holdout 환자 전처리 시작\n",
      "🔍 원본 환자 특성: 17개\n",
      "🔍 모델 훈련 특성: 17개\n",
      "✅ child_pugh_classification: 원본 데이터 사용\n",
      "✅ ishak_fibrosis_score: 원본 데이터 사용\n",
      "✅ ajcc_pathologic_stage: 원본 데이터 사용\n",
      "✅ ajcc_pathologic_t: 원본 데이터 사용\n",
      "✅ ajcc_pathologic_n: 원본 데이터 사용\n",
      "✅ ajcc_pathologic_m: 원본 데이터 사용\n",
      "✅ tumor_grade: 원본 데이터 사용\n",
      "✅ morphology: 원본 데이터 사용\n",
      "✅ age_at_diagnosis: 원본 데이터 사용\n",
      "✅ gender: 원본 데이터 사용\n",
      "✅ race: 원본 데이터 사용\n",
      "✅ ethnicity: 원본 데이터 사용\n",
      "✅ treatments_pharmaceutical_treatment_intent_type: 원본 데이터 사용\n",
      "✅ treatments_pharmaceutical_treatment_type: 원본 데이터 사용\n",
      "✅ prior_treatment: 원본 데이터 사용\n",
      "✅ primary_diagnosis: 원본 데이터 사용\n",
      "✅ year_of_diagnosis: 원본 데이터 사용\n",
      "\n",
      "🔄 범주형 변수 전처리:\n",
      "   - child_pugh_classification: 원본값 = Unknown\n",
      "     → 인코딩: 'Unknown' → 3\n",
      "   - ishak_fibrosis_score: 원본값 = nan\n",
      "     → 결측치를 '0 - No Fibrosis' (0)로 대체\n",
      "   - ajcc_pathologic_stage: 원본값 = Stage II\n",
      "     → 인코딩: 'Stage II' → 1\n",
      "   - ajcc_pathologic_t: 원본값 = T2\n",
      "     → 인코딩: 'T2' → 1\n",
      "   - ajcc_pathologic_n: 원본값 = N0\n",
      "     → 인코딩: 'N0' → 0\n",
      "   - ajcc_pathologic_m: 원본값 = M0\n",
      "     → 인코딩: 'M0' → 0\n",
      "   - tumor_grade: 원본값 = G2\n",
      "     → 인코딩: 'G2' → 1\n",
      "   - morphology: 원본값 = 8170/3\n",
      "     → 인코딩: '8170/3' → 0\n",
      "   - gender: 원본값 = male\n",
      "     → 인코딩: 'male' → 1\n",
      "   - race: 원본값 = asian\n",
      "     → 인코딩: 'asian' → 1\n",
      "   - ethnicity: 원본값 = not hispanic or latino\n",
      "     → 인코딩: 'not hispanic or latino' → 1\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 원본값 = Adjuvant\n",
      "     → 인코딩: 'Adjuvant' → 0\n",
      "   - treatments_pharmaceutical_treatment_type: 원본값 = Pharmaceutical Therapy, NOS\n",
      "     → 인코딩: 'Pharmaceutical Therapy, NOS' → 0\n",
      "   - prior_treatment: 원본값 = No\n",
      "     → 인코딩: 'No' → 0\n",
      "   - primary_diagnosis: 원본값 = Hepatocellular carcinoma, NOS\n",
      "     → 인코딩: 'Hepatocellular carcinoma, NOS' → 2\n",
      "\n",
      "🔢 데이터 타입 변환:\n",
      "   - child_pugh_classification: 이미 숫자형\n",
      "   - ishak_fibrosis_score: 이미 숫자형\n",
      "   - ajcc_pathologic_stage: 이미 숫자형\n",
      "   - ajcc_pathologic_t: 이미 숫자형\n",
      "   - ajcc_pathologic_n: 이미 숫자형\n",
      "   - ajcc_pathologic_m: 이미 숫자형\n",
      "   - tumor_grade: 이미 숫자형\n",
      "   - morphology: 이미 숫자형\n",
      "   - age_at_diagnosis: 이미 숫자형\n",
      "   - gender: 이미 숫자형\n",
      "   - race: 이미 숫자형\n",
      "   - ethnicity: 이미 숫자형\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 이미 숫자형\n",
      "   - treatments_pharmaceutical_treatment_type: 이미 숫자형\n",
      "   - prior_treatment: 이미 숫자형\n",
      "   - primary_diagnosis: 이미 숫자형\n",
      "   - year_of_diagnosis: 이미 숫자형\n",
      "✅ 특성 순서 정렬 완료: (1, 17)\n",
      "✅ 특성명 확인: True\n",
      "\n",
      "📏 Imputer 적용 (안전한 방법):\n",
      "   - 입력 형태: (1, 17)\n",
      "   - Imputer 기대 특성 수: 17\n",
      "✅ Imputer 적용 완료\n",
      "\n",
      "📏 스케일링 적용 (안전한 방법):\n",
      "   - 입력 형태: (1, 17)\n",
      "   - Scaler 기대 특성 수: 17\n",
      "✅ 스케일링 완료\n",
      "✅ 최종 특성 형태: (1, 17)\n",
      "\n",
      "🔄 RSF 모델 예측 중...\n",
      "   - 모델 타입: RandomSurvivalForest\n",
      "   - 입력 특성 수: 17\n",
      "✅ RSF: 위험도 점수 = 21.1065\n",
      "\n",
      "🔄 Cox_Survival 모델 예측 중...\n",
      "   - 모델 타입: CoxPHSurvivalAnalysis\n",
      "   - 입력 특성 수: 17\n",
      "✅ Cox_Survival: 위험도 점수 = -0.2602\n",
      "\n",
      "🔄 RF_Treatment 모델 예측 중...\n",
      "   - 모델 타입: RandomForestClassifier\n",
      "   - 입력 특성 수: 17\n",
      "✅ RF_Treatment: 치료효과 불량 (확률: 0.879)\n",
      "\n",
      "🔄 XGB_Treatment 모델 예측 중...\n",
      "   - 모델 타입: XGBClassifier\n",
      "   - 입력 특성 수: 17\n",
      "✅ XGB_Treatment: 치료효과 불량 (확률: 0.982)\n",
      "\n",
      "🔄 LGB_Treatment 모델 예측 중...\n",
      "   - 모델 타입: LGBMClassifier\n",
      "   - 입력 특성 수: 17\n",
      "✅ LGB_Treatment: 치료효과 불량 (확률: 0.889)\n",
      "📁 시각화 결과 저장: liver_cancer_treatment_effect_prediction_cdss_xai_overfitting_fixed.png\n",
      "\n",
      "📋 8. 결과 보고서 생성\n",
      "📁 보고서 저장: liver_cancer_treatment_effect_prediction_cdss_overfitting_fixed_report.txt\n",
      "\n",
      "============================================================\n",
      "간암 환자 치료 효과 예측 모델 분석 결과 (XAI + CDSS 호환 + 과적합 방지)\n",
      "============================================================\n",
      "분석 일시: 2025-06-16 12:42:50\n",
      "데이터 경로: C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\n",
      "\n",
      "📊 데이터 요약\n",
      "------------------------------\n",
      "총 환자 수: 373\n",
      "모델 훈련용: 372명\n",
      "CDSS 테스트용: 1명\n",
      "사망률: 35.5%\n",
      "중간 생존 시간: 602일\n",
      "치료효과 양호율: 50.5%\n",
      "사용된 특성 수: 17\n",
      "\n",
      "🤖 모델 성능\n",
      "------------------------------\n",
      "\n",
      "생존 예측 모델 (C-index):\n",
      "  RSF Train: C-index = 0.764\n",
      "  RSF Validation: C-index = 0.692\n",
      "  RSF Test: C-index = 0.570\n",
      "  Cox_Survival Train: C-index = 0.642\n",
      "  Cox_Survival Validation: C-index = 0.699\n",
      "  Cox_Survival Test: C-index = 0.567\n",
      "\n",
      "치료효과 분류 모델 (Accuracy):\n",
      "  RF_Treatment Train: Accuracy = 0.824\n",
      "  RF_Treatment Train: AUC = 0.910\n",
      "  RF_Treatment Validation: Accuracy = 0.716\n",
      "  RF_Treatment Validation: AUC = 0.743\n",
      "  RF_Treatment Test: Accuracy = 0.667\n",
      "  RF_Treatment Test: AUC = 0.703\n",
      "  XGB_Treatment Train: Accuracy = 0.986\n",
      "  XGB_Treatment Train: AUC = 0.997\n",
      "  XGB_Treatment Validation: Accuracy = 0.689\n",
      "  XGB_Treatment Validation: AUC = 0.740\n",
      "  XGB_Treatment Test: Accuracy = 0.693\n",
      "  XGB_Treatment Test: AUC = 0.718\n",
      "  LGB_Treatment Train: Accuracy = 0.815\n",
      "  LGB_Treatment Train: AUC = 0.895\n",
      "  LGB_Treatment Validation: Accuracy = 0.730\n",
      "  LGB_Treatment Validation: AUC = 0.755\n",
      "  LGB_Treatment Test: Accuracy = 0.693\n",
      "  LGB_Treatment Test: AUC = 0.757\n",
      "\n",
      "과적합 분석:\n",
      "  RF_Treatment: 과적합 정도 = 0.158 (심각)\n",
      "  XGB_Treatment: 과적합 정도 = 0.293 (심각)\n",
      "  LGB_Treatment: 과적합 정도 = 0.122 (심각)\n",
      "\n",
      "🏆 최고 성능 모델: XGB_Treatment_Accuracy (점수: 0.693)\n",
      "\n",
      "ℹ️  특징:\n",
      "   - CDSS 호환 치료 효과 예측 모델\n",
      "   - XAI 설명 가능성 포함 (SHAP, LIME)\n",
      "   - Holdout 환자로 실제 예측 테스트\n",
      "   - 과적합 방지 기법 적용\n",
      "   - 생존 예측 + 치료 효과 분류 통합\n",
      "\n",
      "============================================================\n",
      "\n",
      "💾 CDSS 호환 모델 저장\n",
      "✅ RSF 모델 저장: cdss_liver_cancer_treatment_rsf_model.pkl\n",
      "✅ Cox_Survival 모델 저장: cdss_liver_cancer_treatment_cox_survival_model.pkl\n",
      "✅ RF_Treatment 모델 저장: cdss_liver_cancer_treatment_rf_treatment_model.pkl\n",
      "✅ XGB_Treatment 모델 저장: cdss_liver_cancer_treatment_xgb_treatment_model.pkl\n",
      "✅ LGB_Treatment 모델 저장: cdss_liver_cancer_treatment_lgb_treatment_model.pkl\n",
      "✅ 전체 파이프라인 저장: cdss_liver_cancer_treatment_complete_pipeline.pkl\n",
      "\n",
      "🎉 전체 분석 완료!\n",
      "⏰ 완료 시간: 2025-06-16 12:42:50\n",
      "\n",
      "✨ 모든 분석이 성공적으로 완료되었습니다!\n",
      "📁 생성된 파일들:\n",
      "   - liver_cancer_treatment_effect_prediction_cdss_xai_overfitting_fixed.png (시각화 결과)\n",
      "   - liver_cancer_treatment_effect_prediction_cdss_overfitting_fixed_report.txt (분석 보고서)\n",
      "   - cdss_liver_cancer_treatment_*_model.pkl (CDSS 호환 개별 모델)\n",
      "   - cdss_liver_cancer_treatment_complete_pipeline.pkl (전체 파이프라인)\n",
      "   - shap_*.png (SHAP 설명)\n",
      "   - lime_*.png (LIME 설명)\n",
      "\n",
      "🔬 주요 개선사항:\n",
      "   - 과적합 방지 기법 적용\n",
      "   - 균형잡힌 모델 하이퍼파라미터\n",
      "   - 안전한 CDSS 호환성\n",
      "   - XAI 설명 가능성 포함\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import pickle\n",
    "\n",
    "# 생존 분석 라이브러리\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "def setup_korean_font():\n",
    "    \"\"\"한글 폰트 설정\"\"\"\n",
    "    import platform\n",
    "    import matplotlib.font_manager as fm\n",
    "    \n",
    "    system = platform.system()\n",
    "    \n",
    "    if system == 'Windows':\n",
    "        try:\n",
    "            plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "        except:\n",
    "            try:\n",
    "                font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            except:\n",
    "                print(\"⚠️ 한글 폰트 설정 실패\")\n",
    "    elif system == 'Darwin':\n",
    "        plt.rcParams['font.family'] = 'AppleGothic'\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(\"✅ 한글 폰트 설정 완료\")\n",
    "\n",
    "class LiverCancerTreatmentEffectPredictorCDSS:\n",
    "    \"\"\"간암 치료 효과 예측 모델 클래스 (CDSS 호환 + XAI + 과적합 방지)\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        setup_korean_font()\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.processed_df = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.feature_names = []\n",
    "        self.scaler = None\n",
    "        self.label_encoders = {}\n",
    "        self.shap_explainers = {}\n",
    "        self.shap_values = {}\n",
    "        self.lime_explainers = {}\n",
    "        self.holdout_patient = None\n",
    "        \n",
    "        print(f\"🚀 간암 치료 효과 예측 모델 초기화 (CDSS 호환 + XAI + 과적합 방지)\")\n",
    "        print(f\"📁 데이터 경로: {data_path}\")\n",
    "        print(f\"⏰ 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"데이터 로드 및 탐색적 분석\"\"\"\n",
    "        print(\"\\n📊 1. 데이터 로드 및 탐색\")\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "            print(f\"✅ 데이터 로드 성공: {self.df.shape[0]}행 × {self.df.shape[1]}열\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # 기본 정보 출력\n",
    "        print(f\"📈 데이터 기본 정보:\")\n",
    "        print(f\"   - 총 환자 수: {len(self.df)}\")\n",
    "        print(f\"   - 총 컬럼 수: {len(self.df.columns)}\")\n",
    "        \n",
    "        # 생존 상태 분포\n",
    "        if 'vital_status' in self.df.columns:\n",
    "            status_counts = self.df['vital_status'].value_counts()\n",
    "            print(f\"   - 생존 환자: {status_counts.get('Alive', 0)}명\")\n",
    "            print(f\"   - 사망 환자: {status_counts.get('Dead', 0)}명\")\n",
    "            print(f\"   - 사망률: {status_counts.get('Dead', 0)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        print(\"\\n🔧 2. 데이터 전처리\")\n",
    "        \n",
    "        # 치료 효과 예측 모델용 선택된 컬럼들\n",
    "        selected_columns = [\n",
    "            # 생존 결과 변수\n",
    "            'vital_status', 'days_to_death', 'days_to_last_follow_up',\n",
    "            # 간기능 평가 (핵심 예측 인자)\n",
    "            'child_pugh_classification', 'ishak_fibrosis_score',\n",
    "            # 병기 및 종양 특성\n",
    "            'ajcc_pathologic_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'tumor_grade', 'morphology',\n",
    "            # 환자 기본 특성\n",
    "            'age_at_diagnosis', 'gender', 'race', 'ethnicity',\n",
    "            # 치료 관련 변수\n",
    "            'treatments_pharmaceutical_treatment_intent_type', \n",
    "            'treatments_pharmaceutical_treatment_type',\n",
    "            'prior_treatment',\n",
    "            # 추가 임상 변수\n",
    "            'primary_diagnosis', 'year_of_diagnosis'\n",
    "        ]\n",
    "        \n",
    "        # 존재하는 컬럼만 선택\n",
    "        available_columns = [col for col in selected_columns if col in self.df.columns]\n",
    "        missing_columns = [col for col in selected_columns if col not in self.df.columns]\n",
    "        \n",
    "        print(f\"✅ 사용 가능한 컬럼: {len(available_columns)}개\")\n",
    "        if missing_columns:\n",
    "            print(f\"⚠️  누락된 컬럼: {missing_columns}\")\n",
    "        \n",
    "        self.processed_df = self.df[available_columns].copy()\n",
    "        \n",
    "        # 생존 시간 및 이벤트 변수 생성\n",
    "        print(\"🔄 생존 변수 생성 중...\")\n",
    "        self.processed_df['event'] = (self.processed_df['vital_status'] == 'Dead').astype(int)\n",
    "        \n",
    "        # 생존 시간 계산\n",
    "        self.processed_df['duration'] = self.processed_df['days_to_death'].fillna(\n",
    "            self.processed_df['days_to_last_follow_up']\n",
    "        )\n",
    "        \n",
    "        # 치료 효과 지표 생성\n",
    "        self.processed_df['treatment_effectiveness'] = np.where(\n",
    "            self.processed_df['duration'] > self.processed_df['duration'].median(), 1, 0\n",
    "        )\n",
    "        \n",
    "        # 유효하지 않은 생존 시간 제거\n",
    "        valid_mask = (self.processed_df['duration'].notna()) & (self.processed_df['duration'] > 0)\n",
    "        self.processed_df = self.processed_df[valid_mask].copy()\n",
    "        \n",
    "        print(f\"✅ 유효한 생존 데이터: {len(self.processed_df)}명\")\n",
    "        print(f\"   - 사망 이벤트: {self.processed_df['event'].sum()}건\")\n",
    "        print(f\"   - 중간 생존 시간: {self.processed_df['duration'].median():.0f}일\")\n",
    "        print(f\"   - 치료 효과 양호: {self.processed_df['treatment_effectiveness'].sum()}명\")\n",
    "        \n",
    "        # 결측값 분석\n",
    "        print(\"\\n📋 결측값 분석:\")\n",
    "        missing_analysis = self.processed_df.isnull().sum()\n",
    "        missing_percent = (missing_analysis / len(self.processed_df) * 100).round(1)\n",
    "        \n",
    "        for col in missing_analysis[missing_analysis > 0].index:\n",
    "            print(f\"   - {col}: {missing_analysis[col]}개 ({missing_percent[col]}%)\")\n",
    "        \n",
    "        # 높은 결측률 컬럼 제거 (80% 이상)\n",
    "        high_missing_cols = missing_percent[missing_percent > 80].index.tolist()\n",
    "        if high_missing_cols:\n",
    "            print(f\"🗑️  높은 결측률 컬럼 제거: {high_missing_cols}\")\n",
    "            self.processed_df = self.processed_df.drop(columns=high_missing_cols)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"특성 준비 및 인코딩 (CDSS 호환)\"\"\"\n",
    "        print(\"\\n🎯 3. 특성 준비 및 인코딩\")\n",
    "        \n",
    "        # CDSS 테스트용 환자 1명 미리 분리\n",
    "        print(\"🔄 CDSS 테스트용 환자 분리 중...\")\n",
    "        holdout_idx = self.processed_df.sample(n=1, random_state=42).index[0]\n",
    "        self.holdout_patient = self.processed_df.loc[holdout_idx:holdout_idx].copy()\n",
    "        remaining_df = self.processed_df.drop(holdout_idx).copy()\n",
    "        \n",
    "        print(f\"   - CDSS 테스트 환자: {holdout_idx}\")\n",
    "        print(f\"   - 모델 훈련용 데이터: {len(remaining_df)}명\")\n",
    "        \n",
    "        # 특성과 타겟 분리\n",
    "        feature_cols = [col for col in remaining_df.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'treatment_effectiveness']]\n",
    "        \n",
    "        X = remaining_df[feature_cols].copy()\n",
    "        y_duration = remaining_df['duration'].values\n",
    "        y_event = remaining_df['event'].values.astype(bool)\n",
    "        y_effectiveness = remaining_df['treatment_effectiveness'].values\n",
    "        \n",
    "        print(f\"📊 초기 특성 개수: {len(feature_cols)}\")\n",
    "        print(f\"📊 샘플 개수: {len(X)}\")\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        print(f\"🔤 범주형 변수: {len(categorical_cols)}개\")\n",
    "        print(f\"🔢 수치형 변수: {len(numerical_cols)}개\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        print(\"🔄 결측값 처리 중...\")\n",
    "        \n",
    "        # 임상적으로 의미있는 Unknown 값을 가질 수 있는 컬럼들\n",
    "        meaningful_unknown_cols = [\n",
    "            'child_pugh_classification', 'ajcc_pathologic_stage', 'ajcc_pathologic_t',\n",
    "            'ajcc_pathologic_n', 'ajcc_pathologic_m', 'tumor_grade',\n",
    "            'treatments_pharmaceutical_treatment_intent_type',\n",
    "            'treatments_pharmaceutical_treatment_type', 'prior_treatment'\n",
    "        ]\n",
    "        \n",
    "        self.label_encoders = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col in X.columns:\n",
    "                print(f\"\\n   🔍 {col} 처리:\")\n",
    "                \n",
    "                # 현재 값 분포 확인\n",
    "                value_counts = X[col].value_counts(dropna=False)\n",
    "                print(f\"      - 전처리 전 분포: {dict(list(value_counts.items())[:3])}\")\n",
    "                \n",
    "                # 'NA' 문자열을 결측치로 변환\n",
    "                if 'NA' in X[col].values:\n",
    "                    X[col] = X[col].replace('NA', np.nan)\n",
    "                    print(f\"      - 'NA' 문자열을 결측치로 변환\")\n",
    "                \n",
    "                # Unknown 값 처리 결정\n",
    "                has_unknown = X[col].str.contains('Unknown', na=False).any() if X[col].dtype == object else False\n",
    "                \n",
    "                if has_unknown:\n",
    "                    if col in meaningful_unknown_cols:\n",
    "                        print(f\"      - 'Unknown' 값 유지 (임상적 의미 있음)\")\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "                    else:\n",
    "                        print(f\"      - 'Unknown' 값을 결측치로 변환 후 대체\")\n",
    "                        X[col] = X[col].replace('Unknown', np.nan)\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "                else:\n",
    "                    if X[col].isnull().any():\n",
    "                        mode_value = X[col].mode()\n",
    "                        if not mode_value.empty:\n",
    "                            fill_value = mode_value[0]\n",
    "                            X[col] = X[col].fillna(fill_value)\n",
    "                            print(f\"      - 결측치를 '{fill_value}'로 대체\")\n",
    "        \n",
    "        # 모든 범주형 변수 인코딩\n",
    "        print(\"\\n🔄 범주형 변수 인코딩:\")\n",
    "        all_categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        for col in all_categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "            \n",
    "            if col in meaningful_unknown_cols:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"   - {col} 인코딩 매핑: {mapping}\")\n",
    "        \n",
    "        # 모든 특성을 수치형으로 변환\n",
    "        for col in X.columns:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        \n",
    "        # 전체 특성에 대해 Imputer 훈련 (메모리 항목[5] 적용)\n",
    "        print(f\"\\n📏 전체 특성 Imputer 훈련:\")\n",
    "        print(f\"   - 전체 특성 수: {X.shape[1]}\")\n",
    "        \n",
    "        self.num_imputer = SimpleImputer(strategy='median')\n",
    "        X_imputed = self.num_imputer.fit_transform(X)\n",
    "        X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "        \n",
    "        print(f\"✅ 전체 특성 Imputer 훈련 완료: {X.shape[1]}개 특성\")\n",
    "        \n",
    "        # 특성 스케일링\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        self.feature_names = X_scaled.columns.tolist()\n",
    "        \n",
    "        # scikit-survival 형식으로 변환\n",
    "        y_structured = np.array([(event, duration) for event, duration in zip(y_event, y_duration)],\n",
    "                               dtype=[('event', '?'), ('time', '<f8')])\n",
    "        \n",
    "        print(\"✅ 특성 준비 완료 (CDSS 호환)\")\n",
    "        \n",
    "        return X_scaled, y_structured, y_duration, y_event, y_effectiveness\n",
    "    \n",
    "    def split_data(self, X, y_structured, y_duration, y_event, y_effectiveness):\n",
    "        \"\"\"데이터 분할 (메모리 항목[3] 적용)\"\"\"\n",
    "        print(\"\\n✂️  4. 데이터 분할 (훈련:검증:테스트 = 60:20:20)\")\n",
    "        \n",
    "        # 먼저 훈련+검증 vs 테스트로 분할\n",
    "        X_temp, X_test, y_temp_struct, y_test_struct, y_temp_dur, y_test_dur, y_temp_event, y_test_event, y_temp_eff, y_test_eff = \\\n",
    "            train_test_split(X, y_structured, y_duration, y_event, y_effectiveness,\n",
    "                           test_size=0.2, random_state=42, stratify=y_effectiveness)\n",
    "        \n",
    "        # 훈련 vs 검증으로 분할\n",
    "        X_train, X_val, y_train_struct, y_val_struct, y_train_dur, y_val_dur, y_train_event, y_val_event, y_train_eff, y_val_eff = \\\n",
    "            train_test_split(X_temp, y_temp_struct, y_temp_dur, y_temp_event, y_temp_eff,\n",
    "                           test_size=0.25, random_state=42, stratify=y_temp_eff)\n",
    "        \n",
    "        print(f\"📊 훈련 세트: {len(X_train)}명 (사망: {y_train_event.sum()}명, 치료효과양호: {y_train_eff.sum()}명)\")\n",
    "        print(f\"📊 검증 세트: {len(X_val)}명 (사망: {y_val_event.sum()}명, 치료효과양호: {y_val_eff.sum()}명)\")\n",
    "        print(f\"📊 테스트 세트: {len(X_test)}명 (사망: {y_test_event.sum()}명, 치료효과양호: {y_test_eff.sum()}명)\")\n",
    "        print(f\"📊 CDSS 테스트: 1명 (별도 보관)\")\n",
    "        \n",
    "        return (X_train, X_val, X_test, \n",
    "                y_train_struct, y_val_struct, y_test_struct,\n",
    "                y_train_dur, y_val_dur, y_test_dur,\n",
    "                y_train_event, y_val_event, y_test_event,\n",
    "                y_train_eff, y_val_eff, y_test_eff)\n",
    "    \n",
    "    def train_models(self, X_train, X_val, X_test, \n",
    "                    y_train_struct, y_val_struct, y_test_struct,\n",
    "                    y_train_dur, y_val_dur, y_test_dur,\n",
    "                    y_train_event, y_val_event, y_test_event,\n",
    "                    y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"모델 훈련 (균형잡힌 과적합 방지)\"\"\"\n",
    "        print(\"\\n🤖 5. 모델 훈련 (균형잡힌 과적합 방지)\")\n",
    "        \n",
    "        # 1. Random Survival Forest (생존 예측)\n",
    "        print(\"🔄 Random Survival Forest 훈련 중...\")\n",
    "        try:\n",
    "            rsf_model = RandomSurvivalForest(\n",
    "                n_estimators=100,\n",
    "                max_depth=8,\n",
    "                min_samples_split=15,\n",
    "                min_samples_leaf=8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rsf_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            rsf_wrapper = {\n",
    "                'model': rsf_model,\n",
    "                'model_type': 'RandomSurvivalForest',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['RSF'] = rsf_wrapper\n",
    "            print(\"✅ Random Survival Forest 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ RSF 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 2. Cox 비례위험 모델 (생존 예측)\n",
    "        print(\"🔄 Cox 비례위험 모델 훈련 중...\")\n",
    "        try:\n",
    "            cox_model = CoxPHSurvivalAnalysis(alpha=0.5)\n",
    "            cox_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            cox_wrapper = {\n",
    "                'model': cox_model,\n",
    "                'model_type': 'CoxPHSurvivalAnalysis',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['Cox_Survival'] = cox_wrapper\n",
    "            print(\"✅ Cox 생존 모델 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Cox 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 3. Random Forest (균형잡힌 설정)\n",
    "        print(\"🔄 Random Forest 균형잡힌 설정으로 훈련 중...\")\n",
    "        try:\n",
    "            rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=8,\n",
    "                min_samples_split=15,\n",
    "                min_samples_leaf=8,\n",
    "                max_features='sqrt',\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf_classifier.fit(X_train, y_train_eff)\n",
    "            \n",
    "            rf_wrapper = {\n",
    "                'model': rf_classifier,\n",
    "                'model_type': 'RandomForestClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['치료효과 불량', '치료효과 양호'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': rf_classifier.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['RF_Treatment'] = rf_wrapper\n",
    "            print(\"✅ Random Forest 균형잡힌 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ RF 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 4. XGBoost (적절한 정규화)\n",
    "        print(\"🔄 XGBoost 적절한 정규화로 훈련 중...\")\n",
    "        try:\n",
    "            xgb_model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.5,\n",
    "                reg_lambda=0.5,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            \n",
    "            xgb_model.fit(X_train, y_train_eff)\n",
    "            \n",
    "            xgb_wrapper = {\n",
    "                'model': xgb_model,\n",
    "                'model_type': 'XGBClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['치료효과 불량', '치료효과 양호'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': xgb_model.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['XGB_Treatment'] = xgb_wrapper\n",
    "            print(\"✅ XGBoost 적절한 정규화 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ XGBoost 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        # 5. LightGBM (과적합 방지 최적화)\n",
    "        print(\"🔄 LightGBM 과적합 방지 최적화로 훈련 중...\")\n",
    "        try:\n",
    "            lgb_model = lgb.LGBMClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=15,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.5,\n",
    "                reg_lambda=0.5,\n",
    "                min_child_samples=20,\n",
    "                min_child_weight=0.001,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            \n",
    "            lgb_model.fit(\n",
    "                X_train, y_train_eff,\n",
    "                eval_set=[(X_val, y_val_eff)],\n",
    "                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]\n",
    "            )\n",
    "            \n",
    "            lgb_wrapper = {\n",
    "                'model': lgb_model,\n",
    "                'model_type': 'LGBMClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['치료효과 불량', '치료효과 양호'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': lgb_model.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['LGB_Treatment'] = lgb_wrapper\n",
    "            print(\"✅ LightGBM 과적합 방지 훈련 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ LightGBM 모델 훈련 실패: {e}\")\n",
    "        \n",
    "        print(f\"\\n🎯 균형잡힌 {len(self.models)}개 모델 훈련 완료\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def evaluate_models(self, X_train, X_val, X_test,\n",
    "                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                       y_train_event, y_val_event, y_test_event,\n",
    "                       y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"모델 평가\"\"\"\n",
    "        print(\"\\n📈 6. 모델 평가\")\n",
    "        \n",
    "        datasets = {\n",
    "            'Train': (X_train, y_train_struct, y_train_dur, y_train_event, y_train_eff),\n",
    "            'Validation': (X_val, y_val_struct, y_val_dur, y_val_event, y_val_eff),\n",
    "            'Test': (X_test, y_test_struct, y_test_dur, y_test_event, y_test_eff)\n",
    "        }\n",
    "        \n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            print(f\"\\n🔍 {model_name} 모델 평가:\")\n",
    "            self.results[model_name] = {}\n",
    "            \n",
    "            for dataset_name, (X, y_struct, y_dur, y_event, y_eff) in datasets.items():\n",
    "                try:\n",
    "                    actual_model = model_wrapper['model']\n",
    "                    model_type = model_wrapper['model_type']\n",
    "                    \n",
    "                    if model_type in ['RandomSurvivalForest', 'CoxPHSurvivalAnalysis']:\n",
    "                        # 생존 모델 평가\n",
    "                        risk_scores = actual_model.predict(X)\n",
    "                        c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                        self.results[model_name][dataset_name] = {'c_index': c_index}\n",
    "                        print(f\"   {dataset_name}: C-index = {c_index:.3f}\")\n",
    "                    \n",
    "                    else:\n",
    "                        # 분류 모델 평가 (치료 효과)\n",
    "                        y_pred = actual_model.predict(X)\n",
    "                        accuracy = (y_pred == y_eff).mean()\n",
    "                        \n",
    "                        try:\n",
    "                            y_proba = actual_model.predict_proba(X)\n",
    "                            auc_score = roc_auc_score(y_eff, y_proba[:, 1])\n",
    "                        except:\n",
    "                            auc_score = np.nan\n",
    "                        \n",
    "                        self.results[model_name][dataset_name] = {\n",
    "                            'accuracy': accuracy,\n",
    "                            'auc': auc_score\n",
    "                        }\n",
    "                        print(f\"   {dataset_name}: Accuracy = {accuracy:.3f}, AUC = {auc_score:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ {dataset_name} 평가 실패: {e}\")\n",
    "                    self.results[model_name][dataset_name] = {'error': str(e)}\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def explain_models(self, X_train, X_test):\n",
    "        \"\"\"XAI 모델 설명 생성\"\"\"\n",
    "        print(\"\\n🔍 XAI 모델 설명 생성\")\n",
    "        \n",
    "        # SHAP 설명기 초기화\n",
    "        print(\"🔄 SHAP 설명 생성 중...\")\n",
    "        tree_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        \n",
    "        for model_name in tree_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    X_test_sample = X_test.iloc[:50]\n",
    "                    \n",
    "                    actual_model = self.models[model_name]['model']\n",
    "                    \n",
    "                    explainer = shap.TreeExplainer(actual_model)\n",
    "                    shap_values = explainer.shap_values(X_test_sample)\n",
    "                    \n",
    "                    self.shap_explainers[model_name] = explainer\n",
    "                    self.shap_values[model_name] = shap_values\n",
    "                    print(f\"✅ {model_name} SHAP 설명 생성 완료\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} SHAP 실패: {e}\")\n",
    "        \n",
    "        # LIME 설명기 초기화\n",
    "        print(\"\\n🔄 LIME 설명 생성 중...\")\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    actual_model = self.models[model_name]['model']\n",
    "                    class_labels = self.models[model_name]['class_labels']\n",
    "                    \n",
    "                    explainer = lime_tabular.LimeTabularExplainer(\n",
    "                        training_data=X_train.values,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=class_labels,\n",
    "                        mode='classification',\n",
    "                        discretize_continuous=True\n",
    "                    )\n",
    "                    \n",
    "                    self.lime_explainers[model_name] = {\n",
    "                        'explainer': explainer,\n",
    "                        'predict_fn': actual_model.predict_proba\n",
    "                    }\n",
    "                    print(f\"✅ {model_name} LIME 설명기 생성 완료\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} LIME 실패: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_xai_visualizations(self, X_test, sample_index=0):\n",
    "        \"\"\"XAI 시각화 생성 및 저장\"\"\"\n",
    "        print(\"\\n📊 XAI 시각화 생성\")\n",
    "        \n",
    "        # SHAP 시각화\n",
    "        shap_figures = []\n",
    "        for model_name in self.shap_explainers:\n",
    "            try:\n",
    "                print(f\"🔄 {model_name} SHAP 시각화 생성 중...\")\n",
    "                \n",
    "                shap_vals = self.shap_values[model_name]\n",
    "                \n",
    "                # 이진 분류 SHAP 값 처리\n",
    "                if isinstance(shap_vals, list) and len(shap_vals) == 2:\n",
    "                    shap_vals_to_plot = shap_vals[1]\n",
    "                    expected_val = self.shap_explainers[model_name].expected_value[1]\n",
    "                elif hasattr(shap_vals, 'shape') and shap_vals.ndim == 3:\n",
    "                    shap_vals_to_plot = shap_vals[:, :, 1]\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value[1] \n",
    "                                if hasattr(self.shap_explainers[model_name].expected_value, '__len__') \n",
    "                                else self.shap_explainers[model_name].expected_value)\n",
    "                else:\n",
    "                    shap_vals_to_plot = shap_vals\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value \n",
    "                                if not hasattr(self.shap_explainers[model_name].expected_value, '__len__')\n",
    "                                else self.shap_explainers[model_name].expected_value[0])\n",
    "                \n",
    "                # Summary plot\n",
    "                plt.figure(figsize=(10,6))\n",
    "                shap.summary_plot(shap_vals_to_plot, X_test.iloc[:50], \n",
    "                                feature_names=self.feature_names,\n",
    "                                plot_type=\"bar\", show=False)\n",
    "                plt.title(f\"{model_name} 특성 중요도 (SHAP)\")\n",
    "                shap_summary_path = f\"shap_summary_{model_name}.png\"\n",
    "                plt.savefig(shap_summary_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                # Individual waterfall plot\n",
    "                plt.figure(figsize=(12,6))\n",
    "                \n",
    "                if shap_vals_to_plot.ndim == 2:\n",
    "                    individual_shap = shap_vals_to_plot[sample_index, :]\n",
    "                else:\n",
    "                    individual_shap = shap_vals_to_plot\n",
    "                \n",
    "                if hasattr(expected_val, '__len__') and len(expected_val) > 0:\n",
    "                    base_value = float(expected_val[0]) if hasattr(expected_val[0], '__float__') else 0.0\n",
    "                else:\n",
    "                    base_value = float(expected_val) if hasattr(expected_val, '__float__') else 0.0\n",
    "                \n",
    "                try:\n",
    "                    shap.waterfall_plot(\n",
    "                        shap.Explanation(\n",
    "                            values=individual_shap.astype(float),\n",
    "                            base_values=base_value,\n",
    "                            data=X_test.iloc[sample_index].values.astype(float),\n",
    "                            feature_names=self.feature_names\n",
    "                        ),\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f\"{model_name} 개별 설명 (샘플 {sample_index})\")\n",
    "                    shap_waterfall_path = f\"shap_waterfall_{model_name}_{sample_index}.png\"\n",
    "                    plt.savefig(shap_waterfall_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    shap_figures.extend([shap_summary_path, shap_waterfall_path])\n",
    "                    \n",
    "                except Exception as waterfall_error:\n",
    "                    print(f\"⚠️ Waterfall plot 실패, Force plot으로 대체: {waterfall_error}\")\n",
    "                    \n",
    "                    shap.force_plot(\n",
    "                        base_value,\n",
    "                        individual_shap,\n",
    "                        X_test.iloc[sample_index],\n",
    "                        feature_names=self.feature_names,\n",
    "                        matplotlib=True,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f\"{model_name} 개별 설명 - Force Plot (샘플 {sample_index})\")\n",
    "                    shap_force_path = f\"shap_force_{model_name}_{sample_index}.png\"\n",
    "                    plt.savefig(shap_force_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    shap_figures.extend([shap_summary_path, shap_force_path])\n",
    "                \n",
    "                print(f\"✅ {model_name} SHAP 시각화 완료\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {model_name} SHAP 시각화 실패: {e}\")\n",
    "        \n",
    "        # LIME 시각화\n",
    "        lime_figures = []\n",
    "        for model_name in self.lime_explainers:\n",
    "            try:\n",
    "                lime_data = self.lime_explainers[model_name]\n",
    "                exp = lime_data['explainer'].explain_instance(\n",
    "                    X_test.iloc[sample_index].values,\n",
    "                    lime_data['predict_fn'],\n",
    "                    num_features=5\n",
    "                )\n",
    "                lime_path = f\"lime_explanation_{model_name}_{sample_index}.png\"\n",
    "                fig = exp.as_pyplot_figure()\n",
    "                plt.title(f\"{model_name} LIME 설명 (샘플 {sample_index})\")\n",
    "                plt.savefig(lime_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                lime_figures.append(lime_path)\n",
    "                print(f\"✅ {model_name} LIME 시각화 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {model_name} LIME 시각화 실패: {e}\")\n",
    "        \n",
    "        return shap_figures, lime_figures\n",
    "    \n",
    "    def preprocess_holdout_patient(self):\n",
    "        \"\"\"Holdout 환자 데이터 전처리 (더 안전한 방법)\"\"\"\n",
    "        print(\"\\n🔧 Holdout 환자 전처리 시작\")\n",
    "        \n",
    "        # holdout 환자의 특성 데이터만 추출\n",
    "        feature_cols = [col for col in self.holdout_patient.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'treatment_effectiveness']]\n",
    "        \n",
    "        patient_raw = self.holdout_patient[feature_cols].copy()\n",
    "        print(f\"🔍 원본 환자 특성: {len(patient_raw.columns)}개\")\n",
    "        print(f\"🔍 모델 훈련 특성: {len(self.feature_names)}개\")\n",
    "        \n",
    "        # 모델 훈련 시 사용한 특성명과 정확히 일치하는 DataFrame 생성\n",
    "        patient_processed = pd.DataFrame(index=patient_raw.index)\n",
    "        \n",
    "        for feature_name in self.feature_names:\n",
    "            if feature_name in patient_raw.columns:\n",
    "                patient_processed[feature_name] = patient_raw[feature_name].copy()\n",
    "                print(f\"✅ {feature_name}: 원본 데이터 사용\")\n",
    "            else:\n",
    "                patient_processed[feature_name] = 0.0\n",
    "                print(f\"⚠️ {feature_name}: 기본값(0.0) 설정\")\n",
    "        \n",
    "        # 범주형 변수 전처리\n",
    "        print(\"\\n🔄 범주형 변수 전처리:\")\n",
    "        for col, encoder in self.label_encoders.items():\n",
    "            if col in patient_processed.columns:\n",
    "                try:\n",
    "                    original_value = patient_processed[col].iloc[0]\n",
    "                    print(f\"   - {col}: 원본값 = {original_value}\")\n",
    "                    \n",
    "                    if pd.isna(original_value) or original_value == 'NA':\n",
    "                        encoded_value = encoder.transform([encoder.classes_[0]])[0]\n",
    "                        patient_processed[col] = float(encoded_value)\n",
    "                        print(f\"     → 결측치를 '{encoder.classes_[0]}' ({encoded_value})로 대체\")\n",
    "                    else:\n",
    "                        str_value = str(original_value)\n",
    "                        if str_value in encoder.classes_:\n",
    "                            encoded_value = encoder.transform([str_value])[0]\n",
    "                            patient_processed[col] = float(encoded_value)\n",
    "                            print(f\"     → 인코딩: '{str_value}' → {encoded_value}\")\n",
    "                        else:\n",
    "                            encoded_value = encoder.transform([encoder.classes_[0]])[0]\n",
    "                            patient_processed[col] = float(encoded_value)\n",
    "                            print(f\"     → 새로운 값 '{str_value}'을 '{encoder.classes_[0]}' ({encoded_value})로 대체\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"     ❌ {col} 인코딩 실패: {e}\")\n",
    "                    patient_processed[col] = 0.0\n",
    "        \n",
    "        # 모든 컬럼을 수치형으로 변환\n",
    "        print(\"\\n🔢 데이터 타입 변환:\")\n",
    "        for col in patient_processed.columns:\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(patient_processed[col]):\n",
    "                    print(f\"   - {col}: 이미 숫자형\")\n",
    "                else:\n",
    "                    patient_processed[col] = pd.to_numeric(patient_processed[col], errors='coerce')\n",
    "                    print(f\"   - {col}: 숫자형으로 변환\")\n",
    "                \n",
    "                if patient_processed[col].isnull().any():\n",
    "                    patient_processed[col] = patient_processed[col].fillna(0.0)\n",
    "                    print(f\"   - {col}: 결측값을 0.0으로 대체\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {col} 수치형 변환 실패: {e}\")\n",
    "                patient_processed[col] = 0.0\n",
    "        \n",
    "        # 특성 순서를 훈련 시와 정확히 일치시키기\n",
    "        patient_processed = patient_processed[self.feature_names]\n",
    "        print(f\"✅ 특성 순서 정렬 완료: {patient_processed.shape}\")\n",
    "        print(f\"✅ 특성명 확인: {list(patient_processed.columns) == self.feature_names}\")\n",
    "        \n",
    "        # Imputer 적용 (안전한 방법)\n",
    "        if hasattr(self, 'num_imputer') and self.num_imputer is not None:\n",
    "            try:\n",
    "                print(f\"\\n📏 Imputer 적용 (안전한 방법):\")\n",
    "                print(f\"   - 입력 형태: {patient_processed.shape}\")\n",
    "                \n",
    "                if hasattr(self.num_imputer, 'n_features_in_'):\n",
    "                    expected_features = self.num_imputer.n_features_in_\n",
    "                    print(f\"   - Imputer 기대 특성 수: {expected_features}\")\n",
    "                    \n",
    "                    if patient_processed.shape[1] == expected_features:\n",
    "                        patient_values = patient_processed.values\n",
    "                        imputed_values = self.num_imputer.transform(patient_values)\n",
    "                        patient_processed = pd.DataFrame(\n",
    "                            imputed_values,\n",
    "                            columns=self.feature_names,\n",
    "                            index=patient_processed.index\n",
    "                        )\n",
    "                        print(f\"✅ Imputer 적용 완료\")\n",
    "                    else:\n",
    "                        print(f\"⚠️ 특성 수 불일치: 입력 {patient_processed.shape[1]} vs 기대 {expected_features}\")\n",
    "                        print(f\"⚠️ Imputer 건너뜀 - 결측값은 이미 처리됨\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Imputer 특성 정보 없음 - 안전하게 건너뜀\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Imputer 적용 중 오류 발생, 건너뜀: {e}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ Imputer가 없거나 None - 건너뜀\")\n",
    "        \n",
    "        # Scaler 적용 (안전한 방법)\n",
    "        if hasattr(self, 'scaler') and self.scaler is not None:\n",
    "            try:\n",
    "                print(f\"\\n📏 스케일링 적용 (안전한 방법):\")\n",
    "                print(f\"   - 입력 형태: {patient_processed.shape}\")\n",
    "                \n",
    "                if hasattr(self.scaler, 'n_features_in_'):\n",
    "                    expected_features = self.scaler.n_features_in_\n",
    "                    print(f\"   - Scaler 기대 특성 수: {expected_features}\")\n",
    "                    \n",
    "                    if patient_processed.shape[1] == expected_features:\n",
    "                        patient_values = patient_processed.values\n",
    "                        scaled_values = self.scaler.transform(patient_values)\n",
    "                        patient_features_scaled = pd.DataFrame(\n",
    "                            scaled_values,\n",
    "                            columns=self.feature_names,\n",
    "                            index=patient_processed.index\n",
    "                        )\n",
    "                        print(f\"✅ 스케일링 완료\")\n",
    "                        print(f\"✅ 최종 특성 형태: {patient_features_scaled.shape}\")\n",
    "                        return patient_features_scaled\n",
    "                    else:\n",
    "                        print(f\"⚠️ 특성 수 불일치: 입력 {patient_processed.shape[1]} vs 기대 {expected_features}\")\n",
    "                        print(f\"⚠️ 스케일링 없이 반환\")\n",
    "                        return patient_processed\n",
    "                else:\n",
    "                    print(f\"⚠️ Scaler 특성 정보 없음 - 안전하게 건너뜀\")\n",
    "                    return patient_processed\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 스케일링 중 오류 발생: {e}\")\n",
    "                print(f\"⚠️ 스케일링 없이 반환\")\n",
    "                return patient_processed\n",
    "        else:\n",
    "            print(f\"ℹ️ Scaler가 없거나 None - 건너뜀\")\n",
    "            return patient_processed\n",
    "    \n",
    "    def test_cdss_compatibility(self):\n",
    "        \"\"\"CDSS 호환성 테스트\"\"\"\n",
    "        print(\"\\n🔬 CDSS 호환성 테스트\")\n",
    "        \n",
    "        try:\n",
    "            # holdout 환자 데이터 전처리\n",
    "            holdout_features = self.preprocess_holdout_patient()\n",
    "            \n",
    "            # 각 모델로 예측 수행\n",
    "            predictions = {}\n",
    "            \n",
    "            for model_name, model_wrapper in self.models.items():\n",
    "                try:\n",
    "                    print(f\"\\n🔄 {model_name} 모델 예측 중...\")\n",
    "                    \n",
    "                    actual_model = model_wrapper['model']\n",
    "                    model_type = model_wrapper['model_type']\n",
    "                    \n",
    "                    print(f\"   - 모델 타입: {model_type}\")\n",
    "                    print(f\"   - 입력 특성 수: {holdout_features.shape[1]}\")\n",
    "                    \n",
    "                    if model_type in ['RandomSurvivalForest', 'CoxPHSurvivalAnalysis']:\n",
    "                        # 생존 모델\n",
    "                        pred = actual_model.predict(holdout_features)[0]\n",
    "                        predictions[model_name] = {\n",
    "                            'type': 'survival',\n",
    "                            'risk_score': pred\n",
    "                        }\n",
    "                        print(f\"✅ {model_name}: 위험도 점수 = {pred:.4f}\")\n",
    "                    else:\n",
    "                        # 분류 모델\n",
    "                        pred_class = actual_model.predict(holdout_features)[0]\n",
    "                        pred_proba = actual_model.predict_proba(holdout_features)[0]\n",
    "                        class_labels = model_wrapper['class_labels']\n",
    "                        \n",
    "                        predictions[model_name] = {\n",
    "                            'type': 'classification',\n",
    "                            'class': pred_class,\n",
    "                            'class_name': class_labels[pred_class],\n",
    "                            'probabilities': pred_proba\n",
    "                        }\n",
    "                        \n",
    "                        print(f\"✅ {model_name}: {class_labels[pred_class]} (확률: {pred_proba[pred_class]:.3f})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} 예측 실패: {e}\")\n",
    "                    predictions[model_name] = {'error': str(e)}\n",
    "            \n",
    "            return predictions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ CDSS 호환성 테스트 실패: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def save_models_for_cdss(self):\n",
    "        \"\"\"CDSS 호환 모델 저장\"\"\"\n",
    "        print(\"\\n💾 CDSS 호환 모델 저장\")\n",
    "        \n",
    "        # 전체 파이프라인을 하나의 객체로 저장\n",
    "        cdss_pipeline = {\n",
    "            'models': self.models,\n",
    "            'holdout_patient': self.holdout_patient,\n",
    "            'metadata': {\n",
    "                'created_date': datetime.now().isoformat(),\n",
    "                'model_version': '4.0',\n",
    "                'description': 'TCGA-LIHC 간암 치료 효과 예측 모델 (CDSS 호환 + 과적합 방지)',\n",
    "                'class_labels': ['치료효과 불량', '치료효과 양호']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 개별 모델도 저장\n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            try:\n",
    "                filename = f\"cdss_liver_cancer_treatment_{model_name.lower()}_model.pkl\"\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(model_wrapper, f)\n",
    "                print(f\"✅ {model_name} 모델 저장: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {model_name} 모델 저장 실패: {e}\")\n",
    "        \n",
    "        # 전체 파이프라인 저장\n",
    "        try:\n",
    "            pipeline_filename = \"cdss_liver_cancer_treatment_complete_pipeline.pkl\"\n",
    "            with open(pipeline_filename, 'wb') as f:\n",
    "                pickle.dump(cdss_pipeline, f)\n",
    "            print(f\"✅ 전체 파이프라인 저장: {pipeline_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파이프라인 저장 실패: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def plot_results(self, X_test, y_test_dur, y_test_event, y_test_eff):\n",
    "        \"\"\"결과 시각화 (치료 효과 예측 특화)\"\"\"\n",
    "        print(\"\\n📊 7. 결과 시각화\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(25, 35))\n",
    "        gs = fig.add_gridspec(5, 3)\n",
    "        axes = [\n",
    "            fig.add_subplot(gs[0, 0]),  # 치료효과별 생존 곡선\n",
    "            fig.add_subplot(gs[0, 1]),  # 치료효과 분포\n",
    "            fig.add_subplot(gs[0, 2]),  # 생존 모델 성능\n",
    "            fig.add_subplot(gs[1, 0]),  # 치료효과 분류 성능\n",
    "            fig.add_subplot(gs[1, 1]),  # AUC 성능\n",
    "            fig.add_subplot(gs[1, 2]),  # 특성 중요도 (XGBoost)\n",
    "            fig.add_subplot(gs[2, 0]),  # 특성 중요도 (LightGBM)\n",
    "            fig.add_subplot(gs[2, 1]),  # 치료효과별 생존율\n",
    "            fig.add_subplot(gs[2, 2]),  # CDSS 테스트 결과\n",
    "            fig.add_subplot(gs[3, :]),  # SHAP 시각화\n",
    "            fig.add_subplot(gs[4, :])   # LIME 시각화\n",
    "        ]\n",
    "        \n",
    "        fig.suptitle('간암 치료 효과 예측 모델 분석 결과 (CDSS 호환 + XAI + 과적합 방지)', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. 치료효과별 생존 곡선\n",
    "        print(\"🔍 치료효과별 생존 곡선 생성 중...\")\n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                label = '치료효과 양호' if eff_level == 1 else '치료효과 불량'\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask], label=f'{label} (n={mask.sum()})')\n",
    "                kmf.plot_survival_function(ax=axes[0])\n",
    "        \n",
    "        axes[0].set_title('치료효과별 생존 곡선 (Kaplan-Meier)')\n",
    "        axes[0].set_ylabel('생존 확률')\n",
    "        axes[0].set_xlabel('시간 (일)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. 치료효과 분포\n",
    "        eff_counts = pd.Series(y_test_eff).value_counts().sort_index()\n",
    "        colors = ['lightcoral', 'lightgreen']\n",
    "        labels = ['치료효과 불량', '치료효과 양호']\n",
    "        bars = axes[1].bar([labels[i] for i in eff_counts.index], \n",
    "                          eff_counts.values, color=colors)\n",
    "        axes[1].set_title('테스트 세트 치료효과 분포')\n",
    "        axes[1].set_ylabel('환자 수')\n",
    "        \n",
    "        for bar, value in zip(bars, eff_counts.values):\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                        f'{value}명', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 3. 생존 모델 성능 비교\n",
    "        survival_models = ['RSF', 'Cox_Survival']\n",
    "        survival_c_indices = []\n",
    "        survival_names = []\n",
    "        \n",
    "        for model_name in survival_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                c_index = self.results[model_name]['Test'].get('c_index', np.nan)\n",
    "                if not np.isnan(c_index):\n",
    "                    survival_c_indices.append(c_index)\n",
    "                    survival_names.append(model_name)\n",
    "        \n",
    "        if survival_c_indices:\n",
    "            bars = axes[2].bar(survival_names, survival_c_indices, \n",
    "                             color=['skyblue', 'lightcoral'][:len(survival_names)])\n",
    "            axes[2].set_title('생존 모델 성능 (C-index)')\n",
    "            axes[2].set_ylabel('C-index')\n",
    "            axes[2].set_ylim(0.5, 1.0)\n",
    "            axes[2].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, survival_c_indices):\n",
    "                axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 4. 치료효과 분류 모델 성능 (Accuracy)\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        classification_accuracies = []\n",
    "        classification_names = []\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                accuracy = self.results[model_name]['Test'].get('accuracy', np.nan)\n",
    "                if not np.isnan(accuracy):\n",
    "                    classification_accuracies.append(accuracy)\n",
    "                    classification_names.append(model_name)\n",
    "        \n",
    "        if classification_accuracies:\n",
    "            bars = axes[3].bar(classification_names, classification_accuracies, \n",
    "                             color=['lightgreen', 'orange', 'purple'][:len(classification_names)])\n",
    "            axes[3].set_title('치료효과 분류 모델 성능 (Accuracy)')\n",
    "            axes[3].set_ylabel('Accuracy')\n",
    "            axes[3].set_ylim(0, 1.0)\n",
    "            axes[3].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, classification_accuracies):\n",
    "                axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 5. AUC 성능\n",
    "        classification_aucs = []\n",
    "        auc_names = []\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                auc = self.results[model_name]['Test'].get('auc', np.nan)\n",
    "                if not np.isnan(auc):\n",
    "                    classification_aucs.append(auc)\n",
    "                    auc_names.append(model_name)\n",
    "        \n",
    "        if classification_aucs:\n",
    "            bars = axes[4].bar(auc_names, classification_aucs, \n",
    "                             color=['lightgreen', 'orange', 'purple'][:len(auc_names)])\n",
    "            axes[4].set_title('치료효과 분류 모델 성능 (AUC)')\n",
    "            axes[4].set_ylabel('AUC')\n",
    "            axes[4].set_ylim(0, 1.0)\n",
    "            axes[4].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, classification_aucs):\n",
    "                axes[4].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 6-7. 특성 중요도 시각화\n",
    "        for idx, model_name in enumerate(['XGB_Treatment', 'LGB_Treatment']):\n",
    "            ax_idx = 5 + idx\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    model_wrapper = self.models[model_name]\n",
    "                    importance = model_wrapper['training_info']['feature_importance']\n",
    "                    \n",
    "                    feature_importance_df = pd.DataFrame({\n",
    "                        'feature': self.feature_names,\n",
    "                        'importance': importance\n",
    "                    }).sort_values('importance', ascending=True).tail(10)\n",
    "                    \n",
    "                    color = 'orange' if 'XGB' in model_name else 'purple'\n",
    "                    bars = axes[ax_idx].barh(range(len(feature_importance_df)), \n",
    "                                           feature_importance_df['importance'],\n",
    "                                           color=color)\n",
    "                    \n",
    "                    axes[ax_idx].set_yticks(range(len(feature_importance_df)))\n",
    "                    axes[ax_idx].set_yticklabels(feature_importance_df['feature'], fontsize=10)\n",
    "                    axes[ax_idx].set_title(f'특성 중요도 ({model_name})', fontsize=12, fontweight='bold')\n",
    "                    axes[ax_idx].set_xlabel('중요도')\n",
    "                    axes[ax_idx].grid(True, alpha=0.3, axis='x')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {model_name} 특성 중요도 시각화 실패: {e}\")\n",
    "        \n",
    "        # 8. 치료효과별 생존율 요약\n",
    "        survival_summary = []\n",
    "        time_points = [365, 1095, 1825]  # 1년, 3년, 5년\n",
    "        \n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask])\n",
    "                \n",
    "                survival_rates = []\n",
    "                for time_point in time_points:\n",
    "                    try:\n",
    "                        survival_rate = kmf.survival_function_at_times(time_point).values[0]\n",
    "                        survival_rates.append(survival_rate * 100)\n",
    "                    except:\n",
    "                        survival_rates.append(np.nan)\n",
    "                \n",
    "                survival_summary.append(survival_rates)\n",
    "            else:\n",
    "                survival_summary.append([np.nan, np.nan, np.nan])\n",
    "        \n",
    "        # 생존율 히트맵\n",
    "        survival_df = pd.DataFrame(survival_summary, \n",
    "                                  index=['치료효과 불량', '치료효과 양호'],\n",
    "                                  columns=['1년', '3년', '5년'])\n",
    "        \n",
    "        sns.heatmap(survival_df, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                   ax=axes[7], cbar_kws={'label': '생존율 (%)'})\n",
    "        axes[7].set_title('치료효과별 생존율 요약')\n",
    "        axes[7].set_ylabel('치료효과 그룹')\n",
    "        \n",
    "        # 9. CDSS 테스트 결과\n",
    "        cdss_results = self.test_cdss_compatibility()\n",
    "        if cdss_results:\n",
    "            model_names_cdss = []\n",
    "            predictions_cdss = []\n",
    "            \n",
    "            for model_name, result in cdss_results.items():\n",
    "                if 'type' in result:\n",
    "                    model_names_cdss.append(model_name)\n",
    "                    if result['type'] == 'classification':\n",
    "                        predictions_cdss.append(result['class'])\n",
    "                    else:\n",
    "                        predictions_cdss.append(result['risk_score'])\n",
    "            \n",
    "            if model_names_cdss:\n",
    "                bars = axes[8].bar(model_names_cdss, predictions_cdss, \n",
    "                                 color=['skyblue', 'lightcoral', 'lightgreen', 'orange', 'purple'][:len(model_names_cdss)])\n",
    "                axes[8].set_title('CDSS 호환성 테스트\\n(Holdout 환자 예측)')\n",
    "                axes[8].set_ylabel('예측값')\n",
    "                axes[8].grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "                for bar, value in zip(bars, predictions_cdss):\n",
    "                    axes[8].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                               f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 10-11. XAI 시각화 로드\n",
    "        try:\n",
    "            model_name = 'XGB_Treatment' if 'XGB_Treatment' in self.shap_explainers else 'RF_Treatment'\n",
    "            if model_name:\n",
    "                img = plt.imread(f\"shap_summary_{model_name}.png\")\n",
    "                axes[9].imshow(img)\n",
    "                axes[9].axis('off')\n",
    "                axes[9].set_title('SHAP 전역 설명 (치료효과 예측)', fontsize=12)\n",
    "        except Exception as e:\n",
    "            axes[9].text(0.5, 0.5, 'SHAP 시각화 불러오기 실패', \n",
    "                        ha='center', va='center', transform=axes[9].transAxes,\n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        try:\n",
    "            model_name = 'XGB_Treatment' if 'XGB_Treatment' in self.lime_explainers else 'RF_Treatment'\n",
    "            if model_name:\n",
    "                img = plt.imread(f\"lime_explanation_{model_name}_0.png\")\n",
    "                axes[10].imshow(img)\n",
    "                axes[10].axis('off')\n",
    "                axes[10].set_title('LIME 개별 설명 (첫 번째 환자)', fontsize=12)\n",
    "        except Exception as e:\n",
    "            axes[10].text(0.5, 0.5, 'LIME 시각화 불러오기 실패', \n",
    "                         ha='center', va='center', transform=axes[10].transAxes,\n",
    "                         fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = \"liver_cancer_treatment_effect_prediction_cdss_xai_overfitting_fixed.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"📁 시각화 결과 저장: {save_path}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"결과 보고서 생성\"\"\"\n",
    "        print(\"\\n📋 8. 결과 보고서 생성\")\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"=\"*60)\n",
    "        report.append(\"간암 환자 치료 효과 예측 모델 분석 결과 (XAI + CDSS 호환 + 과적합 방지)\")\n",
    "        report.append(\"=\"*60)\n",
    "        report.append(f\"분석 일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"데이터 경로: {self.data_path}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # 데이터 요약\n",
    "        report.append(\"📊 데이터 요약\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"총 환자 수: {len(self.processed_df) + 1}\")  # holdout 포함\n",
    "        report.append(f\"모델 훈련용: {len(self.processed_df)}명\")\n",
    "        report.append(f\"CDSS 테스트용: 1명\")\n",
    "        report.append(f\"사망률: {self.processed_df['event'].mean()*100:.1f}%\")\n",
    "        report.append(f\"중간 생존 시간: {self.processed_df['duration'].median():.0f}일\")\n",
    "        report.append(f\"치료효과 양호율: {self.processed_df['treatment_effectiveness'].mean()*100:.1f}%\")\n",
    "        report.append(f\"사용된 특성 수: {len(self.feature_names)}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # 모델 성능\n",
    "        report.append(\"🤖 모델 성능\")\n",
    "        report.append(\"-\" * 30)\n",
    "        \n",
    "        # 생존 모델 성능\n",
    "        report.append(\"\\n생존 예측 모델 (C-index):\")\n",
    "        survival_models = ['RSF', 'Cox_Survival']\n",
    "        for model_name in survival_models:\n",
    "            if model_name in self.results:\n",
    "                for dataset in ['Train', 'Validation', 'Test']:\n",
    "                    if dataset in self.results[model_name]:\n",
    "                        metrics = self.results[model_name][dataset]\n",
    "                        if 'c_index' in metrics:\n",
    "                            report.append(f\"  {model_name} {dataset}: C-index = {metrics['c_index']:.3f}\")\n",
    "        \n",
    "        # 치료효과 분류 모델 성능\n",
    "        report.append(\"\\n치료효과 분류 모델 (Accuracy):\")\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results:\n",
    "                for dataset in ['Train', 'Validation', 'Test']:\n",
    "                    if dataset in self.results[model_name]:\n",
    "                        metrics = self.results[model_name][dataset]\n",
    "                        if 'accuracy' in metrics:\n",
    "                            report.append(f\"  {model_name} {dataset}: Accuracy = {metrics['accuracy']:.3f}\")\n",
    "                        if 'auc' in metrics and not np.isnan(metrics['auc']):\n",
    "                            report.append(f\"  {model_name} {dataset}: AUC = {metrics['auc']:.3f}\")\n",
    "        \n",
    "        # 과적합 분석\n",
    "        report.append(\"\\n과적합 분석:\")\n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results:\n",
    "                train_acc = self.results[model_name].get('Train', {}).get('accuracy', np.nan)\n",
    "                test_acc = self.results[model_name].get('Test', {}).get('accuracy', np.nan)\n",
    "                if not np.isnan(train_acc) and not np.isnan(test_acc):\n",
    "                    overfitting_gap = train_acc - test_acc\n",
    "                    report.append(f\"  {model_name}: 과적합 정도 = {overfitting_gap:.3f} ({'심각' if overfitting_gap > 0.1 else '양호' if overfitting_gap < 0.05 else '보통'})\")\n",
    "        \n",
    "        # 최고 성능 모델\n",
    "        test_performances = {}\n",
    "        for model_name in self.results:\n",
    "            if 'Test' in self.results[model_name]:\n",
    "                metrics = self.results[model_name]['Test']\n",
    "                if 'c_index' in metrics:\n",
    "                    test_performances[f\"{model_name}_C-index\"] = metrics['c_index']\n",
    "                elif 'accuracy' in metrics:\n",
    "                    test_performances[f\"{model_name}_Accuracy\"] = metrics['accuracy']\n",
    "        \n",
    "        if test_performances:\n",
    "            best_model = max(test_performances, key=test_performances.get)\n",
    "            report.append(f\"\\n🏆 최고 성능 모델: {best_model} (점수: {test_performances[best_model]:.3f})\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "        report.append(\"ℹ️  특징:\")\n",
    "        report.append(\"   - CDSS 호환 치료 효과 예측 모델\")\n",
    "        report.append(\"   - XAI 설명 가능성 포함 (SHAP, LIME)\")\n",
    "        report.append(\"   - Holdout 환자로 실제 예측 테스트\")\n",
    "        report.append(\"   - 과적합 방지 기법 적용\")\n",
    "        report.append(\"   - 생존 예측 + 치료 효과 분류 통합\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"=\"*60)\n",
    "        \n",
    "        # 보고서 저장\n",
    "        report_text = \"\\n\".join(report)\n",
    "        with open(\"liver_cancer_treatment_effect_prediction_cdss_overfitting_fixed_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(\"📁 보고서 저장: liver_cancer_treatment_effect_prediction_cdss_overfitting_fixed_report.txt\")\n",
    "        print(\"\\n\" + report_text)\n",
    "        \n",
    "        return report_text\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"전체 분석 실행 (XAI + CDSS 호환 + 과적합 방지)\"\"\"\n",
    "        print(\"🎯 간암 치료 효과 예측 모델 전체 분석 시작 (XAI + CDSS 호환 + 과적합 방지)\")\n",
    "        \n",
    "        try:\n",
    "            # 1. 데이터 로드\n",
    "            if not self.load_and_explore_data():\n",
    "                return False\n",
    "            \n",
    "            # 2. 데이터 전처리\n",
    "            if not self.preprocess_data():\n",
    "                return False\n",
    "            \n",
    "            # 3. 특성 준비 (CDSS 호환)\n",
    "            X, y_structured, y_duration, y_event, y_effectiveness = self.prepare_features()\n",
    "            \n",
    "            # 4. 데이터 분할\n",
    "            (X_train, X_val, X_test, \n",
    "             y_train_struct, y_val_struct, y_test_struct,\n",
    "             y_train_dur, y_val_dur, y_test_dur,\n",
    "             y_train_event, y_val_event, y_test_event,\n",
    "             y_train_eff, y_val_eff, y_test_eff) = self.split_data(X, y_structured, y_duration, y_event, y_effectiveness)\n",
    "            \n",
    "            # 5. 모델 훈련 (과적합 방지)\n",
    "            if not self.train_models(X_train, X_val, X_test,\n",
    "                                   y_train_struct, y_val_struct, y_test_struct,\n",
    "                                   y_train_dur, y_val_dur, y_test_dur,\n",
    "                                   y_train_event, y_val_event, y_test_event,\n",
    "                                   y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 6. 모델 평가\n",
    "            if not self.evaluate_models(X_train, X_val, X_test,\n",
    "                                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                                       y_train_event, y_val_event, y_test_event,\n",
    "                                       y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 7. XAI 설명 생성\n",
    "            self.explain_models(X_train, X_test)\n",
    "            \n",
    "            # 8. XAI 시각화 생성\n",
    "            self.generate_xai_visualizations(X_test)\n",
    "            \n",
    "            # 9. 시각화 (XAI + CDSS 포함)\n",
    "            if not self.plot_results(X_test, y_test_dur, y_test_event, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 10. 보고서 생성\n",
    "            self.generate_report()\n",
    "            \n",
    "            # 11. CDSS 호환 모델 저장\n",
    "            self.save_models_for_cdss()\n",
    "            \n",
    "            print(\"\\n🎉 전체 분석 완료!\")\n",
    "            print(f\"⏰ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 분석 중 오류 발생: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 경로\n",
    "    data_path = r\"C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\"\n",
    "    \n",
    "    # 분석 실행\n",
    "    treatment_predictor = LiverCancerTreatmentEffectPredictorCDSS(data_path)\n",
    "    success = treatment_predictor.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n✨ 모든 분석이 성공적으로 완료되었습니다!\")\n",
    "        print(\"📁 생성된 파일들:\")\n",
    "        print(\"   - liver_cancer_treatment_effect_prediction_cdss_xai_overfitting_fixed.png (시각화 결과)\")\n",
    "        print(\"   - liver_cancer_treatment_effect_prediction_cdss_overfitting_fixed_report.txt (분석 보고서)\")\n",
    "        print(\"   - cdss_liver_cancer_treatment_*_model.pkl (CDSS 호환 개별 모델)\")\n",
    "        print(\"   - cdss_liver_cancer_treatment_complete_pipeline.pkl (전체 파이프라인)\")\n",
    "        print(\"   - shap_*.png (SHAP 설명)\")\n",
    "        print(\"   - lime_*.png (LIME 설명)\")\n",
    "        print(\"\\n🔬 주요 개선사항:\")\n",
    "        print(\"   - 과적합 방지 기법 적용\")\n",
    "        print(\"   - 균형잡힌 모델 하이퍼파라미터\")\n",
    "        print(\"   - 안전한 CDSS 호환성\")\n",
    "        print(\"   - XAI 설명 가능성 포함\")\n",
    "    else:\n",
    "        print(\"\\n❌ 분석 중 문제가 발생했습니다. 로그를 확인해주세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496b814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏥 Submitter ID: TCGA-CC-A9FS\n",
      "🆔 원본 인덱스: 332\n",
      "👤 연령: 20157.0\n",
      "👤 성별: male\n",
      "👤 생존 상태: Alive\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터에서 holdout 환자 찾기\n",
    "holdout_idx = treatment_predictor.processed_df.sample(n=1, random_state=42).index[0]\n",
    "\n",
    "# 원본 데이터에서 해당 환자 정보 추출\n",
    "if 'submitter_id' in treatment_predictor.df.columns:\n",
    "    original_patient = treatment_predictor.df.loc[holdout_idx]\n",
    "    print(f\"🏥 Submitter ID: {original_patient['submitter_id']}\")\n",
    "    print(f\"🆔 원본 인덱스: {holdout_idx}\")\n",
    "    \n",
    "    # 추가 정보도 확인 가능\n",
    "    print(f\"👤 연령: {original_patient.get('age_at_diagnosis', 'N/A')}\")\n",
    "    print(f\"👤 성별: {original_patient.get('gender', 'N/A')}\")\n",
    "    print(f\"👤 생존 상태: {original_patient.get('vital_status', 'N/A')}\")\n",
    "else:\n",
    "    print(\"⚠️ submitter_id 컬럼이 데이터에 없습니다\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc0e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🏥 HOLDOUT 환자 상세 정보\n",
      "============================================================\n",
      "🆔 Submitter ID: TCGA-CC-A9FS\n",
      "🆔 원본 인덱스: 332\n",
      "\n",
      "📋 상세 임상 정보:\n",
      "----------------------------------------\n",
      "        \"vital_status\": \"Alive\",\n",
      "        \"days_to_death\": \"None\",\n",
      "        \"days_to_last_follow_up\": \"211.0\",\n",
      "        \"age_at_diagnosis\": \"20157.0\",\n",
      "        \"gender\": \"male\",\n",
      "        \"race\": \"asian\",\n",
      "        \"ethnicity\": \"not hispanic or latino\",\n",
      "        \"ajcc_pathologic_stage\": \"Stage II\",\n",
      "        \"ajcc_pathologic_t\": \"T2\",\n",
      "        \"ajcc_pathologic_n\": \"N0\",\n",
      "        \"ajcc_pathologic_m\": \"M0\",\n",
      "        \"child_pugh_classification\": \"Unknown\",\n",
      "        \"ishak_fibrosis_score\": \"None\",\n",
      "        \"tumor_grade\": \"G2\",\n",
      "        \"primary_diagnosis\": \"Hepatocellular carcinoma, NOS\",\n",
      "        \"tissue_or_organ_of_origin\": \"Liver\",\n",
      "        \"site_of_resection_or_biopsy\": \"Liver\",\n",
      "        \"morphology\": \"8170/3\",\n",
      "        \"residual_disease\": \"R0\",\n",
      "        \"classification_of_tumor\": \"primary\",\n",
      "        \"prior_malignancy\": \"no\",\n",
      "        \"synchronous_malignancy\": \"No\",\n",
      "        \"prior_treatment\": \"No\",\n",
      "        \"treatments_pharmaceutical_treatment_type\": \"Pharmaceutical Therapy, NOS\",\n",
      "        \"treatments_pharmaceutical_treatment_or_therapy\": \"unknown\",\n",
      "        \"treatments_pharmaceutical_treatment_intent_type\": \"Adjuvant\",\n",
      "        \"treatments_radiation_treatment_type\": \"Radiation Therapy, NOS\",\n",
      "        \"treatments_radiation_treatment_or_therapy\": \"unknown\",\n",
      "        \"treatments_radiation_treatment_intent_type\": \"Adjuvant\",\n",
      "        \"year_of_diagnosis\": \"2013.0\",\n",
      "\n",
      "📊 JSON 형태로 출력:\n",
      "{\n",
      "    \"submitter_id\": \"TCGA-CC-A9FS\",\n",
      "    \"index\": 332,\n",
      "    \"vital_status\": \"Alive\",\n",
      "    \"days_to_death\": null,\n",
      "    \"days_to_last_follow_up\": 211.0,\n",
      "    \"age_at_diagnosis\": 20157.0,\n",
      "    \"gender\": \"male\",\n",
      "    \"race\": \"asian\",\n",
      "    \"ethnicity\": \"not hispanic or latino\",\n",
      "    \"ajcc_pathologic_stage\": \"Stage II\",\n",
      "    \"ajcc_pathologic_t\": \"T2\",\n",
      "    \"ajcc_pathologic_n\": \"N0\",\n",
      "    \"ajcc_pathologic_m\": \"M0\",\n",
      "    \"child_pugh_classification\": \"Unknown\",\n",
      "    \"ishak_fibrosis_score\": null,\n",
      "    \"tumor_grade\": \"G2\",\n",
      "    \"primary_diagnosis\": \"Hepatocellular carcinoma, NOS\",\n",
      "    \"tissue_or_organ_of_origin\": \"Liver\",\n",
      "    \"site_of_resection_or_biopsy\": \"Liver\",\n",
      "    \"morphology\": \"8170/3\",\n",
      "    \"residual_disease\": \"R0\",\n",
      "    \"classification_of_tumor\": \"primary\",\n",
      "    \"prior_malignancy\": \"no\",\n",
      "    \"synchronous_malignancy\": \"No\",\n",
      "    \"prior_treatment\": \"No\",\n",
      "    \"treatments_pharmaceutical_treatment_type\": \"Pharmaceutical Therapy, NOS\",\n",
      "    \"treatments_pharmaceutical_treatment_or_therapy\": \"unknown\",\n",
      "    \"treatments_pharmaceutical_treatment_intent_type\": \"Adjuvant\",\n",
      "    \"treatments_radiation_treatment_type\": \"Radiation Therapy, NOS\",\n",
      "    \"treatments_radiation_treatment_or_therapy\": \"unknown\",\n",
      "    \"treatments_radiation_treatment_intent_type\": \"Adjuvant\",\n",
      "    \"year_of_diagnosis\": 2013.0,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터에서 holdout 환자 찾기\n",
    "holdout_idx = treatment_predictor.processed_df.sample(n=1, random_state=42).index[0]\n",
    "\n",
    "# 출력할 모든 컬럼 리스트\n",
    "detailed_columns = [\n",
    "    \"vital_status\", \"days_to_death\", \"days_to_last_follow_up\", \n",
    "    \"age_at_diagnosis\", \"gender\", \"race\", \"ethnicity\",\n",
    "    \"ajcc_pathologic_stage\", \"ajcc_pathologic_t\", \"ajcc_pathologic_n\", \"ajcc_pathologic_m\",\n",
    "    \"child_pugh_classification\", \"ishak_fibrosis_score\", \"tumor_grade\",\n",
    "    \"primary_diagnosis\", \"tissue_or_organ_of_origin\", \"site_of_resection_or_biopsy\",\n",
    "    \"morphology\", \"residual_disease\", \"classification_of_tumor\",\n",
    "    \"prior_malignancy\", \"synchronous_malignancy\", \"prior_treatment\",\n",
    "    \"treatments_pharmaceutical_treatment_type\", \"treatments_pharmaceutical_treatment_or_therapy\",\n",
    "    \"treatments_pharmaceutical_treatment_intent_type\", \"treatments_radiation_treatment_type\",\n",
    "    \"treatments_radiation_treatment_or_therapy\", \"treatments_radiation_treatment_intent_type\",\n",
    "    \"year_of_diagnosis\"\n",
    "]\n",
    "\n",
    "# 원본 데이터에서 해당 환자 정보 추출\n",
    "if 'submitter_id' in treatment_predictor.df.columns:\n",
    "    original_patient = treatment_predictor.df.loc[holdout_idx]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"🏥 HOLDOUT 환자 상세 정보\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🆔 Submitter ID: {original_patient['submitter_id']}\")\n",
    "    print(f\"🆔 원본 인덱스: {holdout_idx}\")\n",
    "    print(\"\\n📋 상세 임상 정보:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # 모든 상세 정보 출력\n",
    "    for col in detailed_columns:\n",
    "        if col in original_patient.index:\n",
    "            value = original_patient[col]\n",
    "            # None 값을 적절히 처리\n",
    "            if pd.isna(value) or value is None:\n",
    "                value = \"None\"\n",
    "            print(f'        \"{col}\": \"{value}\",')\n",
    "        else:\n",
    "            print(f'        \"{col}\": \"N/A\",')\n",
    "    \n",
    "    print(\"\\n📊 JSON 형태로 출력:\")\n",
    "    print(\"{\")\n",
    "    print(f'    \"submitter_id\": \"{original_patient[\"submitter_id\"]}\",')\n",
    "    print(f'    \"index\": {holdout_idx},')\n",
    "    \n",
    "    for col in detailed_columns:\n",
    "        if col in original_patient.index:\n",
    "            value = original_patient[col]\n",
    "            if pd.isna(value) or value is None:\n",
    "                print(f'    \"{col}\": null,')\n",
    "            elif isinstance(value, str):\n",
    "                print(f'    \"{col}\": \"{value}\",')\n",
    "            else:\n",
    "                print(f'    \"{col}\": {value},')\n",
    "        else:\n",
    "            print(f'    \"{col}\": \"N/A\",')\n",
    "    print(\"}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ submitter_id 컬럼이 데이터에 없습니다\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
