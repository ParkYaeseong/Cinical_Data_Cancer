{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259c2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\02\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 13.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)\n",
      "ğŸ“ ë°ì´í„° ê²½ë¡œ: G:\\.shortcut-targets-by-id\\1aXfYtUWSYS8foz14MAJMhDH7IHhG1wNZ\\2ì¡°\\ë°ì´í„°\\clinical model\\kidney\\TCGA-KIRP_clinical_data.csv\n",
      "â° ì‹œì‘ ì‹œê°„: 2025-06-20 12:45:05\n",
      "============================================================\n",
      "ğŸš€ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì „ì²´ ë¶„ì„ ì‹œì‘\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: 291í–‰ Ã— 97ì—´\n",
      "ğŸ“ˆ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\n",
      "   - ì´ í™˜ì ìˆ˜: 291\n",
      "   - ì´ ì»¬ëŸ¼ ìˆ˜: 97\n",
      "   - ìƒì¡´ í™˜ì: 247ëª…\n",
      "   - ì‚¬ë§ í™˜ì: 44ëª…\n",
      "   - ì‚¬ë§ë¥ : 15.1%\n",
      "\n",
      "ğŸ”§ 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
      "âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: 28ê°œ\n",
      "ğŸ”„ ìƒì¡´ ë³€ìˆ˜ ìƒì„± ì¤‘...\n",
      "âœ… ìœ íš¨í•œ ìƒì¡´ ë°ì´í„°: 288ëª…\n",
      "   - ì‚¬ë§ ì´ë²¤íŠ¸: 44ê±´\n",
      "   - ì¤‘ê°„ ìƒì¡´ ì‹œê°„: 768ì¼\n",
      "   - ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸: 145ëª…\n",
      "\n",
      "ğŸ“‹ ê²°ì¸¡ê°’ ë¶„ì„:\n",
      "   - days_to_death: 244ê°œ (84.7%)\n",
      "   - treatments_pharmaceutical_treatment_type: 78ê°œ (27.1%)\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 79ê°œ (27.4%)\n",
      "   - treatments_pharmaceutical_treatment_or_therapy: 78ê°œ (27.1%)\n",
      "   - treatments_radiation_treatment_type: 63ê°œ (21.9%)\n",
      "   - treatments_radiation_treatment_or_therapy: 63ê°œ (21.9%)\n",
      "   - ajcc_pathologic_stage: 30ê°œ (10.4%)\n",
      "   - ajcc_pathologic_n: 1ê°œ (0.3%)\n",
      "   - ajcc_pathologic_m: 15ê°œ (5.2%)\n",
      "   - age_at_diagnosis: 26ê°œ (9.0%)\n",
      "   - pack_years_smoked: 212ê°œ (73.6%)\n",
      "   - days_to_diagnosis: 24ê°œ (8.3%)\n",
      "   - year_of_diagnosis: 22ê°œ (7.6%)\n",
      "ğŸ—‘ï¸  ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼ ì œê±°: ['days_to_death']\n",
      "\n",
      "ğŸ¯ 3. íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”©\n",
      "ğŸ”„ CDSS í…ŒìŠ¤íŠ¸ìš© í™˜ì ë¶„ë¦¬ ì¤‘...\n",
      "   - CDSS í…ŒìŠ¤íŠ¸ í™˜ì: 46\n",
      "   - ëª¨ë¸ í›ˆë ¨ìš© ë°ì´í„°: 287ëª…\n",
      "ğŸ“Š ì´ˆê¸° íŠ¹ì„± ê°œìˆ˜: 25\n",
      "ğŸ“Š ìƒ˜í”Œ ê°œìˆ˜: 287\n",
      "ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜: 21ê°œ\n",
      "ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: 4ê°œ\n",
      "ğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "   ğŸ” treatments_pharmaceutical_treatment_type ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Pharmaceutical Therapy, NOS': 209, nan: 78}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Pharmaceutical Therapy, NOS'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_pharmaceutical_treatment_intent_type ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Adjuvant': 208, nan: 79}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Adjuvant'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_pharmaceutical_treatment_or_therapy ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'no': 177, nan: 78, 'unknown': 30}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'no'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_radiation_treatment_type ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Radiation Therapy, NOS': 218, nan: 63, 'Radiation, External Beam': 6}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Radiation Therapy, NOS'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_radiation_treatment_or_therapy ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'no': 187, nan: 63, 'unknown': 28}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'no'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_stage ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Stage I': 171, 'Stage III': 51, nan: 29}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Stage I'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_t ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'T1a': 107, 'T1b': 62, 'T3a': 38}\n",
      "\n",
      "   ğŸ” ajcc_pathologic_n ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'NX': 209, 'N0': 50, 'N1': 23}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'NX'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_m ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'MX': 168, 'M0': 95, nan: 15}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'MX'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” morphology ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'8260/3': 287}\n",
      "\n",
      "   ğŸ” primary_diagnosis ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Papillary adenocarcinoma, NOS': 287}\n",
      "\n",
      "   ğŸ” gender ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'male': 210, 'female': 77}\n",
      "\n",
      "   ğŸ” race ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'white': 204, 'black or african american': 61, 'not reported': 14}\n",
      "\n",
      "   ğŸ” ethnicity ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'not hispanic or latino': 241, 'not reported': 35, 'hispanic or latino': 11}\n",
      "\n",
      "   ğŸ” prior_treatment ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'No': 287}\n",
      "\n",
      "   ğŸ” prior_malignancy ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'no': 249, 'yes': 38}\n",
      "\n",
      "   ğŸ” tobacco_smoking_status ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Lifelong Non-Smoker': 115, 'Current Reformed Smoker for > 15 yrs': 46, 'Current Reformed Smoker for < or = 15 yrs': 39}\n",
      "      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Lifelong Non-Smoker'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” laterality ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Left': 158, 'Right': 126, 'Bilateral': 2}\n",
      "\n",
      "   ğŸ” site_of_resection_or_biopsy ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Kidney, NOS': 287}\n",
      "\n",
      "   ğŸ” tissue_or_organ_of_origin ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Kidney, NOS': 287}\n",
      "\n",
      "   ğŸ” synchronous_malignancy ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'No': 269, 'Yes': 18}\n",
      "\n",
      "ğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©:\n",
      "   - treatments_pharmaceutical_treatment_type ì¸ì½”ë”© ë§¤í•‘: {'Pharmaceutical Therapy, NOS': 0}\n",
      "   - treatments_pharmaceutical_treatment_intent_type ì¸ì½”ë”© ë§¤í•‘: {'Adjuvant': 0}\n",
      "   - treatments_pharmaceutical_treatment_or_therapy ì¸ì½”ë”© ë§¤í•‘: {'no': 0, 'unknown': 1, 'yes': 2}\n",
      "   - treatments_radiation_treatment_type ì¸ì½”ë”© ë§¤í•‘: {'Radiation Therapy, NOS': 0, 'Radiation, External Beam': 1}\n",
      "   - treatments_radiation_treatment_or_therapy ì¸ì½”ë”© ë§¤í•‘: {'no': 0, 'unknown': 1, 'yes': 2}\n",
      "   - ajcc_pathologic_stage ì¸ì½”ë”© ë§¤í•‘: {'Stage I': 0, 'Stage II': 1, 'Stage III': 2, 'Stage IV': 3}\n",
      "   - ajcc_pathologic_t ì¸ì½”ë”© ë§¤í•‘: {'T1': 0, 'T1a': 1, 'T1b': 2, 'T2': 3, 'T2a': 4, 'T2b': 5, 'T3': 6, 'T3a': 7, 'T3b': 8, 'T3c': 9, 'T4': 10, 'TX': 11}\n",
      "   - ajcc_pathologic_n ì¸ì½”ë”© ë§¤í•‘: {'N0': 0, 'N1': 1, 'N2': 2, 'NX': 3}\n",
      "   - ajcc_pathologic_m ì¸ì½”ë”© ë§¤í•‘: {'M0': 0, 'M1': 1, 'MX': 2}\n",
      "   - morphology ì¸ì½”ë”© ë§¤í•‘: {'8260/3': 0}\n",
      "   - primary_diagnosis ì¸ì½”ë”© ë§¤í•‘: {'Papillary adenocarcinoma, NOS': 0}\n",
      "   - prior_treatment ì¸ì½”ë”© ë§¤í•‘: {'No': 0}\n",
      "   - prior_malignancy ì¸ì½”ë”© ë§¤í•‘: {'no': 0, 'yes': 1}\n",
      "   - synchronous_malignancy ì¸ì½”ë”© ë§¤í•‘: {'No': 0, 'Yes': 1}\n",
      "\n",
      "ğŸ“ ì „ì²´ íŠ¹ì„± Imputer í›ˆë ¨:\n",
      "   - ì „ì²´ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… ì „ì²´ íŠ¹ì„± Imputer í›ˆë ¨ ì™„ë£Œ: 25ê°œ íŠ¹ì„±\n",
      "âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ (CDSS í˜¸í™˜)\n",
      "\n",
      "âœ‚ï¸  4. ë°ì´í„° ë¶„í•  (í›ˆë ¨:ê²€ì¦:í…ŒìŠ¤íŠ¸ = 60:20:20)\n",
      "ğŸ“Š í›ˆë ¨ ì„¸íŠ¸: 171ëª… (ì‚¬ë§: 26ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 87ëª…)\n",
      "ğŸ“Š ê²€ì¦ ì„¸íŠ¸: 58ëª… (ì‚¬ë§: 7ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 29ëª…)\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 58ëª… (ì‚¬ë§: 11ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 29ëª…)\n",
      "ğŸ“Š CDSS í…ŒìŠ¤íŠ¸: 1ëª… (ë³„ë„ ë³´ê´€)\n",
      "\n",
      "ğŸ¤– 5. ëª¨ë¸ í›ˆë ¨ (ê· í˜•ì¡íŒ ê³¼ì í•© ë°©ì§€)\n",
      "ğŸ”„ Random Survival Forest í›ˆë ¨ ì¤‘...\n",
      "âœ… Random Survival Forest í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… Cox ìƒì¡´ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Random Forest ê· í˜•ì¡íŒ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ ì¤‘...\n",
      "âœ… Random Forest ê· í˜•ì¡íŒ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ XGBoost ì ì ˆí•œ ì •ê·œí™”ë¡œ í›ˆë ¨ ì¤‘...\n",
      "âœ… XGBoost ì ì ˆí•œ ì •ê·œí™” í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ LightGBM ê³¼ì í•© ë°©ì§€ ìµœì í™”ë¡œ í›ˆë ¨ ì¤‘...\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.509156\n",
      "âœ… LightGBM ê³¼ì í•© ë°©ì§€ í›ˆë ¨ ì™„ë£Œ\n",
      "\n",
      "ğŸ¯ ê· í˜•ì¡íŒ 5ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "\n",
      "ğŸ“ˆ 6. ëª¨ë¸ í‰ê°€\n",
      "\n",
      "ğŸ” RSF ëª¨ë¸ í‰ê°€:\n",
      "   Train: C-index = 0.881\n",
      "   Validation: C-index = 0.919\n",
      "   Test: C-index = 0.876\n",
      "\n",
      "ğŸ” Cox_Survival ëª¨ë¸ í‰ê°€:\n",
      "   Train: C-index = 0.814\n",
      "   Validation: C-index = 0.718\n",
      "   Test: C-index = 0.808\n",
      "\n",
      "ğŸ” RF_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.784, AUC = 0.898\n",
      "   Validation: Accuracy = 0.690, AUC = 0.803\n",
      "   Test: Accuracy = 0.914, AUC = 0.919\n",
      "\n",
      "ğŸ” XGB_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.936, AUC = 0.994\n",
      "   Validation: Accuracy = 0.759, AUC = 0.855\n",
      "   Test: Accuracy = 0.810, AUC = 0.886\n",
      "\n",
      "ğŸ” LGB_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.825, AUC = 0.922\n",
      "   Validation: Accuracy = 0.810, AUC = 0.836\n",
      "   Test: Accuracy = 0.879, AUC = 0.926\n",
      "\n",
      "ğŸ” XAI ëª¨ë¸ ì„¤ëª… ìƒì„±\n",
      "ğŸ”„ SHAP ì„¤ëª… ìƒì„± ì¤‘...\n",
      "âœ… RF_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "âœ… XGB_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "âœ… LGB_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ LIME ì„¤ëª… ìƒì„± ì¤‘...\n",
      "âœ… RF_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "âœ… XGB_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "âœ… LGB_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š 7. ê²°ê³¼ ì‹œê°í™”\n",
      "ğŸ” ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  ìƒì„± ì¤‘...\n",
      "ğŸ” CDSS í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ì¤‘...\n",
      "\n",
      "ğŸ”¬ CDSS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸\n",
      "\n",
      "ğŸ”§ Holdout í™˜ì ì „ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ” ì›ë³¸ í™˜ì íŠ¹ì„±: 25ê°œ\n",
      "ğŸ” ëª¨ë¸ í›ˆë ¨ íŠ¹ì„±: 25ê°œ\n",
      "âœ… treatments_pharmaceutical_treatment_type: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… treatments_pharmaceutical_treatment_intent_type: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… treatments_pharmaceutical_treatment_or_therapy: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… treatments_radiation_treatment_type: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… treatments_radiation_treatment_or_therapy: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… ajcc_pathologic_stage: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… ajcc_pathologic_t: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… ajcc_pathologic_n: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… ajcc_pathologic_m: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… morphology: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… primary_diagnosis: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… age_at_diagnosis: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… gender: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… race: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… ethnicity: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… prior_treatment: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… prior_malignancy: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… tobacco_smoking_status: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… pack_years_smoked: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… laterality: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… site_of_resection_or_biopsy: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… tissue_or_organ_of_origin: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… synchronous_malignancy: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… days_to_diagnosis: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "âœ… year_of_diagnosis: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\n",
      "\n",
      "ğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬:\n",
      "   - treatments_pharmaceutical_treatment_type: ì›ë³¸ê°’ = Pharmaceutical Therapy, NOS\n",
      "     â†’ ì¸ì½”ë”©: 'Pharmaceutical Therapy, NOS' â†’ 0\n",
      "   - treatments_pharmaceutical_treatment_intent_type: ì›ë³¸ê°’ = Adjuvant\n",
      "     â†’ ì¸ì½”ë”©: 'Adjuvant' â†’ 0\n",
      "   - treatments_pharmaceutical_treatment_or_therapy: ì›ë³¸ê°’ = no\n",
      "     â†’ ì¸ì½”ë”©: 'no' â†’ 0\n",
      "   - treatments_radiation_treatment_type: ì›ë³¸ê°’ = Radiation Therapy, NOS\n",
      "     â†’ ì¸ì½”ë”©: 'Radiation Therapy, NOS' â†’ 0\n",
      "   - treatments_radiation_treatment_or_therapy: ì›ë³¸ê°’ = no\n",
      "     â†’ ì¸ì½”ë”©: 'no' â†’ 0\n",
      "   - ajcc_pathologic_stage: ì›ë³¸ê°’ = nan\n",
      "     â†’ ê²°ì¸¡ì¹˜ë¥¼ 'Stage I' (0)ë¡œ ëŒ€ì²´\n",
      "   - ajcc_pathologic_t: ì›ë³¸ê°’ = T1a\n",
      "     â†’ ì¸ì½”ë”©: 'T1a' â†’ 1\n",
      "   - ajcc_pathologic_n: ì›ë³¸ê°’ = NX\n",
      "     â†’ ì¸ì½”ë”©: 'NX' â†’ 3\n",
      "   - ajcc_pathologic_m: ì›ë³¸ê°’ = MX\n",
      "     â†’ ì¸ì½”ë”©: 'MX' â†’ 2\n",
      "   - morphology: ì›ë³¸ê°’ = 8260/3\n",
      "     â†’ ì¸ì½”ë”©: '8260/3' â†’ 0\n",
      "   - primary_diagnosis: ì›ë³¸ê°’ = Papillary adenocarcinoma, NOS\n",
      "     â†’ ì¸ì½”ë”©: 'Papillary adenocarcinoma, NOS' â†’ 0\n",
      "   - gender: ì›ë³¸ê°’ = male\n",
      "     â†’ ì¸ì½”ë”©: 'male' â†’ 1\n",
      "   - race: ì›ë³¸ê°’ = white\n",
      "     â†’ ì¸ì½”ë”©: 'white' â†’ 4\n",
      "   - ethnicity: ì›ë³¸ê°’ = not hispanic or latino\n",
      "     â†’ ì¸ì½”ë”©: 'not hispanic or latino' â†’ 1\n",
      "   - prior_treatment: ì›ë³¸ê°’ = No\n",
      "     â†’ ì¸ì½”ë”©: 'No' â†’ 0\n",
      "   - prior_malignancy: ì›ë³¸ê°’ = no\n",
      "     â†’ ì¸ì½”ë”©: 'no' â†’ 0\n",
      "   - tobacco_smoking_status: ì›ë³¸ê°’ = Unknown\n",
      "     â†’ ìƒˆë¡œìš´ ê°’ 'Unknown'ì„ 'Current Reformed Smoker for < or = 15 yrs' (0)ë¡œ ëŒ€ì²´\n",
      "   - laterality: ì›ë³¸ê°’ = Right\n",
      "     â†’ ì¸ì½”ë”©: 'Right' â†’ 3\n",
      "   - site_of_resection_or_biopsy: ì›ë³¸ê°’ = Kidney, NOS\n",
      "     â†’ ì¸ì½”ë”©: 'Kidney, NOS' â†’ 0\n",
      "   - tissue_or_organ_of_origin: ì›ë³¸ê°’ = Kidney, NOS\n",
      "     â†’ ì¸ì½”ë”©: 'Kidney, NOS' â†’ 0\n",
      "   - synchronous_malignancy: ì›ë³¸ê°’ = No\n",
      "     â†’ ì¸ì½”ë”©: 'No' â†’ 0\n",
      "\n",
      "ğŸ”¢ ë°ì´í„° íƒ€ì… ë³€í™˜:\n",
      "   - treatments_pharmaceutical_treatment_type: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - treatments_pharmaceutical_treatment_intent_type: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - treatments_pharmaceutical_treatment_or_therapy: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - treatments_radiation_treatment_type: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - treatments_radiation_treatment_or_therapy: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - ajcc_pathologic_stage: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - ajcc_pathologic_t: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - ajcc_pathologic_n: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - ajcc_pathologic_m: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - morphology: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - primary_diagnosis: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - age_at_diagnosis: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - gender: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - race: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - ethnicity: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - prior_treatment: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - prior_malignancy: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - tobacco_smoking_status: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - pack_years_smoked: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - pack_years_smoked: ê²°ì¸¡ê°’ì„ 0.0ìœ¼ë¡œ ëŒ€ì²´\n",
      "   - laterality: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - site_of_resection_or_biopsy: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - tissue_or_organ_of_origin: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - synchronous_malignancy: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - days_to_diagnosis: ì´ë¯¸ ìˆ«ìí˜•\n",
      "   - year_of_diagnosis: ì´ë¯¸ ìˆ«ìí˜•\n",
      "âœ… íŠ¹ì„± ìˆœì„œ ì •ë ¬ ì™„ë£Œ: (1, 25)\n",
      "âœ… íŠ¹ì„±ëª… í™•ì¸: True\n",
      "\n",
      "ğŸ“ Imputer ì ìš© (ì•ˆì „í•œ ë°©ë²•):\n",
      "   - ì…ë ¥ í˜•íƒœ: (1, 25)\n",
      "   - Imputer ê¸°ëŒ€ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… Imputer ì ìš© ì™„ë£Œ\n",
      "\n",
      "ğŸ“ ìŠ¤ì¼€ì¼ë§ ì ìš© (ì•ˆì „í•œ ë°©ë²•):\n",
      "   - ì…ë ¥ í˜•íƒœ: (1, 25)\n",
      "   - Scaler ê¸°ëŒ€ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\n",
      "âœ… ìµœì¢… íŠ¹ì„± í˜•íƒœ: (1, 25)\n",
      "\n",
      "ğŸ”„ RSF ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\n",
      "   - ëª¨ë¸ íƒ€ì…: RandomSurvivalForest\n",
      "   - ì…ë ¥ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… RSF: ìœ„í—˜ë„ ì ìˆ˜ = 3.6733\n",
      "\n",
      "ğŸ”„ Cox_Survival ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\n",
      "   - ëª¨ë¸ íƒ€ì…: CoxPHSurvivalAnalysis\n",
      "   - ì…ë ¥ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… Cox_Survival: ìœ„í—˜ë„ ì ìˆ˜ = -1.2388\n",
      "\n",
      "ğŸ”„ RF_Treatment ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\n",
      "   - ëª¨ë¸ íƒ€ì…: RandomForestClassifier\n",
      "   - ì…ë ¥ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… RF_Treatment: ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ (í™•ë¥ : 0.697)\n",
      "\n",
      "ğŸ”„ XGB_Treatment ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\n",
      "   - ëª¨ë¸ íƒ€ì…: XGBClassifier\n",
      "   - ì…ë ¥ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… XGB_Treatment: ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ (í™•ë¥ : 0.948)\n",
      "\n",
      "ğŸ”„ LGB_Treatment ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\n",
      "   - ëª¨ë¸ íƒ€ì…: LGBMClassifier\n",
      "   - ì…ë ¥ íŠ¹ì„± ìˆ˜: 25\n",
      "âœ… LGB_Treatment: ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ (í™•ë¥ : 0.919)\n",
      "\n",
      "ğŸ“Š XAI ì‹œê°í™” ìƒì„±\n",
      "ğŸ”„ RF_Treatment SHAP ì‹œê°í™” ìƒì„± ì¤‘...\n",
      "âœ… RF_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "ğŸ”„ XGB_Treatment SHAP ì‹œê°í™” ìƒì„± ì¤‘...\n",
      "âœ… XGB_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "ğŸ”„ LGB_Treatment SHAP ì‹œê°í™” ìƒì„± ì¤‘...\n",
      "âœ… LGB_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… RF_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… XGB_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… LGB_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… ë©”ì¸ ê²°ê³¼ ì €ì¥: kidney_cancer_treatment_effect_analysis_results.png\n",
      "\n",
      "ğŸ’¾ CDSS í˜¸í™˜ ëª¨ë¸ ì €ì¥\n",
      "âœ… RSF ëª¨ë¸ ì €ì¥: cdss_kidney_cancer_treatment_rsf_model.pkl\n",
      "âœ… Cox_Survival ëª¨ë¸ ì €ì¥: cdss_kidney_cancer_treatment_cox_survival_model.pkl\n",
      "âœ… RF_Treatment ëª¨ë¸ ì €ì¥: cdss_kidney_cancer_treatment_rf_treatment_model.pkl\n",
      "âœ… XGB_Treatment ëª¨ë¸ ì €ì¥: cdss_kidney_cancer_treatment_xgb_treatment_model.pkl\n",
      "âœ… LGB_Treatment ëª¨ë¸ ì €ì¥: cdss_kidney_cancer_treatment_lgb_treatment_model.pkl\n",
      "âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì €ì¥: cdss_kidney_cancer_treatment_complete_pipeline.pkl\n",
      "\n",
      "ğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„±\n",
      "\n",
      "================================================================================\n",
      "ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ë³´ê³ ì„œ (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ê°œìš”:\n",
      "- ì´ í™˜ì ìˆ˜: 288ëª…\n",
      "- ì‚¬ë§ í™˜ì: 44ëª…\n",
      "- ì‚¬ë§ë¥ : 15.3%\n",
      "- ì¤‘ê°„ ì¶”ì  ê¸°ê°„: 768ì¼\n",
      "- ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸: 145ëª…\n",
      "\n",
      "ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\n",
      "\n",
      "RSF:\n",
      "  - Train: C-index = 0.881\n",
      "  - Validation: C-index = 0.919\n",
      "  - Test: C-index = 0.876\n",
      "\n",
      "Cox_Survival:\n",
      "  - Train: C-index = 0.814\n",
      "  - Validation: C-index = 0.718\n",
      "  - Test: C-index = 0.808\n",
      "\n",
      "RF_Treatment:\n",
      "  - Train: Accuracy = 0.784, AUC = 0.898\n",
      "  - Validation: Accuracy = 0.690, AUC = 0.803\n",
      "  - Test: Accuracy = 0.914, AUC = 0.919\n",
      "\n",
      "XGB_Treatment:\n",
      "  - Train: Accuracy = 0.936, AUC = 0.994\n",
      "  - Validation: Accuracy = 0.759, AUC = 0.855\n",
      "  - Test: Accuracy = 0.810, AUC = 0.886\n",
      "\n",
      "LGB_Treatment:\n",
      "  - Train: Accuracy = 0.825, AUC = 0.922\n",
      "  - Validation: Accuracy = 0.810, AUC = 0.836\n",
      "  - Test: Accuracy = 0.879, AUC = 0.926\n",
      "\n",
      "ğŸ”¬ CDSS í˜¸í™˜ì„±:\n",
      "- ëª¨ë“  ëª¨ë¸ì´ CDSS í˜¸í™˜ í˜•íƒœë¡œ ë˜í•‘ë¨\n",
      "- Holdout í™˜ì í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "- ì‹¤ì‹œê°„ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥\n",
      "\n",
      "ğŸ§  ì„¤ëª… ê°€ëŠ¥ AI (XAI):\n",
      "- SHAP ì„¤ëª…ê¸° êµ¬í˜„ ì™„ë£Œ\n",
      "- LIME ì„¤ëª…ê¸° êµ¬í˜„ ì™„ë£Œ\n",
      "- íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ\n",
      "\n",
      "âš–ï¸ ê³¼ì í•© ë°©ì§€:\n",
      "- ê· í˜•ì¡íŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
      "- ì ì ˆí•œ ì •ê·œí™” ì ìš©\n",
      "- Early Stopping êµ¬í˜„\n",
      "\n",
      "ğŸ’¾ ì €ì¥ëœ íŒŒì¼:\n",
      "- ëª¨ë¸ íŒŒì¼: cdss_kidney_cancer_treatment_*_model.pkl\n",
      "- ì „ì²´ íŒŒì´í”„ë¼ì¸: cdss_kidney_cancer_treatment_complete_pipeline.pkl\n",
      "- ì‹œê°í™” ê²°ê³¼: kidney_cancer_treatment_effect_analysis_results.png\n",
      "- XAI ì‹œê°í™”: shap_*.png, lime_*.png\n",
      "\n",
      "â° ë¶„ì„ ì™„ë£Œ ì‹œê°„: 2025-06-20 12:45:11\n",
      "================================================================================\n",
      "\n",
      "âœ… ë³´ê³ ì„œ ì €ì¥: kidney_cancer_treatment_effect_analysis_report.txt\n",
      "\n",
      "ğŸ‰ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!\n",
      "âœ… ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ¯ ë¶„ì„ ê²°ê³¼ ìš”ì•½:\n",
      "- 5ê°œì˜ CDSS í˜¸í™˜ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„± ì™„ë£Œ\n",
      "  * Random Survival Forest (ìƒì¡´ ì˜ˆì¸¡)\n",
      "  * Cox ë¹„ë¡€ìœ„í—˜ëª¨ë¸ (ìƒì¡´ ì˜ˆì¸¡)\n",
      "  * Random Forest (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\n",
      "  * XGBoost (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\n",
      "  * LightGBM (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\n",
      "- XAI ì„¤ëª… ê°€ëŠ¥ AI êµ¬í˜„ ì™„ë£Œ\n",
      "- ê³¼ì í•© ë°©ì§€ ìµœì í™” ì™„ë£Œ\n",
      "- ì‹¤ì‹œê°„ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\n",
      "- ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import pickle\n",
    "\n",
    "# ìƒì¡´ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "def setup_korean_font():\n",
    "    \"\"\"í•œê¸€ í°íŠ¸ ì„¤ì •\"\"\"\n",
    "    import platform\n",
    "    import matplotlib.font_manager as fm\n",
    "    \n",
    "    system = platform.system()\n",
    "    \n",
    "    if system == 'Windows':\n",
    "        try:\n",
    "            plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "        except:\n",
    "            try:\n",
    "                font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            except:\n",
    "                print(\"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨\")\n",
    "    elif system == 'Darwin':\n",
    "        plt.rcParams['font.family'] = 'AppleGothic'\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "class KidneyCancerTreatmentEffectPredictorCDSS:\n",
    "    \"\"\"ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        setup_korean_font()\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.processed_df = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.feature_names = []\n",
    "        self.scaler = None\n",
    "        self.label_encoders = {}\n",
    "        self.shap_explainers = {}\n",
    "        self.shap_values = {}\n",
    "        self.lime_explainers = {}\n",
    "        self.holdout_patient = None\n",
    "        \n",
    "        print(f\"ğŸš€ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)\")\n",
    "        print(f\"ğŸ“ ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "        print(f\"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë¶„ì„\"\"\"\n",
    "        print(\"\\nğŸ“Š 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\")\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "            print(f\"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {self.df.shape[0]}í–‰ Ã— {self.df.shape[1]}ì—´\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ğŸ“ˆ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "        print(f\"   - ì´ í™˜ì ìˆ˜: {len(self.df)}\")\n",
    "        print(f\"   - ì´ ì»¬ëŸ¼ ìˆ˜: {len(self.df.columns)}\")\n",
    "        \n",
    "        # ìƒì¡´ ìƒíƒœ ë¶„í¬\n",
    "        if 'vital_status' in self.df.columns:\n",
    "            status_counts = self.df['vital_status'].value_counts()\n",
    "            print(f\"   - ìƒì¡´ í™˜ì: {status_counts.get('Alive', 0)}ëª…\")\n",
    "            print(f\"   - ì‚¬ë§ í™˜ì: {status_counts.get('Dead', 0)}ëª…\")\n",
    "            print(f\"   - ì‚¬ë§ë¥ : {status_counts.get('Dead', 0)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "        print(\"\\nğŸ”§ 2. ë°ì´í„° ì „ì²˜ë¦¬\")\n",
    "        \n",
    "        # ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ìš© ì„ íƒëœ ì»¬ëŸ¼ë“¤\n",
    "        selected_columns = [\n",
    "            # ìƒì¡´ ê²°ê³¼ ë³€ìˆ˜\n",
    "            'vital_status', 'days_to_death', 'days_to_last_follow_up',\n",
    "            \n",
    "            # ì¹˜ë£Œ ê´€ë ¨ ë³€ìˆ˜ (ê°€ì¥ ì¤‘ìš”)\n",
    "            'treatments_pharmaceutical_treatment_type',\n",
    "            'treatments_pharmaceutical_treatment_intent_type',\n",
    "            'treatments_pharmaceutical_treatment_or_therapy',\n",
    "            'treatments_radiation_treatment_type',\n",
    "            'treatments_radiation_treatment_or_therapy',\n",
    "            \n",
    "            # ë³‘ê¸° ë° ì¢…ì–‘ íŠ¹ì„± (ì˜ˆí›„ ì¸ì)\n",
    "            'ajcc_pathologic_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'morphology', 'primary_diagnosis',\n",
    "            \n",
    "            # í™˜ì ê¸°ë³¸ ì •ë³´\n",
    "            'age_at_diagnosis', 'gender', 'race', 'ethnicity',\n",
    "            \n",
    "            # ì´ì „ ì¹˜ë£Œë ¥\n",
    "            'prior_treatment', 'prior_malignancy',\n",
    "            \n",
    "            # ìƒí™œìŠµê´€ ìœ„í—˜ì¸ì\n",
    "            'tobacco_smoking_status', 'pack_years_smoked',\n",
    "            \n",
    "            # í•´ë¶€í•™ì /ì¢…ì–‘ íŠ¹ì„±\n",
    "            'laterality', 'site_of_resection_or_biopsy', 'tissue_or_organ_of_origin',\n",
    "            'synchronous_malignancy',\n",
    "            \n",
    "            # ì‹œê°„ ê´€ë ¨ ë³€ìˆ˜\n",
    "            'days_to_diagnosis', 'year_of_diagnosis'\n",
    "        ]\n",
    "        \n",
    "        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "        available_columns = [col for col in selected_columns if col in self.df.columns]\n",
    "        missing_columns = [col for col in selected_columns if col not in self.df.columns]\n",
    "        \n",
    "        print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {len(available_columns)}ê°œ\")\n",
    "        if missing_columns:\n",
    "            print(f\"âš ï¸  ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}\")\n",
    "        \n",
    "        self.processed_df = self.df[available_columns].copy()\n",
    "        \n",
    "        # Series ê°ì²´ë¥¼ ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "        def extract_first_value(x):\n",
    "            if isinstance(x, pd.Series):\n",
    "                return x.iloc[0] if len(x) > 0 else np.nan\n",
    "            else:\n",
    "                return x\n",
    "        \n",
    "        # days_to_last_follow_up ì»¬ëŸ¼ ë‚´ Series ê°ì²´ë¥¼ ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "        if 'days_to_last_follow_up' in self.processed_df.columns:\n",
    "            self.processed_df['days_to_last_follow_up'] = self.processed_df['days_to_last_follow_up'].apply(extract_first_value)\n",
    "        \n",
    "        # ìƒì¡´ ì‹œê°„ ë° ì´ë²¤íŠ¸ ë³€ìˆ˜ ìƒì„±\n",
    "        print(\"ğŸ”„ ìƒì¡´ ë³€ìˆ˜ ìƒì„± ì¤‘...\")\n",
    "        self.processed_df['event'] = (self.processed_df['vital_status'] == 'Dead').astype(int)\n",
    "        \n",
    "        # ìƒì¡´ ì‹œê°„ ê³„ì‚° (Series ì²˜ë¦¬ í¬í•¨)\n",
    "        def calculate_duration(row):\n",
    "            death_day = row['days_to_death']\n",
    "            followup_day = row['days_to_last_follow_up']\n",
    "            \n",
    "            # followup_dayê°€ Seriesì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬\n",
    "            if isinstance(followup_day, pd.Series):\n",
    "                followup_day = followup_day.iloc[0] if len(followup_day) > 0 else np.nan\n",
    "            \n",
    "            if pd.notna(death_day):\n",
    "                return death_day\n",
    "            elif pd.notna(followup_day):\n",
    "                return followup_day\n",
    "            else:\n",
    "                return np.nan\n",
    "        \n",
    "        self.processed_df['duration'] = self.processed_df.apply(calculate_duration, axis=1)\n",
    "        \n",
    "        # ì¹˜ë£Œ íš¨ê³¼ ì§€í‘œ ìƒì„± (ì‹ ì¥ì•” íŠ¹í™”)\n",
    "        self.processed_df['treatment_effectiveness'] = np.where(\n",
    "            self.processed_df['duration'] > self.processed_df['duration'].median(), 1, 0\n",
    "        )\n",
    "        \n",
    "        # ìœ íš¨í•˜ì§€ ì•Šì€ ìƒì¡´ ì‹œê°„ ì œê±°\n",
    "        valid_mask = (pd.notna(self.processed_df['duration'])) & (self.processed_df['duration'] > 0)\n",
    "        self.processed_df = self.processed_df[valid_mask].copy()\n",
    "        \n",
    "        print(f\"âœ… ìœ íš¨í•œ ìƒì¡´ ë°ì´í„°: {len(self.processed_df)}ëª…\")\n",
    "        print(f\"   - ì‚¬ë§ ì´ë²¤íŠ¸: {self.processed_df['event'].sum()}ê±´\")\n",
    "        print(f\"   - ì¤‘ê°„ ìƒì¡´ ì‹œê°„: {self.processed_df['duration'].median():.0f}ì¼\")\n",
    "        print(f\"   - ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸: {self.processed_df['treatment_effectiveness'].sum()}ëª…\")\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ ë¶„ì„\n",
    "        print(\"\\nğŸ“‹ ê²°ì¸¡ê°’ ë¶„ì„:\")\n",
    "        missing_analysis = self.processed_df.isnull().sum()\n",
    "        missing_percent = (missing_analysis / len(self.processed_df) * 100).round(1)\n",
    "        \n",
    "        for col in missing_analysis[missing_analysis > 0].index:\n",
    "            print(f\"   - {col}: {missing_analysis[col]}ê°œ ({missing_percent[col]}%)\")\n",
    "        \n",
    "        # ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼ ì œê±° (80% ì´ìƒ)\n",
    "        high_missing_cols = missing_percent[missing_percent > 80].index.tolist()\n",
    "        if high_missing_cols:\n",
    "            print(f\"ğŸ—‘ï¸  ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼ ì œê±°: {high_missing_cols}\")\n",
    "            self.processed_df = self.processed_df.drop(columns=high_missing_cols)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”© (CDSS í˜¸í™˜)\"\"\"\n",
    "        print(\"\\nğŸ¯ 3. íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”©\")\n",
    "        \n",
    "        # CDSS í…ŒìŠ¤íŠ¸ìš© í™˜ì 1ëª… ë¯¸ë¦¬ ë¶„ë¦¬\n",
    "        print(\"ğŸ”„ CDSS í…ŒìŠ¤íŠ¸ìš© í™˜ì ë¶„ë¦¬ ì¤‘...\")\n",
    "        holdout_idx = self.processed_df.sample(n=1, random_state=42).index[0]\n",
    "        self.holdout_patient = self.processed_df.loc[holdout_idx:holdout_idx].copy()\n",
    "        remaining_df = self.processed_df.drop(holdout_idx).copy()\n",
    "        \n",
    "        print(f\"   - CDSS í…ŒìŠ¤íŠ¸ í™˜ì: {holdout_idx}\")\n",
    "        print(f\"   - ëª¨ë¸ í›ˆë ¨ìš© ë°ì´í„°: {len(remaining_df)}ëª…\")\n",
    "        \n",
    "        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "        feature_cols = [col for col in remaining_df.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'treatment_effectiveness']]\n",
    "        \n",
    "        X = remaining_df[feature_cols].copy()\n",
    "        y_duration = remaining_df['duration'].values\n",
    "        y_event = remaining_df['event'].values.astype(bool)\n",
    "        y_effectiveness = remaining_df['treatment_effectiveness'].values\n",
    "        \n",
    "        print(f\"ğŸ“Š ì´ˆê¸° íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}\")\n",
    "        print(f\"ğŸ“Š ìƒ˜í”Œ ê°œìˆ˜: {len(X)}\")\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        print(f\"ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜: {len(categorical_cols)}ê°œ\")\n",
    "        print(f\"ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numerical_cols)}ê°œ\")\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "        print(\"ğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì„ìƒì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” Unknown ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ë“¤ (ì‹ ì¥ì•” íŠ¹í™”)\n",
    "        meaningful_unknown_cols = [\n",
    "            'ajcc_pathologic_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'morphology', 'primary_diagnosis',\n",
    "            'treatments_pharmaceutical_treatment_type', 'treatments_pharmaceutical_treatment_intent_type',\n",
    "            'treatments_pharmaceutical_treatment_or_therapy', 'treatments_radiation_treatment_type',\n",
    "            'treatments_radiation_treatment_or_therapy', 'prior_treatment', 'prior_malignancy',\n",
    "            'synchronous_malignancy'\n",
    "        ]\n",
    "        \n",
    "        self.label_encoders = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col in X.columns:\n",
    "                print(f\"\\n   ğŸ” {col} ì²˜ë¦¬:\")\n",
    "                \n",
    "                # í˜„ì¬ ê°’ ë¶„í¬ í™•ì¸\n",
    "                value_counts = X[col].value_counts(dropna=False)\n",
    "                print(f\"      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {dict(list(value_counts.items())[:3])}\")\n",
    "                \n",
    "                # 'NA' ë¬¸ìì—´ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜\n",
    "                if 'NA' in X[col].values:\n",
    "                    X[col] = X[col].replace('NA', np.nan)\n",
    "                    print(f\"      - 'NA' ë¬¸ìì—´ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜\")\n",
    "                \n",
    "                # Unknown ê°’ ì²˜ë¦¬ ê²°ì •\n",
    "                has_unknown = X[col].str.contains('Unknown', na=False).any() if X[col].dtype == object else False\n",
    "                \n",
    "                if has_unknown:\n",
    "                    if col in meaningful_unknown_cols:\n",
    "                        print(f\"      - 'Unknown' ê°’ ìœ ì§€ (ì„ìƒì  ì˜ë¯¸ ìˆìŒ)\")\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "                    else:\n",
    "                        print(f\"      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\")\n",
    "                        X[col] = X[col].replace('Unknown', np.nan)\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "                else:\n",
    "                    if X[col].isnull().any():\n",
    "                        mode_value = X[col].mode()\n",
    "                        if not mode_value.empty:\n",
    "                            fill_value = mode_value[0]\n",
    "                            X[col] = X[col].fillna(fill_value)\n",
    "                            print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "        \n",
    "        # ëª¨ë“  ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "        print(\"\\nğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©:\")\n",
    "        all_categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        for col in all_categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "            \n",
    "            if col in meaningful_unknown_cols:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"   - {col} ì¸ì½”ë”© ë§¤í•‘: {mapping}\")\n",
    "        \n",
    "        # ëª¨ë“  íŠ¹ì„±ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "        for col in X.columns:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        \n",
    "        # ì „ì²´ íŠ¹ì„±ì— ëŒ€í•´ Imputer í›ˆë ¨\n",
    "        print(f\"\\nğŸ“ ì „ì²´ íŠ¹ì„± Imputer í›ˆë ¨:\")\n",
    "        print(f\"   - ì „ì²´ íŠ¹ì„± ìˆ˜: {X.shape[1]}\")\n",
    "        \n",
    "        self.num_imputer = SimpleImputer(strategy='median')\n",
    "        X_imputed = self.num_imputer.fit_transform(X)\n",
    "        X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "        \n",
    "        print(f\"âœ… ì „ì²´ íŠ¹ì„± Imputer í›ˆë ¨ ì™„ë£Œ: {X.shape[1]}ê°œ íŠ¹ì„±\")\n",
    "        \n",
    "        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        self.feature_names = X_scaled.columns.tolist()\n",
    "        \n",
    "        # scikit-survival í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        y_structured = np.array([(event, duration) for event, duration in zip(y_event, y_duration)],\n",
    "                               dtype=[('event', '?'), ('time', '<f8')])\n",
    "        \n",
    "        print(\"âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ (CDSS í˜¸í™˜)\")\n",
    "        \n",
    "        return X_scaled, y_structured, y_duration, y_event, y_effectiveness\n",
    "    \n",
    "    def split_data(self, X, y_structured, y_duration, y_event, y_effectiveness):\n",
    "        \"\"\"ë°ì´í„° ë¶„í• \"\"\"\n",
    "        print(\"\\nâœ‚ï¸  4. ë°ì´í„° ë¶„í•  (í›ˆë ¨:ê²€ì¦:í…ŒìŠ¤íŠ¸ = 60:20:20)\")\n",
    "        \n",
    "        # ë¨¼ì € í›ˆë ¨+ê²€ì¦ vs í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• \n",
    "        X_temp, X_test, y_temp_struct, y_test_struct, y_temp_dur, y_test_dur, y_temp_event, y_test_event, y_temp_eff, y_test_eff = \\\n",
    "            train_test_split(X, y_structured, y_duration, y_event, y_effectiveness,\n",
    "                           test_size=0.2, random_state=42, stratify=y_effectiveness)\n",
    "        \n",
    "        # í›ˆë ¨ vs ê²€ì¦ìœ¼ë¡œ ë¶„í• \n",
    "        X_train, X_val, y_train_struct, y_val_struct, y_train_dur, y_val_dur, y_train_event, y_val_event, y_train_eff, y_val_eff = \\\n",
    "            train_test_split(X_temp, y_temp_struct, y_temp_dur, y_temp_event, y_temp_eff,\n",
    "                           test_size=0.25, random_state=42, stratify=y_temp_eff)\n",
    "        \n",
    "        print(f\"ğŸ“Š í›ˆë ¨ ì„¸íŠ¸: {len(X_train)}ëª… (ì‚¬ë§: {y_train_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_train_eff.sum()}ëª…)\")\n",
    "        print(f\"ğŸ“Š ê²€ì¦ ì„¸íŠ¸: {len(X_val)}ëª… (ì‚¬ë§: {y_val_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_val_eff.sum()}ëª…)\")\n",
    "        print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(X_test)}ëª… (ì‚¬ë§: {y_test_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_test_eff.sum()}ëª…)\")\n",
    "        print(f\"ğŸ“Š CDSS í…ŒìŠ¤íŠ¸: 1ëª… (ë³„ë„ ë³´ê´€)\")\n",
    "        \n",
    "        return (X_train, X_val, X_test, \n",
    "                y_train_struct, y_val_struct, y_test_struct,\n",
    "                y_train_dur, y_val_dur, y_test_dur,\n",
    "                y_train_event, y_val_event, y_test_event,\n",
    "                y_train_eff, y_val_eff, y_test_eff)\n",
    "    \n",
    "    def train_models(self, X_train, X_val, X_test, \n",
    "                    y_train_struct, y_val_struct, y_test_struct,\n",
    "                    y_train_dur, y_val_dur, y_test_dur,\n",
    "                    y_train_event, y_val_event, y_test_event,\n",
    "                    y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"ëª¨ë¸ í›ˆë ¨ (ê· í˜•ì¡íŒ ê³¼ì í•© ë°©ì§€)\"\"\"\n",
    "        print(\"\\nğŸ¤– 5. ëª¨ë¸ í›ˆë ¨ (ê· í˜•ì¡íŒ ê³¼ì í•© ë°©ì§€)\")\n",
    "        \n",
    "        # 1. Random Survival Forest (ìƒì¡´ ì˜ˆì¸¡)\n",
    "        print(\"ğŸ”„ Random Survival Forest í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            rsf_model = RandomSurvivalForest(\n",
    "                n_estimators=100,\n",
    "                max_depth=8,\n",
    "                min_samples_split=15,\n",
    "                min_samples_leaf=8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rsf_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            rsf_wrapper = {\n",
    "                'model': rsf_model,\n",
    "                'model_type': 'RandomSurvivalForest',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['RSF'] = rsf_wrapper\n",
    "            print(\"âœ… Random Survival Forest í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ RSF ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 2. Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ (ìƒì¡´ ì˜ˆì¸¡)\n",
    "        print(\"ğŸ”„ Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            cox_model = CoxPHSurvivalAnalysis(alpha=0.5)\n",
    "            cox_model.fit(X_train, y_train_struct)\n",
    "            \n",
    "            cox_wrapper = {\n",
    "                'model': cox_model,\n",
    "                'model_type': 'CoxPHSurvivalAnalysis',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'event_rate': y_train_event.mean()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['Cox_Survival'] = cox_wrapper\n",
    "            print(\"âœ… Cox ìƒì¡´ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Cox ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 3. Random Forest (ê· í˜•ì¡íŒ ì„¤ì •)\n",
    "        print(\"ğŸ”„ Random Forest ê· í˜•ì¡íŒ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=8,\n",
    "                min_samples_split=15,\n",
    "                min_samples_leaf=8,\n",
    "                max_features='sqrt',\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf_classifier.fit(X_train, y_train_eff)\n",
    "            \n",
    "            rf_wrapper = {\n",
    "                'model': rf_classifier,\n",
    "                'model_type': 'RandomForestClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': rf_classifier.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['RF_Treatment'] = rf_wrapper\n",
    "            print(\"âœ… Random Forest ê· í˜•ì¡íŒ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ RF ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 4. XGBoost (ì ì ˆí•œ ì •ê·œí™”)\n",
    "        print(\"ğŸ”„ XGBoost ì ì ˆí•œ ì •ê·œí™”ë¡œ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            xgb_model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.5,\n",
    "                reg_lambda=0.5,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            \n",
    "            xgb_model.fit(X_train, y_train_eff)\n",
    "            \n",
    "            xgb_wrapper = {\n",
    "                'model': xgb_model,\n",
    "                'model_type': 'XGBClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': xgb_model.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['XGB_Treatment'] = xgb_wrapper\n",
    "            print(\"âœ… XGBoost ì ì ˆí•œ ì •ê·œí™” í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ XGBoost ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 5. LightGBM (ê³¼ì í•© ë°©ì§€ ìµœì í™”)\n",
    "        print(\"ğŸ”„ LightGBM ê³¼ì í•© ë°©ì§€ ìµœì í™”ë¡œ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            lgb_model = lgb.LGBMClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=15,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.5,\n",
    "                reg_lambda=0.5,\n",
    "                min_child_samples=20,\n",
    "                min_child_weight=0.001,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            \n",
    "            lgb_model.fit(\n",
    "                X_train, y_train_eff,\n",
    "                eval_set=[(X_val, y_val_eff)],\n",
    "                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]\n",
    "            )\n",
    "            \n",
    "            lgb_wrapper = {\n",
    "                'model': lgb_model,\n",
    "                'model_type': 'LGBMClassifier',\n",
    "                'feature_names': self.feature_names,\n",
    "                'scaler': self.scaler,\n",
    "                'label_encoders': self.label_encoders,\n",
    "                'num_imputer': self.num_imputer,\n",
    "                'class_labels': ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸'],\n",
    "                'training_info': {\n",
    "                    'n_samples': len(X_train),\n",
    "                    'n_features': len(self.feature_names),\n",
    "                    'class_distribution': np.bincount(y_train_eff),\n",
    "                    'feature_importance': lgb_model.feature_importances_\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.models['LGB_Treatment'] = lgb_wrapper\n",
    "            print(\"âœ… LightGBM ê³¼ì í•© ë°©ì§€ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LightGBM ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ê· í˜•ì¡íŒ {len(self.models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def evaluate_models(self, X_train, X_val, X_test,\n",
    "                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                       y_train_event, y_val_event, y_test_event,\n",
    "                       y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        print(\"\\nğŸ“ˆ 6. ëª¨ë¸ í‰ê°€\")\n",
    "        \n",
    "        datasets = {\n",
    "            'Train': (X_train, y_train_struct, y_train_dur, y_train_event, y_train_eff),\n",
    "            'Validation': (X_val, y_val_struct, y_val_dur, y_val_event, y_val_eff),\n",
    "            'Test': (X_test, y_test_struct, y_test_dur, y_test_event, y_test_eff)\n",
    "        }\n",
    "        \n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            print(f\"\\nğŸ” {model_name} ëª¨ë¸ í‰ê°€:\")\n",
    "            self.results[model_name] = {}\n",
    "            \n",
    "            for dataset_name, (X, y_struct, y_dur, y_event, y_eff) in datasets.items():\n",
    "                try:\n",
    "                    actual_model = model_wrapper['model']\n",
    "                    model_type = model_wrapper['model_type']\n",
    "                    \n",
    "                    if model_type in ['RandomSurvivalForest', 'CoxPHSurvivalAnalysis']:\n",
    "                        # ìƒì¡´ ëª¨ë¸ í‰ê°€\n",
    "                        risk_scores = actual_model.predict(X)\n",
    "                        c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                        self.results[model_name][dataset_name] = {'c_index': c_index}\n",
    "                        print(f\"   {dataset_name}: C-index = {c_index:.3f}\")\n",
    "                    \n",
    "                    else:\n",
    "                        # ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ (ì¹˜ë£Œ íš¨ê³¼)\n",
    "                        y_pred = actual_model.predict(X)\n",
    "                        accuracy = (y_pred == y_eff).mean()\n",
    "                        \n",
    "                        try:\n",
    "                            y_proba = actual_model.predict_proba(X)\n",
    "                            auc_score = roc_auc_score(y_eff, y_proba[:, 1])\n",
    "                        except:\n",
    "                            auc_score = np.nan\n",
    "                        \n",
    "                        self.results[model_name][dataset_name] = {\n",
    "                            'accuracy': accuracy,\n",
    "                            'auc': auc_score\n",
    "                        }\n",
    "                        print(f\"   {dataset_name}: Accuracy = {accuracy:.3f}, AUC = {auc_score:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ {dataset_name} í‰ê°€ ì‹¤íŒ¨: {e}\")\n",
    "                    self.results[model_name][dataset_name] = {'error': str(e)}\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def explain_models(self, X_train, X_test):\n",
    "        \"\"\"XAI ëª¨ë¸ ì„¤ëª… ìƒì„±\"\"\"\n",
    "        print(\"\\nğŸ” XAI ëª¨ë¸ ì„¤ëª… ìƒì„±\")\n",
    "        \n",
    "        # SHAP ì„¤ëª…ê¸° ì´ˆê¸°í™”\n",
    "        print(\"ğŸ”„ SHAP ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "        tree_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        \n",
    "        for model_name in tree_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    X_test_sample = X_test.iloc[:50]\n",
    "                    \n",
    "                    actual_model = self.models[model_name]['model']\n",
    "                    \n",
    "                    explainer = shap.TreeExplainer(actual_model)\n",
    "                    shap_values = explainer.shap_values(X_test_sample)\n",
    "                    \n",
    "                    self.shap_explainers[model_name] = explainer\n",
    "                    self.shap_values[model_name] = shap_values\n",
    "                    print(f\"âœ… {model_name} SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} SHAP ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # LIME ì„¤ëª…ê¸° ì´ˆê¸°í™”\n",
    "        print(\"\\nğŸ”„ LIME ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    actual_model = self.models[model_name]['model']\n",
    "                    class_labels = self.models[model_name]['class_labels']\n",
    "                    \n",
    "                    explainer = lime_tabular.LimeTabularExplainer(\n",
    "                        training_data=X_train.values,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=class_labels,\n",
    "                        mode='classification',\n",
    "                        discretize_continuous=True\n",
    "                    )\n",
    "                    \n",
    "                    self.lime_explainers[model_name] = {\n",
    "                        'explainer': explainer,\n",
    "                        'predict_fn': actual_model.predict_proba\n",
    "                    }\n",
    "                    print(f\"âœ… {model_name} LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} LIME ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_xai_visualizations(self, X_test, sample_index=0):\n",
    "        \"\"\"XAI ì‹œê°í™” ìƒì„± ë° ì €ì¥\"\"\"\n",
    "        print(\"\\nğŸ“Š XAI ì‹œê°í™” ìƒì„±\")\n",
    "        \n",
    "        # SHAP ì‹œê°í™”\n",
    "        shap_figures = []\n",
    "        for model_name in self.shap_explainers:\n",
    "            try:\n",
    "                print(f\"ğŸ”„ {model_name} SHAP ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
    "                \n",
    "                shap_vals = self.shap_values[model_name]\n",
    "                \n",
    "                # ì´ì§„ ë¶„ë¥˜ SHAP ê°’ ì²˜ë¦¬\n",
    "                if isinstance(shap_vals, list) and len(shap_vals) == 2:\n",
    "                    shap_vals_to_plot = shap_vals[1]\n",
    "                    expected_val = self.shap_explainers[model_name].expected_value[1]\n",
    "                elif hasattr(shap_vals, 'shape') and shap_vals.ndim == 3:\n",
    "                    shap_vals_to_plot = shap_vals[:, :, 1]\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value[1] \n",
    "                                if hasattr(self.shap_explainers[model_name].expected_value, '__len__') \n",
    "                                else self.shap_explainers[model_name].expected_value)\n",
    "                else:\n",
    "                    shap_vals_to_plot = shap_vals\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value \n",
    "                                if not hasattr(self.shap_explainers[model_name].expected_value, '__len__')\n",
    "                                else self.shap_explainers[model_name].expected_value[0])\n",
    "                \n",
    "                # Summary plot\n",
    "                plt.figure(figsize=(10,6))\n",
    "                shap.summary_plot(shap_vals_to_plot, X_test.iloc[:50], \n",
    "                                feature_names=self.feature_names,\n",
    "                                plot_type=\"bar\", show=False)\n",
    "                plt.title(f\"{model_name} íŠ¹ì„± ì¤‘ìš”ë„ (SHAP)\")\n",
    "                shap_summary_path = f\"shap_summary_{model_name}_kidney.png\"\n",
    "                plt.savefig(shap_summary_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                # Individual waterfall plot\n",
    "                plt.figure(figsize=(12,6))\n",
    "                \n",
    "                if shap_vals_to_plot.ndim == 2:\n",
    "                    individual_shap = shap_vals_to_plot[sample_index, :]\n",
    "                else:\n",
    "                    individual_shap = shap_vals_to_plot\n",
    "                \n",
    "                if hasattr(expected_val, '__len__') and len(expected_val) > 0:\n",
    "                    base_value = float(expected_val[0]) if hasattr(expected_val[0], '__float__') else 0.0\n",
    "                else:\n",
    "                    base_value = float(expected_val) if hasattr(expected_val, '__float__') else 0.0\n",
    "                \n",
    "                try:\n",
    "                    shap.waterfall_plot(\n",
    "                        shap.Explanation(\n",
    "                            values=individual_shap.astype(float),\n",
    "                            base_values=base_value,\n",
    "                            data=X_test.iloc[sample_index].values.astype(float),\n",
    "                            feature_names=self.feature_names\n",
    "                        ),\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f\"{model_name} ê°œë³„ ì„¤ëª… (ìƒ˜í”Œ {sample_index})\")\n",
    "                    shap_waterfall_path = f\"shap_waterfall_{model_name}_kidney_{sample_index}.png\"\n",
    "                    plt.savefig(shap_waterfall_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    shap_figures.extend([shap_summary_path, shap_waterfall_path])\n",
    "                    \n",
    "                except Exception as waterfall_error:\n",
    "                    print(f\"âš ï¸ Waterfall plot ì‹¤íŒ¨, Force plotìœ¼ë¡œ ëŒ€ì²´: {waterfall_error}\")\n",
    "                    \n",
    "                    shap.force_plot(\n",
    "                        base_value,\n",
    "                        individual_shap,\n",
    "                        X_test.iloc[sample_index],\n",
    "                        feature_names=self.feature_names,\n",
    "                        matplotlib=True,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f\"{model_name} ê°œë³„ ì„¤ëª… - Force Plot (ìƒ˜í”Œ {sample_index})\")\n",
    "                    shap_force_path = f\"shap_force_{model_name}_kidney_{sample_index}.png\"\n",
    "                    plt.savefig(shap_force_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    shap_figures.extend([shap_summary_path, shap_force_path])\n",
    "                \n",
    "                print(f\"âœ… {model_name} SHAP ì‹œê°í™” ì™„ë£Œ\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} SHAP ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # LIME ì‹œê°í™”\n",
    "        lime_figures = []\n",
    "        for model_name in self.lime_explainers:\n",
    "            try:\n",
    "                lime_data = self.lime_explainers[model_name]\n",
    "                exp = lime_data['explainer'].explain_instance(\n",
    "                    X_test.iloc[sample_index].values,\n",
    "                    lime_data['predict_fn'],\n",
    "                    num_features=5\n",
    "                )\n",
    "                lime_path = f\"lime_explanation_{model_name}_kidney_{sample_index}.png\"\n",
    "                fig = exp.as_pyplot_figure()\n",
    "                plt.title(f\"{model_name} LIME ì„¤ëª… (ìƒ˜í”Œ {sample_index})\")\n",
    "                plt.savefig(lime_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                lime_figures.append(lime_path)\n",
    "                print(f\"âœ… {model_name} LIME ì‹œê°í™” ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} LIME ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return shap_figures, lime_figures\n",
    "    \n",
    "    def preprocess_holdout_patient(self):\n",
    "        \"\"\"Holdout í™˜ì ë°ì´í„° ì „ì²˜ë¦¬ (ë” ì•ˆì „í•œ ë°©ë²•)\"\"\"\n",
    "        print(\"\\nğŸ”§ Holdout í™˜ì ì „ì²˜ë¦¬ ì‹œì‘\")\n",
    "        \n",
    "        # holdout í™˜ìì˜ íŠ¹ì„± ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "        feature_cols = [col for col in self.holdout_patient.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'treatment_effectiveness']]\n",
    "        \n",
    "        patient_raw = self.holdout_patient[feature_cols].copy()\n",
    "        print(f\"ğŸ” ì›ë³¸ í™˜ì íŠ¹ì„±: {len(patient_raw.columns)}ê°œ\")\n",
    "        print(f\"ğŸ” ëª¨ë¸ í›ˆë ¨ íŠ¹ì„±: {len(self.feature_names)}ê°œ\")\n",
    "        \n",
    "        # ëª¨ë¸ í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ íŠ¹ì„±ëª…ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” DataFrame ìƒì„±\n",
    "        patient_processed = pd.DataFrame(index=patient_raw.index)\n",
    "        \n",
    "        for feature_name in self.feature_names:\n",
    "            if feature_name in patient_raw.columns:\n",
    "                patient_processed[feature_name] = patient_raw[feature_name].copy()\n",
    "                print(f\"âœ… {feature_name}: ì›ë³¸ ë°ì´í„° ì‚¬ìš©\")\n",
    "            else:\n",
    "                patient_processed[feature_name] = 0.0\n",
    "                print(f\"âš ï¸ {feature_name}: ê¸°ë³¸ê°’(0.0) ì„¤ì •\")\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬\n",
    "        print(\"\\nğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬:\")\n",
    "        for col, encoder in self.label_encoders.items():\n",
    "            if col in patient_processed.columns:\n",
    "                try:\n",
    "                    original_value = patient_processed[col].iloc[0]\n",
    "                    print(f\"   - {col}: ì›ë³¸ê°’ = {original_value}\")\n",
    "                    \n",
    "                    if pd.isna(original_value) or original_value == 'NA':\n",
    "                        encoded_value = encoder.transform([encoder.classes_[0]])[0]\n",
    "                        patient_processed[col] = float(encoded_value)\n",
    "                        print(f\"     â†’ ê²°ì¸¡ì¹˜ë¥¼ '{encoder.classes_[0]}' ({encoded_value})ë¡œ ëŒ€ì²´\")\n",
    "                    else:\n",
    "                        str_value = str(original_value)\n",
    "                        if str_value in encoder.classes_:\n",
    "                            encoded_value = encoder.transform([str_value])[0]\n",
    "                            patient_processed[col] = float(encoded_value)\n",
    "                            print(f\"     â†’ ì¸ì½”ë”©: '{str_value}' â†’ {encoded_value}\")\n",
    "                        else:\n",
    "                            encoded_value = encoder.transform([encoder.classes_[0]])[0]\n",
    "                            patient_processed[col] = float(encoded_value)\n",
    "                            print(f\"     â†’ ìƒˆë¡œìš´ ê°’ '{str_value}'ì„ '{encoder.classes_[0]}' ({encoded_value})ë¡œ ëŒ€ì²´\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"     âŒ {col} ì¸ì½”ë”© ì‹¤íŒ¨: {e}\")\n",
    "                    patient_processed[col] = 0.0\n",
    "        \n",
    "        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "        print(\"\\nğŸ”¢ ë°ì´í„° íƒ€ì… ë³€í™˜:\")\n",
    "        for col in patient_processed.columns:\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(patient_processed[col]):\n",
    "                    print(f\"   - {col}: ì´ë¯¸ ìˆ«ìí˜•\")\n",
    "                else:\n",
    "                    patient_processed[col] = pd.to_numeric(patient_processed[col], errors='coerce')\n",
    "                    print(f\"   - {col}: ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜\")\n",
    "                \n",
    "                if patient_processed[col].isnull().any():\n",
    "                    patient_processed[col] = patient_processed[col].fillna(0.0)\n",
    "                    print(f\"   - {col}: ê²°ì¸¡ê°’ì„ 0.0ìœ¼ë¡œ ëŒ€ì²´\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {col} ìˆ˜ì¹˜í˜• ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "                patient_processed[col] = 0.0\n",
    "        \n",
    "        # íŠ¹ì„± ìˆœì„œë¥¼ í›ˆë ¨ ì‹œì™€ ì •í™•íˆ ì¼ì¹˜ì‹œí‚¤ê¸°\n",
    "        patient_processed = patient_processed[self.feature_names]\n",
    "        print(f\"âœ… íŠ¹ì„± ìˆœì„œ ì •ë ¬ ì™„ë£Œ: {patient_processed.shape}\")\n",
    "        print(f\"âœ… íŠ¹ì„±ëª… í™•ì¸: {list(patient_processed.columns) == self.feature_names}\")\n",
    "        \n",
    "        # Imputer ì ìš© (ì•ˆì „í•œ ë°©ë²•)\n",
    "        if hasattr(self, 'num_imputer') and self.num_imputer is not None:\n",
    "            try:\n",
    "                print(f\"\\nğŸ“ Imputer ì ìš© (ì•ˆì „í•œ ë°©ë²•):\")\n",
    "                print(f\"   - ì…ë ¥ í˜•íƒœ: {patient_processed.shape}\")\n",
    "                \n",
    "                if hasattr(self.num_imputer, 'n_features_in_'):\n",
    "                    expected_features = self.num_imputer.n_features_in_\n",
    "                    print(f\"   - Imputer ê¸°ëŒ€ íŠ¹ì„± ìˆ˜: {expected_features}\")\n",
    "                    \n",
    "                    if patient_processed.shape[1] == expected_features:\n",
    "                        patient_values = patient_processed.values\n",
    "                        imputed_values = self.num_imputer.transform(patient_values)\n",
    "                        patient_processed = pd.DataFrame(\n",
    "                            imputed_values,\n",
    "                            columns=self.feature_names,\n",
    "                            index=patient_processed.index\n",
    "                        )\n",
    "                        print(f\"âœ… Imputer ì ìš© ì™„ë£Œ\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ íŠ¹ì„± ìˆ˜ ë¶ˆì¼ì¹˜: ì…ë ¥ {patient_processed.shape[1]} vs ê¸°ëŒ€ {expected_features}\")\n",
    "                        print(f\"âš ï¸ Imputer ê±´ë„ˆëœ€ - ê²°ì¸¡ê°’ì€ ì´ë¯¸ ì²˜ë¦¬ë¨\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ Imputer íŠ¹ì„± ì •ë³´ ì—†ìŒ - ì•ˆì „í•˜ê²Œ ê±´ë„ˆëœ€\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Imputer ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ê±´ë„ˆëœ€: {e}\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸ Imputerê°€ ì—†ê±°ë‚˜ None - ê±´ë„ˆëœ€\")\n",
    "        \n",
    "        # Scaler ì ìš© (ì•ˆì „í•œ ë°©ë²•)\n",
    "        if hasattr(self, 'scaler') and self.scaler is not None:\n",
    "            try:\n",
    "                print(f\"\\nğŸ“ ìŠ¤ì¼€ì¼ë§ ì ìš© (ì•ˆì „í•œ ë°©ë²•):\")\n",
    "                print(f\"   - ì…ë ¥ í˜•íƒœ: {patient_processed.shape}\")\n",
    "                \n",
    "                if hasattr(self.scaler, 'n_features_in_'):\n",
    "                    expected_features = self.scaler.n_features_in_\n",
    "                    print(f\"   - Scaler ê¸°ëŒ€ íŠ¹ì„± ìˆ˜: {expected_features}\")\n",
    "                    \n",
    "                    if patient_processed.shape[1] == expected_features:\n",
    "                        patient_values = patient_processed.values\n",
    "                        scaled_values = self.scaler.transform(patient_values)\n",
    "                        patient_features_scaled = pd.DataFrame(\n",
    "                            scaled_values,\n",
    "                            columns=self.feature_names,\n",
    "                            index=patient_processed.index\n",
    "                        )\n",
    "                        print(f\"âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\")\n",
    "                        print(f\"âœ… ìµœì¢… íŠ¹ì„± í˜•íƒœ: {patient_features_scaled.shape}\")\n",
    "                        return patient_features_scaled\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ íŠ¹ì„± ìˆ˜ ë¶ˆì¼ì¹˜: ì…ë ¥ {patient_processed.shape[1]} vs ê¸°ëŒ€ {expected_features}\")\n",
    "                        print(f\"âš ï¸ ìŠ¤ì¼€ì¼ë§ ì—†ì´ ë°˜í™˜\")\n",
    "                        return patient_processed\n",
    "                else:\n",
    "                    print(f\"âš ï¸ Scaler íŠ¹ì„± ì •ë³´ ì—†ìŒ - ì•ˆì „í•˜ê²Œ ê±´ë„ˆëœ€\")\n",
    "                    return patient_processed\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ìŠ¤ì¼€ì¼ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                print(f\"âš ï¸ ìŠ¤ì¼€ì¼ë§ ì—†ì´ ë°˜í™˜\")\n",
    "                return patient_processed\n",
    "        else:\n",
    "            print(f\"â„¹ï¸ Scalerê°€ ì—†ê±°ë‚˜ None - ê±´ë„ˆëœ€\")\n",
    "            return patient_processed\n",
    "    \n",
    "    def test_cdss_compatibility(self):\n",
    "        \"\"\"CDSS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ”¬ CDSS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        try:\n",
    "            # holdout í™˜ì ë°ì´í„° ì „ì²˜ë¦¬\n",
    "            holdout_features = self.preprocess_holdout_patient()\n",
    "            \n",
    "            # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            predictions = {}\n",
    "            \n",
    "            for model_name, model_wrapper in self.models.items():\n",
    "                try:\n",
    "                    print(f\"\\nğŸ”„ {model_name} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...\")\n",
    "                    \n",
    "                    actual_model = model_wrapper['model']\n",
    "                    model_type = model_wrapper['model_type']\n",
    "                    \n",
    "                    print(f\"   - ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
    "                    print(f\"   - ì…ë ¥ íŠ¹ì„± ìˆ˜: {holdout_features.shape[1]}\")\n",
    "                    \n",
    "                    if model_type in ['RandomSurvivalForest', 'CoxPHSurvivalAnalysis']:\n",
    "                        # ìƒì¡´ ëª¨ë¸\n",
    "                        pred = actual_model.predict(holdout_features)[0]\n",
    "                        predictions[model_name] = {\n",
    "                            'type': 'survival',\n",
    "                            'risk_score': pred\n",
    "                        }\n",
    "                        print(f\"âœ… {model_name}: ìœ„í—˜ë„ ì ìˆ˜ = {pred:.4f}\")\n",
    "                    else:\n",
    "                        # ë¶„ë¥˜ ëª¨ë¸\n",
    "                        pred_class = actual_model.predict(holdout_features)[0]\n",
    "                        pred_proba = actual_model.predict_proba(holdout_features)[0]\n",
    "                        class_labels = model_wrapper['class_labels']\n",
    "                        \n",
    "                        predictions[model_name] = {\n",
    "                            'type': 'classification',\n",
    "                            'class': pred_class,\n",
    "                            'class_name': class_labels[pred_class],\n",
    "                            'probabilities': pred_proba\n",
    "                        }\n",
    "                        \n",
    "                        print(f\"âœ… {model_name}: {class_labels[pred_class]} (í™•ë¥ : {pred_proba[pred_class]:.3f})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}\")\n",
    "                    predictions[model_name] = {'error': str(e)}\n",
    "            \n",
    "            return predictions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ CDSS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def save_models_for_cdss(self):\n",
    "        \"\"\"CDSS í˜¸í™˜ ëª¨ë¸ ì €ì¥\"\"\"\n",
    "        print(\"\\nğŸ’¾ CDSS í˜¸í™˜ ëª¨ë¸ ì €ì¥\")\n",
    "        \n",
    "        # ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•˜ë‚˜ì˜ ê°ì²´ë¡œ ì €ì¥\n",
    "        cdss_pipeline = {\n",
    "            'models': self.models,\n",
    "            'holdout_patient': self.holdout_patient,\n",
    "            'metadata': {\n",
    "                'created_date': datetime.now().isoformat(),\n",
    "                'model_version': '4.0',\n",
    "                'description': 'TCGA-KIRC ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ (CDSS í˜¸í™˜ + ê³¼ì í•© ë°©ì§€)',\n",
    "                'class_labels': ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ê°œë³„ ëª¨ë¸ë„ ì €ì¥\n",
    "        for model_name, model_wrapper in self.models.items():\n",
    "            try:\n",
    "                filename = f\"cdss_kidney_cancer_treatment_{model_name.lower()}_model.pkl\"\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(model_wrapper, f)\n",
    "                print(f\"âœ… {model_name} ëª¨ë¸ ì €ì¥: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì €ì¥\n",
    "        try:\n",
    "            pipeline_filename = \"cdss_kidney_cancer_treatment_complete_pipeline.pkl\"\n",
    "            with open(pipeline_filename, 'wb') as f:\n",
    "                pickle.dump(cdss_pipeline, f)\n",
    "            print(f\"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì €ì¥: {pipeline_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì´í”„ë¼ì¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def plot_results(self, X_test, y_test_dur, y_test_event, y_test_eff):\n",
    "        \"\"\"ê²°ê³¼ ì‹œê°í™” (ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ íŠ¹í™”)\"\"\"\n",
    "        print(\"\\nğŸ“Š 7. ê²°ê³¼ ì‹œê°í™”\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(25, 35))\n",
    "        gs = fig.add_gridspec(5, 3)\n",
    "        axes = [\n",
    "            fig.add_subplot(gs[0, 0]),  # ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„ \n",
    "            fig.add_subplot(gs[0, 1]),  # ì¹˜ë£Œíš¨ê³¼ ë¶„í¬\n",
    "            fig.add_subplot(gs[0, 2]),  # ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 0]),  # ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 1]),  # AUC ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 2]),  # íŠ¹ì„± ì¤‘ìš”ë„ (XGBoost)\n",
    "            fig.add_subplot(gs[2, 0]),  # íŠ¹ì„± ì¤‘ìš”ë„ (LightGBM)\n",
    "            fig.add_subplot(gs[2, 1]),  # ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨\n",
    "            fig.add_subplot(gs[2, 2]),  # CDSS í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
    "            fig.add_subplot(gs[3, :]),  # SHAP ì‹œê°í™”\n",
    "            fig.add_subplot(gs[4, :])   # LIME ì‹œê°í™”\n",
    "        ]\n",
    "        \n",
    "        fig.suptitle('ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ê²°ê³¼ (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„ \n",
    "        print(\"ğŸ” ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  ìƒì„± ì¤‘...\")\n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                label = 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸' if eff_level == 1 else 'ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰'\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask], label=f'{label} (n={mask.sum()})')\n",
    "                kmf.plot_survival_function(ax=axes[0])\n",
    "        \n",
    "        axes[0].set_title('ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  (Kaplan-Meier)')\n",
    "        axes[0].set_ylabel('ìƒì¡´ í™•ë¥ ')\n",
    "        axes[0].set_xlabel('ì‹œê°„ (ì¼)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. ì¹˜ë£Œíš¨ê³¼ ë¶„í¬\n",
    "        eff_counts = pd.Series(y_test_eff).value_counts().sort_index()\n",
    "        colors = ['lightcoral', 'lightgreen']\n",
    "        labels = ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸']\n",
    "        bars = axes[1].bar([labels[i] for i in eff_counts.index], \n",
    "                          eff_counts.values, color=colors)\n",
    "        axes[1].set_title('í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì¹˜ë£Œíš¨ê³¼ ë¶„í¬')\n",
    "        axes[1].set_ylabel('í™˜ì ìˆ˜')\n",
    "        \n",
    "        for bar, value in zip(bars, eff_counts.values):\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                        f'{value}ëª…', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 3. ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "        survival_models = ['RSF', 'Cox_Survival']\n",
    "        survival_c_indices = []\n",
    "        survival_names = []\n",
    "        \n",
    "        for model_name in survival_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                c_index = self.results[model_name]['Test'].get('c_index', np.nan)\n",
    "                if not np.isnan(c_index):\n",
    "                    survival_c_indices.append(c_index)\n",
    "                    survival_names.append(model_name)\n",
    "        \n",
    "        if survival_c_indices:\n",
    "            bars = axes[2].bar(survival_names, survival_c_indices, \n",
    "                             color=['skyblue', 'lightcoral'][:len(survival_names)])\n",
    "            axes[2].set_title('ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥ (C-index)')\n",
    "            axes[2].set_ylabel('C-index')\n",
    "            axes[2].set_ylim(0.5, 1.0)\n",
    "            axes[2].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, survival_c_indices):\n",
    "                axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 4. ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (Accuracy)\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        classification_accuracies = []\n",
    "        classification_names = []\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                accuracy = self.results[model_name]['Test'].get('accuracy', np.nan)\n",
    "                if not np.isnan(accuracy):\n",
    "                    classification_accuracies.append(accuracy)\n",
    "                    classification_names.append(model_name)\n",
    "        \n",
    "        if classification_accuracies:\n",
    "            bars = axes[3].bar(classification_names, classification_accuracies,\n",
    "                              color=['lightgreen', 'orange', 'gold'][:len(classification_names)])\n",
    "            axes[3].set_title('ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (Accuracy)')\n",
    "            axes[3].set_ylabel('Accuracy')\n",
    "            axes[3].set_ylim(0, 1.0)\n",
    "            axes[3].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, classification_accuracies):\n",
    "                axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 5. ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (AUC)\n",
    "        classification_aucs = []\n",
    "        for model_name in classification_names:\n",
    "            auc_score = self.results[model_name]['Test'].get('auc', np.nan)\n",
    "            classification_aucs.append(auc_score if not np.isnan(auc_score) else 0)\n",
    "        \n",
    "        if classification_aucs:\n",
    "            bars = axes[4].bar(classification_names, classification_aucs, \n",
    "                              color=['lightgreen', 'orange', 'gold'][:len(classification_names)])\n",
    "            axes[4].set_title('ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (AUC)')\n",
    "            axes[4].set_ylabel('AUC')\n",
    "            axes[4].set_ylim(0, 1.0)\n",
    "            axes[4].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, classification_aucs):\n",
    "                if value > 0:\n",
    "                    axes[4].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 6-7. íŠ¹ì„± ì¤‘ìš”ë„ (XGBoost, LightGBM)\n",
    "        for idx, model_name in enumerate(['XGB_Treatment', 'LGB_Treatment']):\n",
    "            ax_idx = 5 + idx\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    model_wrapper = self.models[model_name]\n",
    "                    importance = model_wrapper['training_info']['feature_importance']\n",
    "                    \n",
    "                    feature_importance_df = pd.DataFrame({\n",
    "                        'feature': self.feature_names,\n",
    "                        'importance': importance\n",
    "                    }).sort_values('importance', ascending=True).tail(10)\n",
    "                    \n",
    "                    color = 'lightcoral' if model_name == 'XGB_Treatment' else 'gold'\n",
    "                    bars = axes[ax_idx].barh(range(len(feature_importance_df)), \n",
    "                                           feature_importance_df['importance'],\n",
    "                                           color=color)\n",
    "                    \n",
    "                    axes[ax_idx].set_yticks(range(len(feature_importance_df)))\n",
    "                    axes[ax_idx].set_yticklabels(feature_importance_df['feature'], fontsize=10)\n",
    "                    axes[ax_idx].set_title(f'íŠ¹ì„± ì¤‘ìš”ë„ ({model_name})', fontsize=12, fontweight='bold')\n",
    "                    axes[ax_idx].set_xlabel('ì¤‘ìš”ë„')\n",
    "                    axes[ax_idx].grid(True, alpha=0.3, axis='x')\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 8. ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨ ìš”ì•½\n",
    "        survival_summary = []\n",
    "        time_points = [365, 1095, 1825]  # 1ë…„, 3ë…„, 5ë…„\n",
    "        \n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask])\n",
    "                \n",
    "                survival_rates = []\n",
    "                for time_point in time_points:\n",
    "                    try:\n",
    "                        survival_rate = kmf.survival_function_at_times(time_point).values[0]\n",
    "                        survival_rates.append(survival_rate * 100)\n",
    "                    except:\n",
    "                        survival_rates.append(np.nan)\n",
    "                \n",
    "                label = 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸' if eff_level == 1 else 'ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰'\n",
    "                survival_summary.append({\n",
    "                    'treatment_effectiveness': label,\n",
    "                    'count': mask.sum(),\n",
    "                    '1ë…„': survival_rates[0],\n",
    "                    '3ë…„': survival_rates[1],\n",
    "                    '5ë…„': survival_rates[2]\n",
    "                })\n",
    "        \n",
    "        # ìƒì¡´ìœ¨ í…Œì´ë¸” ì‹œê°í™”\n",
    "        if survival_summary:\n",
    "            survival_df = pd.DataFrame(survival_summary)\n",
    "            table_data = []\n",
    "            for _, row in survival_df.iterrows():\n",
    "                table_data.append([\n",
    "                    row['treatment_effectiveness'],\n",
    "                    f\"{row['count']}ëª…\",\n",
    "                    f\"{row['1ë…„']:.1f}%\" if not pd.isna(row['1ë…„']) else \"N/A\",\n",
    "                    f\"{row['3ë…„']:.1f}%\" if not pd.isna(row['3ë…„']) else \"N/A\",\n",
    "                    f\"{row['5ë…„']:.1f}%\" if not pd.isna(row['5ë…„']) else \"N/A\"\n",
    "                ])\n",
    "            \n",
    "            table = axes[7].table(cellText=table_data,\n",
    "                                colLabels=['ì¹˜ë£Œíš¨ê³¼', 'í™˜ììˆ˜', '1ë…„ ìƒì¡´ìœ¨', '3ë…„ ìƒì¡´ìœ¨', '5ë…„ ìƒì¡´ìœ¨'],\n",
    "                                cellLoc='center',\n",
    "                                loc='center',\n",
    "                                colWidths=[0.2, 0.15, 0.2, 0.2, 0.2])\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(10)\n",
    "            table.scale(1, 2)\n",
    "            axes[7].axis('off')\n",
    "            axes[7].set_title('ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨ ìš”ì•½', fontweight='bold')\n",
    "        \n",
    "        # 9. CDSS í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
    "        print(\"ğŸ” CDSS í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ì¤‘...\")\n",
    "        cdss_results = self.test_cdss_compatibility()\n",
    "        \n",
    "        if cdss_results:\n",
    "            cdss_table_data = []\n",
    "            for model_name, result in cdss_results.items():\n",
    "                if 'error' not in result:\n",
    "                    if result.get('type') == 'classification':\n",
    "                        cdss_table_data.append([\n",
    "                            model_name,\n",
    "                            result.get('class_name', 'N/A'),\n",
    "                            f\"{max(result.get('probabilities', [0])):.3f}\" if 'probabilities' in result else 'N/A'\n",
    "                        ])\n",
    "                    else:\n",
    "                        cdss_table_data.append([\n",
    "                            model_name,\n",
    "                            'ìƒì¡´ ìœ„í—˜ë„ ì ìˆ˜',\n",
    "                            f\"{result.get('risk_score', 0):.3f}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    cdss_table_data.append([model_name, \"ì˜¤ë¥˜\", \"N/A\"])\n",
    "            \n",
    "            if cdss_table_data:\n",
    "                cdss_table = axes[8].table(cellText=cdss_table_data,\n",
    "                                         colLabels=['ëª¨ë¸', 'ì˜ˆì¸¡ ê²°ê³¼', 'í™•ë¥ /ì ìˆ˜'],\n",
    "                                         cellLoc='center',\n",
    "                                         loc='center',\n",
    "                                         colWidths=[0.4, 0.3, 0.3])\n",
    "                cdss_table.auto_set_font_size(False)\n",
    "                cdss_table.set_fontsize(10)\n",
    "                cdss_table.scale(1, 2)\n",
    "                axes[8].axis('off')\n",
    "                axes[8].set_title('CDSS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼ (Holdout í™˜ì)', fontweight='bold')\n",
    "        \n",
    "        # 10-11. XAI ì‹œê°í™” ì˜ì—­\n",
    "        axes[9].text(0.5, 0.5, 'SHAP ì‹œê°í™”ëŠ” ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤\\n(shap_summary_*.png, shap_waterfall_*.png)', \n",
    "                    ha='center', va='center', fontsize=14, transform=axes[9].transAxes)\n",
    "        axes[9].set_title('SHAP ì„¤ëª… ê°€ëŠ¥ AI', fontweight='bold')\n",
    "        axes[9].axis('off')\n",
    "        \n",
    "        axes[10].text(0.5, 0.5, 'LIME ì‹œê°í™”ëŠ” ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤\\n(lime_explanation_*.png)', \n",
    "                     ha='center', va='center', fontsize=14, transform=axes[10].transAxes)\n",
    "        axes[10].set_title('LIME ì„¤ëª… ê°€ëŠ¥ AI', fontweight='bold')\n",
    "        axes[10].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # XAI ì‹œê°í™” ìƒì„±\n",
    "        shap_figures, lime_figures = self.generate_xai_visualizations(X_test, sample_index=0)\n",
    "        \n",
    "        main_results_path = \"kidney_cancer_treatment_effect_analysis_results.png\"\n",
    "        plt.savefig(main_results_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ… ë©”ì¸ ê²°ê³¼ ì €ì¥: {main_results_path}\")\n",
    "        \n",
    "        return main_results_path, shap_figures, lime_figures\n",
    "    \n",
    "    def generate_final_report(self):\n",
    "        \"\"\"ìµœì¢… ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "        print(\"\\nğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„±\")\n",
    "        \n",
    "        report = f\"\"\"\n",
    "{'='*80}\n",
    "ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ë³´ê³ ì„œ (CDSS í˜¸í™˜ + XAI + ê³¼ì í•© ë°©ì§€)\n",
    "{'='*80}\n",
    "\n",
    "ğŸ“Š ë°ì´í„° ê°œìš”:\n",
    "- ì´ í™˜ì ìˆ˜: {len(self.processed_df)}ëª…\n",
    "- ì‚¬ë§ í™˜ì: {self.processed_df['event'].sum()}ëª…\n",
    "- ì‚¬ë§ë¥ : {self.processed_df['event'].mean()*100:.1f}%\n",
    "- ì¤‘ê°„ ì¶”ì  ê¸°ê°„: {self.processed_df['duration'].median():.0f}ì¼\n",
    "- ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸: {self.processed_df['treatment_effectiveness'].sum()}ëª…\n",
    "\n",
    "ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\n",
    "\"\"\"\n",
    "        \n",
    "        for model_name, results in self.results.items():\n",
    "            report += f\"\\n{model_name}:\\n\"\n",
    "            for dataset, metrics in results.items():\n",
    "                if 'error' not in metrics:\n",
    "                    if 'c_index' in metrics:\n",
    "                        c_index = metrics.get('c_index', 'N/A')\n",
    "                        report += f\"  - {dataset}: C-index = {c_index:.3f}\\n\"\n",
    "                    else:\n",
    "                        accuracy = metrics.get('accuracy', 'N/A')\n",
    "                        auc = metrics.get('auc', 'N/A')\n",
    "                        if isinstance(accuracy, float):\n",
    "                            report += f\"  - {dataset}: Accuracy = {accuracy:.3f}, AUC = {auc:.3f}\\n\"\n",
    "                        else:\n",
    "                            report += f\"  - {dataset}: Accuracy = {accuracy}, AUC = {auc}\\n\"\n",
    "                else:\n",
    "                    report += f\"  - {dataset}: ì˜¤ë¥˜ ë°œìƒ\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "ğŸ”¬ CDSS í˜¸í™˜ì„±:\n",
    "- ëª¨ë“  ëª¨ë¸ì´ CDSS í˜¸í™˜ í˜•íƒœë¡œ ë˜í•‘ë¨\n",
    "- Holdout í™˜ì í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
    "- ì‹¤ì‹œê°„ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥\n",
    "\n",
    "ğŸ§  ì„¤ëª… ê°€ëŠ¥ AI (XAI):\n",
    "- SHAP ì„¤ëª…ê¸° êµ¬í˜„ ì™„ë£Œ\n",
    "- LIME ì„¤ëª…ê¸° êµ¬í˜„ ì™„ë£Œ\n",
    "- íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ\n",
    "\n",
    "âš–ï¸ ê³¼ì í•© ë°©ì§€:\n",
    "- ê· í˜•ì¡íŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "- ì ì ˆí•œ ì •ê·œí™” ì ìš©\n",
    "- Early Stopping êµ¬í˜„\n",
    "\n",
    "ğŸ’¾ ì €ì¥ëœ íŒŒì¼:\n",
    "- ëª¨ë¸ íŒŒì¼: cdss_kidney_cancer_treatment_*_model.pkl\n",
    "- ì „ì²´ íŒŒì´í”„ë¼ì¸: cdss_kidney_cancer_treatment_complete_pipeline.pkl\n",
    "- ì‹œê°í™” ê²°ê³¼: kidney_cancer_treatment_effect_analysis_results.png\n",
    "- XAI ì‹œê°í™”: shap_*.png, lime_*.png\n",
    "\n",
    "â° ë¶„ì„ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "        \n",
    "        # ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        with open(\"kidney_cancer_treatment_effect_analysis_report.txt\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(report)\n",
    "        print(\"âœ… ë³´ê³ ì„œ ì €ì¥: kidney_cancer_treatment_effect_analysis_report.txt\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"ì „ì²´ ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸš€ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì „ì²´ ë¶„ì„ ì‹œì‘\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            # 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
    "            if not self.load_and_explore_data():\n",
    "                return False\n",
    "            \n",
    "            # 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "            if not self.preprocess_data():\n",
    "                return False\n",
    "            \n",
    "            # 3. íŠ¹ì„± ì¤€ë¹„\n",
    "            X, y_structured, y_duration, y_event, y_effectiveness = self.prepare_features()\n",
    "            \n",
    "            # 4. ë°ì´í„° ë¶„í• \n",
    "            (X_train, X_val, X_test, \n",
    "             y_train_struct, y_val_struct, y_test_struct,\n",
    "             y_train_dur, y_val_dur, y_test_dur,\n",
    "             y_train_event, y_val_event, y_test_event,\n",
    "             y_train_eff, y_val_eff, y_test_eff) = self.split_data(\n",
    "                X, y_structured, y_duration, y_event, y_effectiveness)\n",
    "            \n",
    "            # 5. ëª¨ë¸ í›ˆë ¨\n",
    "            if not self.train_models(X_train, X_val, X_test,\n",
    "                                   y_train_struct, y_val_struct, y_test_struct,\n",
    "                                   y_train_dur, y_val_dur, y_test_dur,\n",
    "                                   y_train_event, y_val_event, y_test_event,\n",
    "                                   y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 6. ëª¨ë¸ í‰ê°€\n",
    "            if not self.evaluate_models(X_train, X_val, X_test,\n",
    "                                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                                       y_train_event, y_val_event, y_test_event,\n",
    "                                       y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 7. XAI ì„¤ëª… ìƒì„±\n",
    "            if not self.explain_models(X_train, X_test):\n",
    "                print(\"âš ï¸ XAI ì„¤ëª… ìƒì„± ì‹¤íŒ¨, ê³„ì† ì§„í–‰\")\n",
    "            \n",
    "            # 8. ê²°ê³¼ ì‹œê°í™”\n",
    "            main_plot, shap_plots, lime_plots = self.plot_results(\n",
    "                X_test, y_test_dur, y_test_event, y_test_eff)\n",
    "            \n",
    "            # 9. CDSS í˜¸í™˜ ëª¨ë¸ ì €ì¥\n",
    "            if not self.save_models_for_cdss():\n",
    "                print(\"âš ï¸ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨, ê³„ì† ì§„í–‰\")\n",
    "            \n",
    "            # 10. ìµœì¢… ë³´ê³ ì„œ ìƒì„±\n",
    "            final_report = self.generate_final_report()\n",
    "            \n",
    "            print(\"\\nğŸ‰ ì‹ ì¥ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!\")\n",
    "            print(\"âœ… ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "    data_path = r\"G:\\.shortcut-targets-by-id\\1aXfYtUWSYS8foz14MAJMhDH7IHhG1wNZ\\2ì¡°\\ë°ì´í„°\\clinical model\\kidney\\TCGA-KIRP_clinical_data.csv\"  # ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    \n",
    "    # ë¶„ì„ ê°ì²´ ìƒì„± ë° ì‹¤í–‰\n",
    "    analyzer = KidneyCancerTreatmentEffectPredictorCDSS(data_path)\n",
    "    success = analyzer.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ¯ ë¶„ì„ ê²°ê³¼ ìš”ì•½:\")\n",
    "        print(\"- 5ê°œì˜ CDSS í˜¸í™˜ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„± ì™„ë£Œ\")\n",
    "        print(\"  * Random Survival Forest (ìƒì¡´ ì˜ˆì¸¡)\")\n",
    "        print(\"  * Cox ë¹„ë¡€ìœ„í—˜ëª¨ë¸ (ìƒì¡´ ì˜ˆì¸¡)\")\n",
    "        print(\"  * Random Forest (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\")\n",
    "        print(\"  * XGBoost (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\")\n",
    "        print(\"  * LightGBM (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\")\n",
    "        print(\"- XAI ì„¤ëª… ê°€ëŠ¥ AI êµ¬í˜„ ì™„ë£Œ\")\n",
    "        print(\"- ê³¼ì í•© ë°©ì§€ ìµœì í™” ì™„ë£Œ\")\n",
    "        print(\"- ì‹¤ì‹œê°„ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "        print(\"- ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ë¶„ì„ ì‹¤íŒ¨\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
